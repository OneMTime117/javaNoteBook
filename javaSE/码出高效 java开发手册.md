码出高效 java开发手册

## 1、计算机基础

从编程角度深度探讨计算机组成原理、计算机网络、信息安全等相关内容

### 1.1 走进0与1的世界

​	1、计算机就是有晶体管和电路板组成，无论是图像渲染、网络远程共享，还是大数据计算，归根到底都是对0与1的信号处理；而0与1是通过各种介质中的物理表现形式进行区分的，如三极管的通断、CPU的高低电平、磁盘的电荷左右方向

​	2、由多个0和1的组合排列，就组成了一个二进制数，它们能够表示对应的十进制数；以一个八位二进制为例，它可以有2的8次方种排序，即能表示256种信号（十进制），由于在现实生活中，常常存在负数，因此将最高位作为正负数的判断（0位正，1位负），这样一个八位二进制数就可以表示-128~127的整数范围（00000000代表0；10000000代表-128）

​	3、由于二进制有负数的表现形式，因此可以将减法运算转换为对负数的加法运算，从而降低CPU内部的设计复杂度，使计算更加高效

​	4、二进制数有三种表示方式：原码、反码和补码，用于优化二进制的负数加法运算

原码：正常的二进制表示方式

反码：当使用负数二进制做加法运算时，发现无法得出正确结果；因此就引入的反码，**对于负数即在原码基础上，符号为不变，其他位取反；而正数的反码就是原码本身**；将两个加数同时反码，然后进行加法运算，之后在对结果进行取反，此时二进制就能表示正确结果

补码：当使用反码来进行-1与+1相加时，会发生结果为-0的情况（11111111的反码是10000000），不符合现实中只有0的存在；因此就引入了补码，**对于负数即在原码基础上，符号为不变，其他位取反，然后低位补1；而正数的反码就是原码本身**；将两个加数同时转化为补码，然后进行加法运算，之后在对结果进行取反低位补1，此时二进制就能表示正确结果

**因此最终进行带有负数的加法运算时，使用补码方式来优化运算**；即两个二进制数相加的正确结果，为它们补码相加结果的取反低位补1（若结果为10000000，则不需要转换，直接表示为-128）

为了消除-0，规定10000000代表十进制-128的补码（直接使用10000000参与加法运算，之后再结果取反低位补1）；**并且-128没有原码和反码的表示**

​	5、二进制的位移运算，通过对二进制数的位移，可以使计算机更加高效的进行高低位截取、哈希计算、乘除法运算；同样的二进制位移运算也是使用补码进行操作

​	**二进制带符号位移运算（>>、<<），除负数往右移动最高位补1外，其他情况均补0**

​	**二进制无符号右移动（>>>,不存在无符号左移，因为左移不需要考虑是否有符号），直接高位补0；并且负数无符号移动时，最小值为1，以32位为例，当>>32位时的结果为它本身，>>33位的结果和>>1的结果一致，即每移动32位为一次循环，然后就从原有二进制移动，并且对于负数，当>>31位时，最右边为1，左边均为0，达到最小值1**

​	二进制还有其它位运算，取反 ~、位与 &、位或 |；位与&和逻辑与&&都可以使用在条件表达式中，但其表现不同，逻辑与&&具有短路功能，当前者条件成立后，就不会继续进行后者的处理和判断；并且&&只能使用在布尔类型中，而&既可以进行布尔类型的逻辑运算，又可以进行位与的位运算

### 1.2、定点数与浮点数

​		计算机定义了两种小数，分别为定点数和浮点数。定义数为小数点位置固定，从而确定一段数字的整数和小数部分；浮点数采用的科学计数法来近似表示，由符号位、有效数字、指数三部分组成；

​		定点数由于是在一串数字中确定小数点的位置，因此可以表现的数字范围太小，并且运算时容易产生溢出；但是在表现上更加直观准确，在有效范围内是绝对精度。java中可以通过BigDecimal对象来使用该小数表现方式

#### 1.2.1、浮点数的表示

​		在数学中，采用十进制科学计数法来近似表示一个极大或极小且位数多的数。通过a* 10^n ,其中a的绝对值在1到10之间，并且可以简写为 aen；如-4.86e11 等价于 -4.86 * 10……11，表示的真实值为-486000000000。其中- 为符号，4.86为有效数字，11为指数

​		浮点数则采用二进制数来表示科学计数法中的符号、指数和有效数字。由于使用了科学计数法，因此不能够保证表示的是绝对精度，但是表示的数字范围非常大；在业界IEEE754规范中，规定了四种浮点数类型：单精度、双精度、延伸单精度和延伸双精度；java采两用前种使用，它们取值范围为：

| 精度   | 字节数 | 正数取值范围            | 负数取值范围             |
| ------ | ------ | ----------------------- | ------------------------ |
| 单精度 | 4      | 1.4e-45  至  3.4e+38    | -3.4e+38  至 -1.4e-45    |
| 双精度 | 8      | 4.9e-324  至 1.798e+308 | -1.798e+308 至 -4.9e-424 |

由于浮点数不能表示0，因此取值范围分为两个区间：正数区间和负数区间；双精度浮点数只是因为位数翻倍，因此表示范围大，原理和单精度浮点一致，因此以单精度浮点为例：

一共占4个字节，32位，分别含有符号位（分配了1位表示浮点数符号，0为正，1为负）、阶码位（分配了8位来存储指数对应的移码）和尾数位（分配了23位来存储有效数字的原码）

指数的移码：指一个真值正向平移的一个偏移量得到的值的原码，IEEE754规定，阶码（指数的移码）= 指数 + 2的7次方 -1（127）；节码为无符号的8位二进制，并规定位数全0为0，位数全1为无穷的，因此范围位[1,254]，因此指数的范围为[-126,127]

尾数位的取值：由于科学计数法规定有效数字在1到10之间，因此默认尾数位取值形式为1.x，取值范围为[1,2]；是通过1.后面23位0或1组成的小数二进制得到；然后在将该小数二进制转化为十进制的有效数字

**小数二进制转化十进制的规则：**和普通二进制数一样，如11.11  1* 2^1+1 * 2^0+1 * 2^-1+1 * 2^-2= 3.75

综上所述，单精度最大正数为：符号位为1、阶码位为 11111111  即整个有关指数的结果集为2^127=1.7* 10^38、尾数位23个1 近似为2，最大正数为 2* 1.7*10^38=3.4e+38

浮点数的规格表示：

| 数值  | 浮点数二进制表示                                             | 说明                                                         |
| ----- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| -16   | <font color=red>1</font><font color=green>100-0001-1</font>000-0000-0000-0000-0000-0000 | 1*2^(131-127)                                                |
| 16.35 | <font color=red>0</font><font color=green>100-0001-1</font>000-0010-1100-1100-1100-1101 | 1.00000101100110011001101 小数二进制对应十进制为1.0218750238...*2^(131-127)=16.35000032 ,因此计算机实际存储值可能和真值不一样 |
| 0.35  | <font color=red>0</font><font color=green>011-1110-1</font>011-0011-0011-0011-0011-0011 | 1.399999*2^(125-127)=0.3499999                               |

1.2.2、浮点数的加减运算

​		在数学中进行小数加减运算时，需要先将小数点对齐，然后再进行同位数加减。因此在对采用科学计数法表示的数进行加减时，需要保证其指数一样，从而使两个的2的幂结果保持一致，这样就能保证有效数字进行加减后小数点能保持对齐

​		浮点数的加减运算过程如下：

1、零值检查：浮点数规定当阶码位和尾数位全为0时，该值为0，因此两数运算结果直接省略，为另一个数本身（这样减少不必要的操作，提高浮点运算性能）

2、对阶操作：比较两个浮点数的阶码是否相同，当尾码向右移动一位时，相当于有效数字除以2，则指数就需要加1，即阶码加1；由于尾码向右移的误差要比向左移的误差小很多（右移是失去了最小位的精度，左移是失去最大位精度），因此IEE754规定对阶操作只能向右移动，因此选择阶码小的浮点数进行操作

​		由于尾数位默认隐藏了一个最高位1，在向右移动时，最高位还是默认为1

​		由此可以阶码主要是为了进行对阶操作，因此采用移码来简化比较过程

3、尾数求和：当对阶完成时，就可以直接对尾数进行加法（负数需要先转化为补码）；需要将符号位和尾数位隐藏的最高位一起进行计算

4、结果规格化：当运算结果满足规格化时（即尾数相加结果在1到2间），则无需处理；当不满足时，需要对尾数进行移动左移动，保证尾数位隐藏的最高位为1，同时阶码也需要减去移动位数

5、结果舍入：在进行对阶和规格化种，尾数在左移或右移时，都会丢失低位数字，导致结果精度损失；因此计算机为了减少这种精度损失，会将这些失去的低位数字保存起来，称为保护位，等规格化后再根据保护位进行舍入

以1  和 -0.9两个浮点数相加为例：

1 的浮点二进制为：0011-1111-1000-0000-0000-0000-0000-0000

符号位 0   阶码 127  尾数（包含隐藏的最高位）  1000-0000-0000-0000-0000-0000  尾数补码为本身

0.9的浮点二进制为：1011-1111-0110-0110-0110-0110-0110-0110

符号位 1  阶码 126   尾数（包含隐藏的最高位）  1110-0110-0110-0110-0110-0110  尾数补码（符号位为1，因此尾数补码取反+1） 0001-1001-1001-1001-1001-1001

- 对阶：0.9的尾数左移，阶码+1；此时尾数为（最高位默认为1） 1111-0011-0011-0011-0011-0011 尾数补码  1000-1100-1100-1100-1100-1101

- 尾数求和：

  1的符号位+尾数       0 1000-0000-0000-0000-0000-0000

  0.9的符号位+尾数    1 1000-1100-1100-1100-1100-1101

  结果：                       0 0000-1100-1100-1100-1100-1101（结果符号位为0，因此不需要取反+1）

- 规格化：需要保证结果的尾数位最高位为1，因此尾数左移4位，阶码减4；因此左移后阶码等于123（二进制位01111011），尾数为1100-1100-1100-1100-1101-0000，隐藏最高位1，综上所述结果为浮点数二进制为；

  0011-1101-1100-1100-1100-1100-1101-0000 即 1.6000003814..*2^(123-127)=0.100000024

#### 1.2.3 浮点数的使用

​		1、在使用浮点数时，推荐使用双精度，因为单精度的有效位数最多只有7位；而多精度有效位数有15或16位，超出部分会进行四舍五入；也因此双精度和单精度在使用时，会有微小的误差

​		2、在绝对精确的业务场景，一定是使用整型数来表示最小单位的值，如货币使用分来保存；

​		3、在要求精确小数带你后n位的业务场景（n非常大），使用双精度浮点数就无法保证超出有效范围位数后的精度，因此就需要采用数组形式去保存；

​		4、由于浮点数存储时使用科学计数法进行近似，因此当两个浮点数进行运算后，误差将会变大体现出来，导致结果和实现生活不同，所以禁止使用浮点数和其运算结果进行相等判断；

​		5、在使用数据库存储小数时，推荐使用decimal类型，禁止使用float、double（这两种存在精度损失）

#### 1.2.4 十进制小数转化为单精度浮点数二进制过程

​		我们了解了单精度浮点数二进制是由4个字节（32位）组成；符号位、阶码位、尾数位；首先我们可以直接确定符号位，然后将小数转化位二进制，即整数部分除2取余从下到上组合排序、小数部分乘2取整从上到下排序；然后将两组排序进行组合，小数点分隔：

![](C:\Users\OneMTime\Desktop\Typora图片\带小数点的二进制转化.png)

然后将小数二进制左规或右规，转化位 1.x的进行，移动位数对应阶码大小，将其转化为对应移码，而移动后的结果就为尾码（最高位1隐藏，后面23位，位数过多截取，位数少则向后补0）

### 1.3、字符集与乱码

​		日常开发中，以UTF-8为主要编码，该字符集转化格式实现了Unicode编码风格（国际码，可以实现全球所有语言字符编码）；可以由1~6个Unicode字符进行编码表示对应语言字符，使用字节较少，有限降低数据存储、传输成本

​		数据流从底层数据库到应用层，到Web服务器，再到客户端显示，都会出现字符乱码问题，因此在排除乱码问题时，是一个很长的链路，需要逐一排除。对于数据库，是存储字符之源，它在不同层次，都能够独立设置字符集，如服务器级别、schema级别、表级别，因此为减少麻烦，应保证数据库所有级别的字符集一致

### 1.4、CPU与内存

​	在实际代码的运行环境中，CPU和内存是非常关键的两个部件。CPU就是一个超大规模的集成电路板（电路工艺达到6纳米级别），它内部就是对0与1的电流信号进行处理，单其处理机制非常精密复杂。CPU是由控制器、运算器和寄存器构成：

1、控制器，包含控制单位、指令译码器、指令寄存器；指令寄存器用于存储CPU中的指令集（X86、SSE、MMX，指令集是CPU控制计算机操作的一套指令集合，程序就是一系列一定顺序排序的指令）；指令译码器，就是帮助控制单元完成指令读取、分析、并交给运算器执行操作；控制单位，完成对指令的控制（指令读取、分析、并交给运算器执行操作）；整个控制器就相当于一个编程语言的编译器，将0与1的源码流，通过译码器和控制单元完成对指令的控制，并将结果存回寄存器或内存

2、运算器，核心就是算术逻辑运算单元（ALU），能通过指令执行算术运算和逻辑运算，可以从寄存器中提取或存储数据。运算器是受控制器控制的执行部件，完成所有的运算工作

3、寄存器，是CPU运算时的高速缓存，其结构和大小对CPU的性能有很大影响，（CPU的计算速度远大于数据的读写速度，因此缓存的提高会大大增加CPU的整体性能），目前CPU一般分为3级缓存（L1,L2,L3），读写速度由强到弱，容量由小到大（更快的速度，决定了需要的容量越小）

​	内存是计算机其他设备与CPU沟通的桥梁，它的结构比较简单，核心是存储单元，然后通过地址译码器和读写控制器完成对存储单元数据的读写；它的大小和频率，决定了计算机调用资源的速度和缓存资源的大小（因为计算机中的所有程序都是在内存中运行）

### 1.5、网络协议

​		在计算机诞生后，从单机模式发展到多计算机连接，然后到现在的互联网模式，实现信息共享、多机协助的计算网络；而计算机网路第一个需要解决的问题就是如何无障碍发送和接送数据：发送和接收数据的过程需要相应协议支撑，按合理的方式对数据进行打包和解包，使不同厂商设备在不同操作系统上实现网络互通。

​	TCP/IP（Transmission Control Protocol / Internet Protocol）传输控制协议/因特网互联协议。它是目前流行的网络传输协议框架。严格意义上说，它是一个协议族，包含HTTP、HTTPS、FTP、SMTP、UDP、ARP、PPP、IEEE 802.X等，但TCP、IP是其中最核心的协议；由于TCP/IP是在不断解决实际问题中成长壮大起来的，经过了市场的检验，因此目前基本无法被取代（即使有设计不合理，但已经被人们所习惯）

####  	1.5.1、TCP/IP协议分层框架

​		TCP/IP协议分层框架：被分为四层，从低到高为，链路层（IEEE 802.X/PPP）、网络层（IP/ARP）、传输层（TCP/UDP）、应用层（HTTP/FTP/SMTP）

- 链路层：以字节为单位通过0和1定义数据帧，其中包括：写入源和目标机器的物理地址、传输的数据、校验位

  计算机物理地址也叫做MAC地址，长6个字节共48位，使用十六进制数表示。前24位有管理机构统一分配，后24位由厂商分配，因此每一张网卡，都对应自己唯一的MAC地址，也是计算机在网络中的唯一标识

- 网络层：根据IP定义网络地址，区分网段。在进行数据包传输时，需要知道到目标机器的MCA地址，因此首先判断原机器（A）IP是否和目的机器（B）IP在同一个网段，在同一网段内就使用ARP（地址解析协议）进行MAC寻址，然后直接向B发送数据包；当不在一个网段时，则先将数据包发送给A的网关，并将数据包中的写入源MAC地址由A的MAC地址替换位该网关的MAC地址，发送给下一级设备，循环直到找到Bip的网关，然后使用ARP进行MAC寻址，最后将数据包中的目的MAC地址替换，从而包数据包发送给B

  **因此网络数据传输的关键是MAC地址，而IP是为了找到目标机器所在的网段，并在该网段下目标机器所对应的MAC地址**

  IP分为网络地址和主机地址，而子网掩码就是用于区分网络地址和主机地址；网络地址在同一网段是固定的，主机位随机，而该网段的默认广播地址：主机位全为1；网段的默认网络地址：主机位全为0

  默认子网掩码有三类：255.0.0.0、255.255.0.0、255.255.255.0；它们对应网段最多可容纳的IP个数为：1677万、6万、254（对于第三类默认网段，IP地址最后一位不能为0，因为是该网段的网络地址，不能为255，因为是该网段的广播地址）；当然由于者三类之间可容纳的IP数范围相差非常大，因此对于如需要500个IP的网段，无法满足，因此子网掩码可以是非默认的，只要保证二进制数中前面全为1后面全为0，即为1的对于IP的网络地址，为0的对应IP的主机地。所有子网掩码除了0/255，还可以为254、252、248、240、224、192、128

  除了定义子网掩码的形式确定网段外，还可以通过  ip后面+ /24，这代表了IP前24位为网络地址

- 传输层：数据包通过网络层发送到目标计算机后，应用程序则通过传输层定义逻辑端口，实现网络两边端口与端口间的通信，从而定义数据传输和端口连接方式的规范。最典型的传输层协议就是UDP和TCP
- 应用层：传输层的数据到达应用程序后，通过应用层来以某种统一规定协议格式取解读数据，常见应用层协议有HTTP和SMTP等

综上所述，在程序进行网络信息通信时，应用层打包数据，传输层建立数据传输端口和传输方式，网络层通过IP进行MAC寻址，并完成数据传输，链路层在数据中添加传输双方的MAC地址，并将数据拆分成数据帧，完成具体的数据传输。

另外存在著名的 OSI（开方式系统互联通信参考模型）的七层传输协议，包括物理层、链路层、网络层、传输层、会话层、表示层、应用层，但已经被淘汰

#### 1.5.2、IP协议

​		IP协议首先规定了IP地址格式，给每一个互联网中的计算机设置了一个唯一的详细地址。本身计算机中，每一张网卡都有自己唯一的MAC地址，但是只是通过广播的形式，在互联网千万台计算机中找到目标MAC地址是非常费时间的。因此通过IP地址，我们可以对全世界的网络进行分层管理，先通过IP找到依次逐级找到最上级路由，然后在逐级向下找到ip所在网段的网关，此时在以广播形式，更快的找到目标机器，发送IP报文

​		IP报文结构：

![](C:\Users\OneMTime\Desktop\Typora图片\IP协议报文.jpg)

IP报头中的生存时间TTL，指数据包在传输过程中，最多可经过的路由总数。每经过一个路由器，TTL值减1，当该字段为0时，数据包将被丢弃不会继续发送到下一级路由，并且反向发送ICMP报文，通知源主机目标IP地址在TTL值内，无法被找到，从而防止源主机无休止的发送报文

​		ICMP（Internet Contorl Message Protocol 互联网控制消息协议），它是检测传输网络是否通畅、目标主机是否可达、路由是否可用等网络运行状态的协议。ICMP不传输用户数据，只是对网络健康状态进行评估。我们常用的ping命令就是基于ICMP检测网络状态的工具

IP报头中的挂载协议标识标识IP报文子数据包协议类型，6代表TCP、17代表UDP

IP报文在互联网传输时，要经历多个物理网络，才能从源主机到达目标主机。由于其间各种物理硬件的性能特性不同，因此它们在传输数据帧的最大长度也有不同限制，该最大长度被称为最大传输单元（MTU Maximum Transmission Unit）。因此实际上IP报文在物理网传输时，需要进行分片处理，该工作通过路由器完成

IP是TCP/IP的基石，几乎其所有其他协议都是建立在IP提供服务的基础之上，其中就包括实际应用用于传输稳定有序数据的TCP

#### 1.5.3、TCP协议

​		传输控制协议（TCP Transmission Control Protocol），是一种面向连接、确保数据在端与端之间可靠传输的协议。面向连接：指在发送数据前，需要先建立一条虚拟的链路，然后让数据在这条链路上“流动”完成传输；确保数据传输可靠：TCP协议会对发送的每个字节进行编码确认，检验每个数据包的有效性，在出现超时情况时，进行重传，并实现滑动窗口和拥塞控制等机制，避免网络状况恶化而影响数据传输。

​		TCP数据包都封装在IP包中，随着IP包一起传输，TCP报文的结构为：

![](C:\Users\OneMTime\Desktop\Typora图片\TCP协议报文.jpg)

TCP报头第一行为源机器和目标机器的端口号，通过两端口号和IP报头中的两IP地址组成一个四元组的唯一标识，也就对应一个TCP连接。

​		TCP是面向连接的，因此分为客户端和服务端。当客户端第一次发送请求建立连接的TCP包时，目标机器端口号为服务端所监听的端口号；国际组织定义了一些默认方便识别的端口号：HTTP服务使用80端口、SHH服务使用22端口、HTTPS服务使用443端口

TCP报头第二行和第三行为序列号（seq），各占4个字节。前者是发送数据包中的数据部分第一个字节的序号，即序列号，后者为确认序列号（ack），当该数据包为响应包时，则会使用确认序列号=请求包序列号+1，用于表示前者发送的数据被确认正确收到，并且也是期望收到对方下一个数据包的序列号

、FIN（Finish 标识后面没有数据需要发送，TCP连接可以关闭）

##### 1.5.3.1、TCP的三次握手，建立连接：

​		TCP的三次握手时通过TCP报头中的SYN（Synchronize Sequence Numbers 同步序列数字，即建立连接时的同步信号）、ACK（Acknowledgement 确认数据信号，表示前者发送的数据被确认正确接收）、序列号和确认序列号四个字段实现的。过程如下：

- A机器发送一个数据包，并将SYN置1，表示希望建立TCP连接，设数据包的序列号为X

- B机器接收到A机器发过来的数据包后，通过SYN为1，得知是请求建立TCP连接，于是发送一个响应包。将SYN和ACK都置1，确认序列号置为X+1，从而表示B接收到了A的建立连接请求。设响应包中的序列号为Y

- A收到B的响应包后需要进行确认，将确认包中的ACK置1，并将序列号置为X+1，确认序列号置为Y+1，表示A能接收到B的确认建立连接的响应

  ![](C:\Users\OneMTime\Desktop\Typora图片\TCP三次握手.png)

三次握手的目的：完成两端信息对等和防止超时

- 信息对等：保证双方都能确认四类信息（自己的发报能力、自己的收报能力、对方的发报能力和对方的收报能力），才能建立有效连接。在第一次握手时，B机器可以确定自己的收报能力和对方的发报能力；第二次握手时，A机器可以确定自己的收报能力和发报能力、对方的收报能力和发报能力（此时A掌握四类信息）；第三次握手时，B机器可以确定自己的发报能力和对方的收报能力（此时B掌握四类信息）

- 防止超时：由于TCP连接超时时间小于IP报文的TTL生存时间，因此导致A由于在建立连接请求超时下，多次发送，而B确能全部接收；若不使用三次握手，只使用两次握手；就会导致后一次请求建立连接后，被前一个超时建立连接请求破坏，重新建立TCP连接，因此前一次连接断开，而后一次连接在A确认时，A的状态不处于建立连接待响应状态（SYN_SENT），因此会忽略B的确认包，最后导致TCP连接中断；但如果使用三次握手时，当B机器收到超时的建立连接请求后，A机器在接收响应包时，由于不处于SYN_SENT状态(建立连接待响应状态)，则会忽略B的响应包，从不会建立脏连接

三次握手时，客户端和服务端的三种状态：

客户端：LISTENING（端口监听状态） 、SYN_SENT（同步信号已发送状态）、ESTABLISHED（连接建立状态）

服务端：LISTENING（端口监听状态）  、SYN_RCVD（同步信号已收到状态）、ESTABLISHED（连接建立状态）

TCP协议支持KeepAlive功能，即隔断时间向对方发送数据表示连接处于健康状态，当心跳包发送出现异常时，就会主动关闭连接，并回收与TCP连接相关资源，确保系统资源利用率

##### 1.5.3.2、TCP的四次挥手，端开连接：

TCP在建立来连接后，是全双工通信，双方都能作为数据的发送方和接收方。但TCP连接也需要断开，通过ACK（Acknowledgement 确认数据信号，表示前者发送的数据被确认正确接收）、FIN（Finish 表示后面没有数据需要发送，TCP连接可以关闭）、que（序列号）和ack（确认序列号）字段实现，过程如下：

- A机器想要关闭连接，因此发送一个数据包，FIN置1。进入等待关闭连接请求响应状态（FIN_WAIT_1），设序列号为U
- B机器收到A想要关闭连接的请求，发送一个响应包，ACK置1，确认序列号为U+1。表示确认收到了A想要关闭连接的请求，并且同意可以断开，但是需要等待B自己完成之前的数据处理，并做好关闭连接准备，此时B处于等待关闭状态（COLSE_WAIT）；
- 当A收到响应包后，就进入半关闭状态（FIN_WAIT_2），无法发送新数据。此时B做好关闭连接准备后，发送关闭连接的响应包，FIN置1、ACK置1、确认序列号为U+1。此时B机器进入关闭确认状态（LAST_ACK），无法再发送新数据。设此时序列号为W
- 当A收到第二个响应包时，确定B已进入最后确认状态，即随时可以断开连接。此时发送一个确认包，ACK置1，序列号为U+1，确认序列号为W+1；此时A进入TIME_WAIT状态，经过2MSL（Maximum Segment Lifetime  TCP报文在网络中的最长生存时间，超出则直接丢弃）后，进入CLOSED状态

![](C:\Users\OneMTime\Desktop\Typora图片\TPC四次挥手.jpg)

如果A机器在FIN_WAIT_1状态下，直接收到B机器发送来带有FIN和ACK标志的响应包时（即B机器处于COLSE_WAIT状态），则无需经过FIN_WAIT_2状态，A机器直接发送最后的确认包，进入TIME_WAIT状态

TIME_WAIT状态的持续时间为2MSL。一般来说，MSL大于TTL,在RFC793中规定MSL为2分钟，因此TIME_WAIT状态需要持续4分钟，之后才能转化为CLOSED状态；4分钟等待时间会导致网络资源的极大浪费，但是这样设计是由原因的：

​	1、确保被动关闭的一方能顺利进入CLOSED状态。因为当由于网络原因，最后的确认包到达B机器时，处于LAST_ACK状态的B机器就会以为A机器没有收到自己发送的FIN+ACK报文，所有就会重发。若此时A机器不进行2MSL的等待，则就不一定能收到B机器重发来的FIN+ACK报文。导致自己”自私“的进入CLOSED状态，而B无法进入。

​	2、防止失效请求。若当A机器直接关闭后，又需要建立了AB机器之间相同端口的TCP连接时，此时就可能出现前一个连接的超时数据在该新连接中进行处理。导致和新连接传输的数据报发生混淆；而有了TIME_WAIT状态的超时时间后，就能有效的将那些超时报文进行丢弃。

由于TIME_WAIT状态下无法真正释放句柄资源，对于高并发服务器，会极大的影响有效TCP连接数量，导致性能出现瓶颈。因此对于高并发服务器，建议调小TIME_WAIT超时时间。毕竟现在网络和路由处理能力大大增强，大部分跨国延时都在1s以内，丢包率极低，基本不会出现这么长时间的超时。

TCP四次挥手中，客户端和服务端各状态：

客户端：ESTABLISHED(连接建立状态)、FIN_WAIT_1（关闭连接请求发送状态）、FIN_WAIT_2（关闭连接请求响应状态，即半关闭状态）、TIME_WAIT（连接关闭前的等待状态）、CLOSED（关闭状态）

服务端：ESTABLISHED(连接建立状态)、CLOSE_WAIT（等待关闭状态，此时进行关闭前的准备工作），LAST_ACK（关闭确认状态，即半关闭状态）、CLOSED（关闭状态）

### 1.6、连接池

​		通过连接来进行系统之间的交互，服务器可以快速创建和断开多个来连接，但对于高并发的后台服务器而言，连接的频繁断开和创建时非常重的负担。因此为了保证连接的使用效率，我们可以通过连接池的方式实现：首先，在客户端和服务端之间事先创建若干连接，放入到连接池中，当需要使用时直接从连接池获取；使用完成后，又放入连接池，从而减少频繁创建连接和释放连接的开销。如RPC服务集群的注册中心和服务器提供方、消费方之间的连接、后台服务器和数据库之间的连接、消息服务集群的缓存服务器和消费者服务器之间的连接

​	以数据库连接池为例，数据库来连接池负责分配、管理和释放连接，通过以内存空间换取时间的策略，来有效提升数据库连接访问的性能。数据库连接池有重要两个参数，数据库初始化最小连接数（MIN）和数据库最大连接数。当MIN过小，就会导致数据库第一时间进行多个数据库访问请求的响应时间增长，影响数据库访问效率；MIN过大，就会导致连接资源浪费；MAX过小，就会导致在高并发下，出现多个请求处于等待状态，不能有效利用数据库最大性能；MAX过大，就会导致在高并发下，数据库连接占满，而自身请求处理能力不足，导致请求超时，影响整个服务器应用。使服务器宕机。

​	在实际应用中，假如数据库配置的MAX为100，一个请求平均处理时间为10ms，则该数据库最大处理=100/10ms =10000QPS（每s查询量，反应数据库处理性能）

​	连接数的增加，只是为了更好的满足高并发场景；但是设置更大的连接数是治标不治本。影响数据库请求响应时间的关键，在于数据库本身的使用优化（数据库MAX一般只设置为30）：

1、建立高效且合适的索引。索引谁都可以建，但想要建好难度极大。因为索引既有数据特征，又有业务特征，数据量的变化会影响索引的选择；业务的不同，索引的优化思路也不一样

2、排查资源为关闭的错误代码。当数据库连接数一直保持很高值时，说明出现了来连接未关闭的情况。这样会大大浪费数据库资源，影响数据库高并发性能，甚至导致数据库崩溃

3、合理拆分多表join的sql，通过应用层面上的逻辑代码，简化高处理量的sql语句

4、使用临时表，有时不断地嵌套查询中，无法有效利用索引提升查询效率，因此可以将中间结果保存到一张临时表中，并对其进行索引创建，之后通过临时表进行后续数据操作

5、改用其他数据库。不同数据库针对的业务场景时不同的，应该合理选择后台数据库

6、应用层优化。对数据结构优化、并发多线程改造等

### 1.7、信息安全

#### 1.7.1黑客与安全

​		黑客（Hacker），黑客地攻击手段十分多样，大体分为非破坏性攻击和破坏性工具。非破坏性攻击时为了扰乱系统的运行，使之暂时失去正常对外提供服务地能力，如DDOS攻击等；破坏性攻击主要是两种后果，系统数据受损或者信息被窃取，如CSRF攻击等。攻击手段有病毒式、洪水式、系统漏洞式等。

​		对于所有互联网企业，都需要建立一套完整的信息安全体现，遵循CIA原则，即保密性（Confidentiality）、完整性（Integrity）、可用性（Availability）

- 保密性，对需要保护的数据（如用户私人信息等）进行保密操作，无论是存储还是传输，都需要保证用户数据及相关资源的安全。如数据传输时使用各种编码加密验证，而黑客不只可以通过网络进行数据窃取，还有可能重企业内部窃取数据，因此对于敏感数据，存储使用密文。

- 完整性。访问的数据需要是完整的，不能被随意篡改或产生缺失。因此在实际开发中，需要对访问到的数据或提交到后台的数据进行签名和校验（如MD5和数字签名等）

- 可用性。服务需要时可用的，保证应用服务不会收到黑客攻击，导致无法提供相应功能。

  web安全问题都是以这三点为基础展开，常见web安全问题有：

#### 1.7.2、SQL注入

​		sql注入式注入式攻击中最常见类型。SQL注入攻击是后台程序员未将代码与数据严格隔离导致的，在读取用户提交的数据时，错误的将数据作为了sql语句的一部分。这样会对数据库数据的安全和业务逻辑操作产生意想不到的影响，如更新/删除数据库中表的该字段所有数据、跳过用户认证等

​		预防方法有：

1、前端过滤用户输入参数中的特殊字符，降低sql注入风险

2、严格使用参数绑定的方式进行sql传参，禁止使用sql拼接

3、合理使用数据库访问框架中的防注入机制，如Mybatis 提供 #{}绑定参数

#### 1.7.3、XSS与CSRF

​		XSS(Cross-Site Scripting)，跨站脚本攻击，为了不和前端开发中的层叠样式表（CSS）名字冲突，简称为XSS。XSS是指黑客通过技术手段，向正常用户请求的HTML页面插入恶意脚本，从而可以执行任意脚本。XSS主要分为反射型XSS、存储型XSS和DOM型XSS。XSS主要用于信息窃取和破坏等目的。

- 反射型XSS，最常见的一种XSS攻击方式，直接通过给别人发送带有恶意脚本的url。当url地址被打开时，恶意脚本代码就会被HTML解析、执行。特点是非持久化，必须欺骗用户自己访问该url才能触发
- 存储型XSS，将恶意脚本存入服务器后台，当目标用户再次访问该页面时，页面就会加重之前后台存储的恶意脚本。特定是持久化，由于需要将脚本存储到服务器中，因此一般出现在网站留言、评论、博客日志中；当用户访问页面，页面请求后台获取你带有恶意脚本的评论后，进行页面加载时，就会触发该脚本
- DOM型XSS，是一种特殊的反射型XSS，同样是使用url进行触发，关键点在于恶意脚本攻击对象为DOM

​		防范XSS，主要是通过对用户输入数据进行过滤或HTML转义实现。有效避免出现脚本输入。

​		CSRF（Cross-Site Request Forgery），跨站请求伪造。在用户不知情的情况下，冒充用户发起请求，在已登陆的Web应用程序中进行恶意操作，如发帖、修改密码、发邮件等

CSRF和XSS的区别：从攻击效果上，两者有重复的地方（获取用户登入信息）；从技术原理上，有本质区别，XSS是正常用户请求的HTML页面中执行了黑客提供的恶意脚本。CSRF是黑客直接盗用用户浏览器中的登录信息，冒充用户执行黑客指定操作;Xss问题出现在用户数据没有过滤、转义；CSRF问题出现在对HTTP接口没有防范不受信任的调用

​		如用户A登录了自己的网银，此时黑客发送给他一个链接，用户点击后，此时就会执行其中的脚本利用当取浏览器保存的网银网站的用户认证，来进行转账操作的HTTP调用；

​		防范CSRF漏洞的主要方式为：

1、进行CSRF Token认证，通过Token来保存认证信息，并绑定到http的header中，导致黑客无法使用cookie中的认证信息来跳过服务端的Token认证

2、人机交互，对于这种需要高安全的操作调用，应该配置短信验证码进行校验

#### 1.7.4、HTTPS

​	在网络通信中，如何保证网络传输数据的加密，是网络安全的重要环境。SSL协议（Secure Socket Layer 安全套接字层），该协议工作在传输层和应用层之间，为应用提供数据的加密传输。而HTTPS即为HTTP over SSL，就是在应用层HTTP传输上增加SSL协议的加密功能。

​	而SSL安全协议建立的基础，就是RSA加密算法。最早的非对称式加密算法，它定义了公开密钥密码体制。即使用不同的加密密钥（公开密钥，公钥）和解幂密钥（私有密钥，私钥），并且加密密钥是通过解密密钥计算出来的，但加密密钥无法反向推导出解密密钥。

​	在RSA算法中，是基于大质数分解的困难性来保证加密的可靠性的。在实际数据安全加密传输中，双方互相知道对方的公钥，然后使用对方的公钥对数据进行加密，传递给对方。到达密文的一方，使用自己保存的私钥进行解码。期间即使双方公钥被获取，也无法对数据进行解密。

​	因此，HTTPS就是通过上面方式来进建立安全的SSL连接的。非对称加密传输过程如下：

1、A告诉B，使用RSA算法进行加密。B收到并同意

2、AB双方分别生成一组RSA密钥，并互相发送公钥

3、A使用收到的B的公钥，对数据加密、发送

4、B收到密文后，使用自己的私钥进行解密。

5、之后B也可以使用同样方式给A发送密文，A用自己私钥解密

非对称加密并非完美，它由一个明显的缺点，就是加密速度慢。只适合少量数据加密处理。因此在通过非对称加密算法建立SSL连接后，会使用对称加密算法（如DES）进行后面数据的加密。而其密钥则在SSL连接建立中，双方确定。

​    在这个过程中，看似无懈可击，但是如果在第(2)步中，A发送自己的密钥给B时，数据包被截获并篡改，使用黑客自己生成的一对RSA密钥中的公钥。B在不知情的情况下，使用该公钥给B发送信息，此时数据被截获时，黑客就能使用自己的私钥进行密文破解，即HTTPS中用于进行对称式加密的密钥被获取，之后所有传输信息都能被破解

​	因此为了解决HTTPS协议使用中的该问题，在基于HTTPS进行连接时，添加一个数字证书，也叫CA（Certificate Authority  认证授权组织）数字证书。用于在搭建SSL连接时，对HTTPS网站服务端请求进行身份认证。此时访问一个HTTPS网站，过程如下：

1、浏览器向服务器发送Client Hello请求，请求中包括浏览器支持的协议（目的是告诉服务器自己支持那些加密协议），并附带一个随机值

2、服务器收到请求后，选择某种非对称加密算法，把该网站的CA数字证书中的签名公钥、身份信息发送给浏览器（目的是告诉浏览器，使用的TLS版本、加密套件，并验证数字证书的真实性），同时也附带一个i而随机值

3、浏览器收到后，验证证书的真实性，发送握手信息（握手信息不会加密）和使用服务器发送的公钥加密的Finish数据（验证加密通道的可行性）给服务器（目的是对服务器发送的证书信息、数据加密方式进行确认）

4、服务器通过之前的随机值，计算出一个对称加密的密钥，并使用SSL连接进行发送（当服务器接收到浏览器的握手信息后，则确定SLL连接建立）。此时服务器和浏览器双方，就都是用该密钥进行数据加密传输

TSL（Transport Layer Security 传输层安全协议）：从大协议栈的角度而言，它和SSL没有太大区别。可以理解位SSL协议3.0版本的升级。

加密套件：确定使用何种 非对称式加密(如RSA)进行何种 对称式加密密钥（如DES）进行加密

### 1.8、编程语言的发展

​		第一代，机器语言时代。机器语言的编程就是单纯的0与1的二进制。直接对机器芯片进行指令操作，因此极大的收到硬件环境的影响。如汇编语言

​		第二代，高级语言时代。各种高级语言百花齐放。无论是面向过程，还是面向对象，都是面向问题编程。

## 2、面向对象

### 2.1、OOP（Object-Oriented Programming）理论

#### 1、面向对象和面向过程的区别：	

- 面向过程：把需求理解成一条条的业务流程，然后将所有流程组合划分成一个个功能模块，对应成相应的代码函数；面向过程关注于业务流程，因此当业务发生改变时，会极大的影响代码的修改，并难以维护；这样大大增加了开发效率，并无法面对实际开发过程中的需求变更

- 面向对象：将需求理解为一个个事物对象，每个对象都定义了自己复杂的事物（我是谁、我从哪里来、我能做什么）；通过对象将容易发生改变的代码封装起来，从而在实现代码复用的同时，极大的降低的代码之间的耦合

- 虽然两者在理论上有本质的区别，但它们同为编程语言，对于程序员只是一个工具；因此即使使用面向过程语言，也可以将程序写的非常内聚、扩展性好。只是说达成该目的会更加麻烦

#### 2、OOP产生的原因：

实现代码的可维护性、可重复性和可扩展性，让模块与模块直接实现高内聚、低耦合。有效降低软件开发开发成本、维护成本和复用成本

#### 3、OOP的三特性：

封装、继承和多态：

- 封装，通过类的权限修饰关键字，来控制类中属性和行为的访问权限，从而实现了代码的高内聚、低耦合，并更加具有维护性；
- 继承，使子类可以继承父类的部分行为和属性，实现代码之间的复用；
- 多态，子类在继承父类代码的同时，可以对行为进行重写；一个类可以有多个子类，因此一个父类类型变量可以指向多种子类类型实例，并实现行为的多态（即在不确定实例类型的情况下，使用父类类型变量接收，让程序拥有多种运行状态）；因此在代码复用的基础上，更加具有扩展性（只需要新增子类，而不需要改变原来代码）
- 抽象，类是由属性和行为组成，属性代表了类的对事物的描述，行为通过操作属性来代表事物的行为；抽象本质上就是将一些事物的共有属性和行为模板（不定义行为的方法体）放在一起作为一个类，再以该类为模板，多样化的创建具体实现，完成从共性到个性、本质到具体的形象化演变

### 2.2、java语言特性

跨平台、分布式、多线程、类库丰富、开发高效、社区健壮；让开发者能使用优雅的思维方式处理复杂问题的编程

### 2.3、类

#### 2.3.1、类的定义

​	1、类的定义由访问级别、类型、类名、是否抽象、是否静态、泛型标识、继承或实现；类型分为class、Interface（接口）、enum（枚举）：**注意static只能修饰内部类**

​	2、类由成员和方法组成；先定义成员，后定义方法；对于方法书写顺序：构造方法、公开方法、私有方法、getter/setter

#### 2.3.2、接口与抽象类

​	接口和抽象类是对类的抽象体现，仅定义公共行为和特征，并且不能直接实例化，但两者也有区别：

| 语法                 | 抽象类    | 接口                                   |
| -------------------- | --------- | -------------------------------------- |
| 定义关键字           | abstract  | interface                              |
| 子类继承或实现关键字 | extends   | implements                             |
| 具体方法             | 可以存在  | JAVA8前不能，之后提供default关键字实现 |
| 方法访问权限         | 无限制    | 默认为public abstract                  |
| 属性访问权限         | 无限制    | 默认为public static final              |
| 静态方法/静态代码块  | 可以存在  | JAVA8前不能存在，之后支持静态方法      |
| 同类型扩展           | 单继承    | 多继承                                 |
| 扩展关键字           | extends A | extends A,B                            |

​	一般情况下，优先使用接口，然后在使用抽象类对接口行为进行进一步分层扩展

#### 2.3.3、内部类

1、在一个类的内部定义类，前者叫外部类，后者叫内部类，按照内部类定义位置，可以分为四类：

- 成员内部类：private class AClass：（一般情况下，访问权限使用私有，原因：作为成员变量时，一般只是给自己使用，从而通过内部类实现”多继承“：在内部类使用继承，获取额外的方法处理外部类属性）
- 静态内部类：static class  BClass（一般情况下，访问权限使用包内，原因：使用更小权限时，会导致外部无法通过 "外部类.内部类" 的形式进行直接访问；使用public会使作用域过大）
- 局部（方法）内部类：定义在方法内部：（没有访问权限关键字，因为内部类的作用域只在该方法中，并通过内部类实现“多继承”，通过在方法中创建该对象来使用）
- 匿名内部类：对接口进行实例化，作为对象使用；

```java
	//成员内部类
	private class ClassA{
		//属性和行为
	}
	
	//静态内部类
	static class ClassB{
		//属性和行为
	}

	public void test(){
        //匿名内部类
		Runnable runnable = new Runnable() {
			public void run() {
				//行为代码
			}
		};
        
        //局部内部类
        class ClassC{
            //属性和行为
        }
    }        
```

2、四种内部类对外部类属性和行为的访问：

- 对于成员、匿名、局部内部类，编译器会隐式创建外围类对象的引用，从而在内部类中可以直接使用外部类变量和方法；当出现内部类中的变量名和外部类重名且类型相同时，会默认都使用内部类，可以通过外部类名.this.变量名区分，但是为了方便一般避免重名
- 对于静态内部类，只能直接访问外部类的静态方法和成员，而非静态则需要通过创建外部类对象进行访问

- 由于匿名内部类（也可以存在为外部类的成员变量初始化中）和局部内部类都存在于外部类方法中，因此可能需要对方法作用域中的变量进行操作，此时就需要保证操作的变量被final修饰，原因：

  内部类的生命周期和外部类方法是不一样的，当方法执行完后，内部类并不会销毁；此时该变量就会随着方法被销毁，为了解决这个问题，内部类在获取该变量时，会对该变量引用进行copy（基本类型则创建变量直接指向值的内存空间），此时就需要保证当前引用/内存空间的值不发生改变，才能满足代码逻辑。因此需要使用final对变量进行修饰

3、四种内部类使用场景：

- 成员内部类，保证类的高内聚同时，单纯的实现多继承，实现灵活的代码，并提供给外部类使用
- 局部内部类，在成员内部类的基础上，进一步缩小内部类的作用域，只提供给单个方法使用

- 匿名内部类,创建对接口实现类的同时，直接获取该类的实例对象.从而更加简洁方便的创建接口具体实现类对象,并实现内部类对外部类成员的访问
- 静态内部类，表示了该内部类不依赖于外部类而存在，外界可以直接进行访问；其中可以使用main方法，从而使用静态内部类进行单元测试，再打包时删除静态内部类的class文件，不让生产代码有过多的注解冗余
- 非静态内部类不能创建静态变量和方法；而静态内部类可以创建静态变量和方法；静态内部类，严格意义上就是一个外部类，只是为了满足类的单一职责设计原则，让它隐藏在外部类中，属于它的一部分，只给外部类使用；但是又可以直接单独实例化调用（即披着内部类的外衣，对外声明，但又可以直接调用，只是在类型上，会表明为是某某类的内部类）

4、所有内部类在编译时，都会生成class文件，命令方式如下：

成员内部类和静态成员内部类：  OuterClass$innerClass.class

匿名内部类： OuterClass$1.class 使用数字按顺序代指内部类

局部内部类：OuterClass$1innerClass.class 在内部类类名前面添加数字代指方第几个方法

5、内部类的闭包特性：

- 闭包：通过一个可以调用的对象（内部类），来保存    它被创建时所在的作用域  中的一些信息（如获取外围类成员变量）

- 作用：

1、对于匿名、局部内部类，实现作用域的数据共享，通过将当前数据赋值给一个final变量，从而内部类就能获取到此变量副本，从而使该变量的声明周期延长

2、对于成员内部类，可以延长外部类的生命周期，并更简单的实现java回调

```java
//老板类
public class BossTest {
	// 员工类
	private class EymTest {
		public void work() {
			System.out.println("员工开始工作");
			try {
				Thread.sleep(3000L);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
			endWork(); //通过内部类特性，回调外部类方法
		}
	}

	public void sentWork() {
		EymTest eymTest = new EymTest();
		eymTest.work();//调用内部类方法
	}

	public void writeWork() {
		for (int i = 0; i < 10; i++) {
			System.out.println(i + "s");
			try {
				Thread.sleep(500L);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
	}

	public void endWork() {
		System.out.println("上个工作结束，进行下一步指示");
	}

	public static void main(String[] args) throws InterruptedException {
		BossTest bossTest = new BossTest();
		Thread thread = new Thread(() -> bossTest.sentWork());
		thread.start();//异步进行内部类的方法调用
		bossTest.writeWork();//主线程执行其他方法
	}
}
```

#### 2.3.4、访问权限

| 访问权限控制符 | 访问权限            |
| -------------- | ------------------- |
| public         | 任何地方            |
| protected      | 同包所有类+包外子类 |
| 无             | 同包所有类          |
| private        | 当前类下            |

访问权限控制符的使用：

**在满足修饰对象（方法、属性、内部类）的使用下，尽量降低修饰对象的访问权限**

#### 2.3.5、this和super关键字

- this：

  1、用于访问当前对象的属性和方法（如 this.name）

  2、用于作为构造方法，在另一个构造方法中实现代码重用（如 this()）

  3、单独使用时，可以代指当前对象（如同步锁使用this）

- super：

  1、用于调用父类的构造方法（使用默认构造器时，会隐式添加super（））

  2、用于访问当前对象父类的属性和方法（如 super.name，属性和方法必须是可继承的）

**this和super关键字，在构造方法中出现时，必须有且只能有一个，并且存在于构造方法的第一行**

#### 2.3.6、类关系

| 类型 | 关键字                             | 关系       | 示例                               |
| ---- | ---------------------------------- | ---------- | ---------------------------------- |
| 继承 | extends                            | is-a       | 小狗类继承动物类                   |
| 实现 | implements                         | can-do     | 小狗类实现狗叫接口                 |
| 组合 | 类的成员变量（生命周期和类一致）   | contains-a | 小狗类包含狗头类这个对象属性       |
| 聚合 | 类的成员变量（生命周期和类不一致） | has-a      | 小狗类有狗绳这个对象属性           |
| 依赖 | import                             | use-a      | 人实现喂养小狗，将小狗作为依赖使用 |

组合比聚合的整体关系更强，它的部分是随着整体一起产生、一起消亡，共同实现一个功能；而聚合只是在整体创建时，将部分放入其中，部分的初始化和消亡与整体无关

#### 2.3.7、类的序列化

内存中，数据对象只能转换为二进制才能进行持久化和网络传输。而将数据对象转换为二进制流的过程就叫做对象的序列化；反之，将二进制流转化为数据对象的过程称之为反序列化。

​	1、序列化优化方向：

序列化需要保留充分的信息来恢复数据对象，但又需要节约存储空间、网络带宽，并满足高频率的转换需求，因此需要有**更好的转换性能和能转换为更小的二进制流**

​	2、java常见序列化方式：

- JAVA原生序列化，通过类实现Serializable接口来实现该类的可序列化。该方式保留了对象类的元数据（类、成员变量、继承类信息等），以及对象数据；兼容性最好，但不支持跨语言，并且性能一般

  同时实现Serializable接口的类需要设置serialVersionUID字段值，定义该类序列化和反序列化时的唯一ID，用于在程序在接收序列化的二进制流时，可以通过serialVersionUID来匹配自己对应的可以序列化类，进行反序列化转换；因此在两个系统通过java原生序列化方式进行对象传递时，需要保证两个系统中，该类的serialVersionUID值保存一致

  当不默认指定serialVersionUID值时，java会自动更加当前类的数据，生成一个；因此当两边系统其中一方添加额外字段后，就会导致两边类的serialVersionUID值不一致，出现序列化失败

  因此一般情况下，不推荐使用java原生序列化

- Hessian序列化，是一种支持动态类型、跨语言、基于对象传输的网络协议，java对象序列化后的二进制流可以被其他面向对象编程特点的语言（c++、Python）反序列化。Hessian协议有如下特性：

  1、自描述序列化类型，用一个字节来表示常用的基础类型，极大地缩短了二进制流

  2、与语言无关，支持脚本语言（JS）

  3、协议简单，比java原生序列化高效

  缺点：Hessian会将复杂对象所有属性存储在一个Map中，进行序列化。对于父类和子类出现同名变量成员时，Hessian序列化会先序列化子类，然后序列化父类，导致子类同名成员变量值被父类覆盖

- JSON序列化，是一种轻量级数据交换格式，JSON序列化就是将数据对象转换为JSON字符串，序列化中抛弃了类型信息，因此在反序列化时，需要手动指定转换的类型。JSON可读性比较好，方便调试

3、序列化攻击：

序列化通常使用在网络传输中，而往往对象数据中会有敏感信息，因此常常被黑客攻击获取利用。因此对于不需要进行传输的对象数据，可以通过transient关键字进行屏蔽

并且黑客会常常利用序列化工具的漏洞，来构造恶意二进制数据，使得程序在反序列化时出现错误，甚至出现OOM，如fastjson、jackson等序列化类库都出现过反序列化漏洞

### 2.4、方法

#### 2.4.1、方法签名

方法签名包括方法名称和参数列表，这是JVM标识方法的唯一索引，不包括返回值、权限访问符等（在使用方法时，使用者**不一定需要方法返回值/或者使用两种方法返回值的共同父类变量接收**，因此使得代码在阅读时，如果返回值也作为方法标识，则就不知道调用的哪个方法），示例：

```
int f(){
    return 1;
}

double f(){
    return 1d;
}

Number a =f();//此时number父类接收，就无法知道调用的是哪个方法，
```

#### 2.4.2、方法参数

​	1、在方法中，参数叫做parameter，在框架注解中，常使用prarm单词作为参数注解，如mybatis预编译时的参数注入；

​	2、方法形参和实参

​	方法参数分为形参和实参；形参为方法定义阶段，实参为方法实际调用时，传递到方法体中的参数；即是将实参值传递给形参，作为方法变量参数方法体的执行；当方法体中出现形参和实参名相同时，更加最近原则，会使用形参进行操作；并且实参传递给形参值的过程，无论是基础数据类型还是引用类型，都是进行值的复制，即实参和形参执行的内存地址不一样，只是值相同。

​	3、可变参数

​	JDK5中引入了可变参数，用于解决反射机制和printf方法问题，使用于不确定参数个数的场景；如printStream类中的printf方法，对多个字符串进行同时打印，定义方式为  参数类型 ...;但由于可变参数过于灵活，极大的影响了代码的可读性和可维护性，因此一般情况下，尽量不要使用，一定要使用则满足

- 只有参数类型相同，且多个参数的业务含义相同的参数，才能作为可变参数

- 方法中只能使用一个可变参数，且放在方法最后

- 不要使用Object类型作为可变参数

  4、参数预处理

  方法定义后，并不能保证调用者传入预期的参数值，为了保证方法的正常运行，需要对参数进行预处理：

- 入参保护：对于一些批量插入的方法，需要对参数量进行上限设置，放在数据处理量过大，影响系统正常使用
- 参数校验：对参数值进行特定的校验，保证参数值符合方法的正常处理条件。使用场景比入参保护要多得多，但是对于频繁调用的代码，会大大降低代码性能

#### 2.4.3、构造方法

构造方法是一个特殊的静态方法，用于对象的实例化。有如下特定：

1、方法名和类名相同、并且没有返回类型（也不能使用void）而是返回当前类的对象；

2、构造方法不会因为public而被子类继承、重写和直接调用，只能通过super、new 关键字、反射进行调用

3、类在创建时，会隐式创建一个无参构造方法；当手动定义有参构造方法，则会被覆盖，只能手动显式定义

4、构造方法可以为private，用于防止类在外部被实例化（如单例）

#### 2.4.4、类中的方法类型

在面向过程的语言中，所有方法都为全局静态方法，在面向对象之后，方法归属于具体的类。类中方法除了构造方法外，还有3类：

1、实例方法：又称为非静态方法，只能通过类的实例进行调用；并且在class文件在加载后，并不会分配方法对于外部调用的入口地址，只有在对象创建后，才会被分配；因此在类实例化前，只能被内部方法调用（即构造方法）

2、静态方法：又称为类方法，类加载后，即分配相应的内存空间，并且静态方法中不能使用实例成员变量和方法；也不能使用super、this关键字

3、静态代码块：同时也存在非静态代码块，但是一般不推荐使用（会在实例化时提前到构造方法中执行，优先于构造方法中的代码，但可以直接使用private的实例方法替代，阅读性更强）；静态代码块会在类加载时，就被调用，并且只会执行一次，一般配合静态变量赋值使用

#### 2.4.5、getter/setter方法

​	getter/setter方法仅提供了对类成员属性的读取和修改，满足面向对象语言封装特性，尽可能的将属性定义为private，使用getter/setter方法进行属性的访问和修改，而不是直接对类属性进行修改，这样也有利于统一控制，对类属性的访问和修改，如在一些使用反射功能的框架中。

​	最典型使用getter/setter方法的类，是POJO（plain ordinary java Object 简单普通的JAVA对象）。只包含getter、setter、toString方法，常见pojo类包括DO(Domain Object)、BO（Business Object）、DTO（Data Transfer Object）、VO（View Object）、AO（Application Object）

#### 2.4.6、重写和重载

重写：子类对父类方法重构，来满足子类的需求

重载：同一方法名，有不同参数列表的方法，本质上是不同方法（因为方法签名不同）

动态绑定：对象实例化时，可以使用父类类型变量进行接收，只有当创建具体实例化对象时，变量才会绑定对应的方法入口地址；JVM使用一个方法表来存储所有可实例化类的方法入口地址，每个类都有自己的对应的方法表数据，当子类继承父类时，则会绑定从父类继承的方法入口地址，对于重写的方法则会保存自身的方法入口地址。

向上转型：当使用父类类型变量接收子类实例化对象时，通过动态绑定，从JVM方法表中获的父类所有方法入口地址，然后查看当前实例化子类是否有重写方法，有则会代替掉父类对应的方法入口地址

### 2.5、泛型

泛型的本质是类型参数化，解决不确定具体对象类型的问题

在java引入泛型之前，使用Object来代表可变类型，然后再通过强转来获的响应对象，这样既大大降低了代码的可读性，又会存在强行转换时的类型转换风险。而泛型就完美解决了这个问题，将类型参数化，从而实现通过不同类型参数，进行不同的处理并返回对应类型的返回值

```java
public <T> T test(T s){
    return s;
}
```

泛型常与集合一起使用，定义集合保存的对象类型，有利于集合使用（在获取集合对象时，可以显式获取当前集合保存的对象类型）

### 2.5、数据类型

#### 2.5.1、基础数据类

java提供八种基础数据类型，指不可再分的原子数据类型，在内存中直接存储此类型的值；包括有：boolean、byte、char、short、int、long、float、double；除了这八种基础数据类型外，java还隐式使用了另一个原子数据类型refvar，它就是面向对象类型的引用变量，也叫引用句柄。该类型代表了引用对象的引用，保存了对象的在堆中的内存地址

| 序号 | 类型名称 | 默认值    | 大小 | 最小值    | 最大值      | 常量池缓存区间 |
| ---- | -------- | --------- | ---- | --------- | ----------- | -------------- |
| 1    | boolean  | false     | 1B   | 1（true） | 0（false）  | true、false    |
| 2    | byte     | （byte）0 | 1B   | -128      | 127         | -128~127       |
| 3    | char     | '\u0000'  | 2B   | ’\u0000‘  | ‘\uFFFF’    | 0~127          |
| 4    | short    | short(0)  | 2B   | -2^15     | 2^15 -32767 | -128~127       |
| 5    | int      | 0         | 4B   | -2^31     | 2^31-1      | -128~127       |
| 6    | long     | 0L        | 8B   | -2^63     | 2^63-1      | -128~127       |
| 7    | float    | 0.0f      | 4B   | 1.4E-45   | 3.4e+38     | 无             |
| 8    | double   | 0.0d      | 8B   | 4.9E-324  | 1.798e+308  | 无             |

对于char的初始值，表示为NUL，即一个空的不可见字符，转换为int就为0；由于0默认为int类型，因此其他类型默认值虽然是0，但需要做强行转换，或特殊表达



​	refvar引用指向对象，简称为refobj。refvar默认值为null，存储refobj的首地址；无论是那种对象的引用，refvar都占用4B空间；而refobj占用12B，用于存储对象基本信息，即对象头，但由于内存分配必须为8B的倍数，因此refobj初始化空间最少为16B；如Integer包装类，refobj对象基础大小为12B，内部成员int占用4B，因此Integer实例化后，占用16B内存空间；同理Double对象占用24B

对象内存存储结构：

1、对象头(Object Header),占用12字节，存储内容包括对象标记和类元信息，其中对象标记存储对象本身运行时的数据，如哈希码、GC标记、锁信息、线程关联信息等，占用8字节；而类元信息存储的是对象的类元数据首地址，和refvar开销一致，占用4个字节

2、实例数据，存储对象实例化的成员变量、和所有可见父类成员变量

3、对象填充，对于前两个占用内存空间总和不会8B倍数时，自动填充使总占用内存为8B的倍数

![](C:\Users\OneMTime\Desktop\Typora图片\对象内存存储结构.jpg)

#### 2.5.2、包装类型

java对八种基本数据类型提供相应的包装类，从而以对象形式进行基础数据的操作，如泛型参数化、序列化、类型转换、数据缓存等。

包装类提供了缓存功能，当对包装类对象直接赋值时，默认调用了valueOf()方法，该方法会先判断缓存区间是否存在该值，没有则通过new来创建该对象（JDK9中，将包装类的new方法标记为过时，推荐使用valueOf（）来合理利用缓存）。但是Float和Double除外，它们没有缓存区间；另外Integer可以通过VM参数，来对缓存区间进行修改，从而提高对Integer类型的缓存能力

**当相同值的基础类型和包装类进行==比较时，不管包装类时new，还是使用常量池，都会自动进行拆箱处理，即使用栈中的值，因此比较会全部相等；而对于相同值的包装类比较，就需要判断两者是使用堆空间还是常量池；因此对于包装类的比较，应该使用equal（)方法**

#### 2.5.3、字符串

String是最常用的数据类型，但它本身还是对象，但JVM对其进行了优化，从而使对String直接赋值时，也可以使用常量池进行缓存，使得直接赋值和new赋值内存空间绝对不可能相同（因此基础类型包装类，缓存池只有-128-127，而String则没有限制）

## 3、代码风格

具体参考阿里巴巴JAVA开发手册（java代码规范）

## 4、走进JVM

​	JVM：java虚拟机，一个虚构出来的计算机（符合计算机架构规范），但可以运行在实际计算机上，提供模拟各种计算机功能；

JVM屏蔽了java代码在具体计算机硬件平台运行的相关细节，而是统一基于JVM进行运行，实现“一次编译，到处运行”，从而实现JAVA跨平台特性

### 4.1、字节码

#### 4.1.1、机器码：

​	计算机只能识别0与1的信号，所有计算机底层指令都是通过0和1组合构成的，这些组合的代码也就叫做机器码，它们是离CPU指令集最近的编码，可以直接被CPU解读，但这样也使得机器码与计算机底层硬件系统有很高的耦合

#### 4.1.2、字节码：

​	但是用机器码时，一个程序就会因为运行的硬件平台的不同，编写多套代码；因此就需要一个中间码，来阻断程序代码和硬件系统的耦合。JAVA就提供这种中间码，也叫做字节码。

​	Java所有指令有200个左右，一个字节（8位）可以代表256种信号，刚好满足所有指令编码需要，所有java使用一个字节来存储表示所有的指令。也因此被称只为字节码(ByteCode)

#### 4.1.3、class文件：

​	java通过编译java文件，获的class文件，即二进制的字节码文件。初始的4个字节非常特殊，为cafe babe 0000 0037， cafe babe 为魔法数，意思为coffee Baby，用于标记该文件为java的class文件，没有则无法被JVM执行；0000 0037 为当前class文件编译使用的JDK版本号

#### 4.1.4、字节码所表示的java指令集：

1、加载/存储指令

​	在栈帧（Stack Frame）中，通过指令操作数据在虚拟机栈的 **局部变量表**与**操作栈**之间来回传输，常见指令如下：

1. 将局部变量加载到操作栈中:ILOAD(将int类型变量值压入栈)、ALOAD（将对象引用 变量值压入栈）

2. 从操作栈顶存储到局部变量表：ISTORE、ASTORE

3. 将常量加载到操作栈顶：在指令集操作中，常量只能为整数和字符串（**也因此8中基础数据类型中浮点数没有常量池**），根据分为分为如下几种：

   | 指令   | 操作常量值范围                            |
   | ------ | ----------------------------------------- |
   | ICONST | -1~5                                      |
   | BIPUSH | -128~127（1个字节）                       |
   | SIPUSH | -32768~32717（2个字节）                   |
   | LDC    | -2147483648~2147483647（4个字节）和字符串 |

2、运算指令

​	对操作栈上的两个值进行运算，并将结果写入操作栈顶:IADD、IMUL（int类型值的加减法）

​	对局部变量表的值进行自增、自减：IINC、IDEC（int类型值）

3、类型转换指令

​	显式转换两种不同的数值类型：I2L\D2F（int转long、double转float）

4、对象创建与访问指令

​	根据类进行对象的创建、初始化、方法调用，常见指令如下：

1. 创建对象指令：NEW、NEWARRAY（对象创建、对象数组创建）
2. 访问属性指令：GETFIELD、PUTFIELD、GETSTATIC
3. 检测实例类型指令：INSTATNCEOF\CHECKCAST

5、操作栈管理指令

​	JVM提供直接控制操作栈的指令，常见指令如下：

1. 出栈操作：POP
2. 赋值栈顶元素并压入栈:DUP

6、方法调用和返回指令

1. 调用对象的实例方法：INVOKEVIRTUAL
2. 调用实例初始化方法、私有方法、父类方法：INVOKESPECIAL
3. 调用类静态方法：INVOKESTATIC
4. 返回void类型:RETURN

7、同步指令

​	用于表示当前栈帧中的同步区域:ACC_SYNCHRONIZED

###栈帧：是实现函数调用的一种数据结构，在栈中保存函数被调用时的 返回地址和参数、临时变量、函数调用的上下文；其在虚拟机栈中的出栈入栈，也就代表了一个方法的执行过程。

​	操作栈：存在于一个栈帧中，初始状态为空的栈结构，用于方法执行时的临时数据进行缓存

#### 4.1.5、字节码生成过程：

java文件是源代码文件，并不能直接交给JVM运行，必须先进行源代码编译生成字节码，通过静态编译器实现：

![](C:\Users\OneMTime\Desktop\Typora图片\字节码生成过程.jpg)

1. 首先通过java词法解析器，获取源代码中所有单词、操作符、控制符等各种信息，通过token流传递给java语法解析器
2. 语法解析器会将获取的token信息流按照java语法规定，组装成一棵语法数
3. 然后通过语义分析，来检查语法树中是否有关键字使用不合理、类型不匹配、作用域不正确的地方（IDE在代码编写时，会自动进行以上三步完成编译性检查，当不打开自动编译功能时，不会生成字节码，也可以关闭编译性检查）
4. 最后生成字节码

#### 4.1.6、字节码的三种执行模式：

​	字节码必须通过 类加载过程  来加载到JVM环境中，才可以被执行。执行有三种模式

1. 解释执行 :对于需要运行的字节码，进行一行行解释，将其转换为JVM中的java指令，交给JVM执行，即边解释边执行，速度会很快，但是相同字节码都需要重复进行解释

2. JIT编译执行：先通过JIT动态编译器，将要执行的字节码统一转换为java指令，然后再交给JVM执行；它会保存该段字节码编译后整套java指令，当再次执行该段字节码时，则直接使用存储的指令；虽然整个过程执行速度会慢一点，但是可以重复利用，对于频繁执行的代码，执行速度会有很大提升

3. JIT编译与解释混合执行（JVM默认执行方式）：首先在代码刚启动时，使用解释执行，减少不必要的编译时间，随着时间的推移，JVM通过热点代码统计分析机制，识别出了高频的方法调用、循环体、公共模块等。它们再次进行执行时，就会使用JIT动态编译技术，将字节码编译成java指令

   ###JIT：just-in-time compilation ，实现java字节码的动态编译，从而进行重复即时使用；并且根据JIT编译器的不同，可以对于转换的java指令进行一定程度的优化

   - **JVM字节码混合执行过程：**

     ![](C:\Users\OneMTime\Desktop\Typora图片\JVM混合执行过程.jpg)

由于JVM的混合执行机制，服务器的热机负载要大于冷机负载；因此在进行切流转换（将一个服务器中的处理数据，转移到其他服务器进行处理）时，如当前新服务器没有运行过该流量的处理代码（冷机），则需要进行分批切流（将部分数据先交给新服务处理一段时间，然后再进行交一部分。。。）

### 4.2、类加载过程

#### 4.2.1、类加载过程：

​	在冯 · 诺依曼的计算机模型中，任何程序都需要加载到内存中，才能与CPU进行交流。对于字节码（.Class文件），同样也需要加载到内存中，才能实例化类。字节码的加载过程也叫做**类加载过程**

​	类加载过程分为三个阶段，Load、Link、Init，即加载、链接、初始化

1. Load阶段：读取类文件对应的二进制流，将其转化为特定的数据结构，初步校验cafe babe魔法值（证明该.class文件的二进制为字节码）、常量池、文件长度、是否有父类等，然后在堆中创建类对应的java.lang.class实例（即该类的class对象）

2. Link阶段：有三个步骤：验证、准备和解析。验证是对数据进行更详细的校验，如final是否符合规则、类型是否正确、静态变量是否合理等；准备阶段是为静态变量分配内存空间，并设定默认值（默认值是对应数据类型的初始默认值，此时并不会进行代码中的显式赋值，但是对于static final，在编译阶段就进行了优化，将其结果放入了常量池，此时就会直接赋值）；之后解析类和方法中的符号引用，将其转换为直接引用，确保类与类执行相互引用的正确性。

3. Init阶段：执行类构造器方法：< clinit >（这个并不是类的构造方法）；对类中所有静态变量赋予正确的初始值，同时初始化赋值过程中，出现调用其他未初始化的类时，则会主动对该类进行初始化；

   - **对于所有类的加载，可以分为两种状态：完成初始化和未完成初始化**

   - **当通过类加载器来获取某个类的class对象时，可以选择不进行类的初始化（一般情况下，初始化会和加载过程一起执行完）**

   - **对于没有任何静态变量和静态代码块的类，它没有< clinit >方法，也因此不需要执行初始化**

   - **类加载阶段，所有数据会被存入方法区，并在堆区存放一个class对象，通过class对象来获取方法区中，该类的元数据**

#### 4.2.2、类加载器：

​	**JVM通过ClassLoader(类加载器)，来完成整个类加载过程，注意几点：**

1. 在程序启动后，类加载器会预先加载将要使用的类（而不是等到该类需要使用时，才加载），当加载过程中出现错误时，并不会立即报错，而是在程序首次主动使用该类时才会报错

2. 类加载过程中，初始化时，会对该类所有未加载的父类进行同步类加载（即要保证父类优先被加载）

   **java自带三个不同层级类加载器，分别为：**

   1. Bootstrap ClassLoader（启动类加载器），为最高级别的加载器，在JVM启动时创建，通常加载与操作系统相关的本地代码（核心java类库），JRE\lib下的rt.jar、resources.jar等，其中包括如Object、System、String等类文件

   2. Extension ClassLoader（扩展类加载器），JRE\LIB\ext\下的jar包，提供了如XML、加密、压缩等相关功能的扩展系统类文件

      ###在JAVA9后，改为Platform ClassLoader（平台类加载器），对Extension ClassLoader进行先后兼容的同时，改变了整个加载模型（模块化系统加载）

   3. Application ClassLoader（应用程序类加载器），加载当前工程目录（classpath）下的所有类文件

   第二、三层加载器为JAVA语言实现，通过如下方式进行查看：

   ```java
   	//获取Application ClassLoader
   	ClassLoader classLoader = TestA.class.getClassLoader();
   	//获取Extension ClassLoader，它是应用程序类加载器的父加载器
   	ClassLoader parent = classLoader.getParent();
   ```

   对于顶层加载器Bootstrap ClassLoader，它是由C/C++实现，并不存在与JVM体系中，因此无法有效获取其对象，它还实际还是Extension ClassLoader的父加载器；

   类加载器的父子级别，并不是java中的继承关系，子加载器只是通过组合的方式来复用父加载器中的功能。

#### 4.2.3、类加载器的双亲委派模型

​	JVM的所有类加载器通过双亲委派模型，同时一起实现整个程序的类加载器过程：

![](C:\Users\OneMTime\Desktop\Typora图片\类加载器的双亲委任模型.jpg)

1、首先当一个类加载器收到任务去加载一个类时，它先回查看自己是否加载过该类，没有则它会将请求委派给父类加载器完成（从而依次向上传递给最高级加载器Bootstrap ClassLoader），同时也询问父加载器是否进行过该类的加载

2、当整个向上传递过程中，都没有发现有哪层类加载器加载过此类时，此时就从Bootstrap ClassLoader开始尝试加载此类

3、如果Bootstrap ClassLoader无法加载，就将加载此类的请求交给子类加载器（从而依次向下传递，直到被某层类加载器加载）

双亲委派模型的好处：

- 保证了同一个类不会被多次加载（因为询问了所有类加载器，是否加载过）
- 每个类加载器只能加载自己范围内的类（所有加载类功能，都是通过组合方式扩展的，因此每一层加载器，都有合适自己加载的类）

#### 4.2.4、自定义类加载器：

​	用户也可以自定义类加载器，只需要继承java.lang.ClassLoader类，重写findClass方法

​	**自定义类加载器的使用场景：**

1. 隔离加载类。通过不同类加载器，来隔离区别同一应用中，不同模块使用的相同jar，从而创建出不同的JVM环境
2. 修改类的加载方式，如实现定时加载或动态加载
3. 扩展额外加载源，通过自定义加载器，来加载额外不同来源的二进制字节码，而不是单单读取本地jar包、class文件，如网络二进制流
4. 防止源码泄露,class文件容易被反编译，因此常常需要使用编译加密，而同时加载该字节码的类加载器也就需要进行自定义，从而还原加密的字节码
5. 自定义类加载器可以避免无用类元信息占用内存空间

### 4.3、JVM内存布局：

​	内存是硬盘和CPU的中间桥梁，承载着操作系统和应用程序的实时运行。JVM内存布局规定了java程序在运行过程中，内存申请、分配和管理策略，保证JVM的高效稳定运行。不同的JVM对于内存的划分方式和管理机制也存在显著差异。以最经典的JVM内存布局为例：

![](C:\Users\OneMTime\Desktop\Typora图片\JVM内存布局.jpg)

#### 4.3.1、Heap（堆区）：

​	几乎所有的实例对象都存储在Heap（**会由于JIT的逃逸分析，将对象分配到虚拟机栈中**），它们通过Heap中的垃圾收集器（GC）自动回收，并且Heap中的存储数据可以由各个子线程同享使用

​	通常情况下，Heap是jvm内存空间占用最大的区域，当无节制地创建大量对象时，会很快消耗完所有空间，导致OOM故障发生（也是OOM最主要的发源地）。堆的内存空间既可以固定大小，也可以在运行时动态调整，可以通过设置JVM运行参数来调整：比如 -Xms256M -Xmx1024M ，-X代表了它是JVM运行参数，ms（memory start  开始内存）代表了最小堆内存容量；mx（memory max 最大内存）代表了最大堆内存容量；但是通常情况下，服务器在运行过程中，对空间会不断的扩容和回缩，因此如果一开始就设置一个较小内存空间上限的限制，会导致不必要的系统压力，因此一般生产环境，JVM的Xms、Xmx的大小一样，避免GC调整堆大小时，带来额外压力

- **堆区内部空间划分：新生代（Young区）、老年代（Old区），其对象内存分配规则如下：**

1. 一般情况下，当对象刚创建时，会存储在新生代，存活一定时间后，就会转移到老年代
2. 新生代又分为 1个Eden区+2个Survivor区，绝大部分对象在Eden区生成，当Eden区被占用完时，触发Young Garbage Collection，即YGC（新生代垃圾收集）。在进行YGC时，会将Eden区没有引用的对象直接回收，而依然存活的对象移动到Survivor区
3. Survivor区一共有两块内存空间（S0、S1），当进行YGC时，只使用其中一块，并把前一次使用的另一块空间的存活对象转移到当前空间的（即总保证其中一个Survivor区没有使用，并清理其需要回收的对象）
4. 在进行YGC，将对象从Eden区转移到其中一块Survivor区（或将另一个Survivor区存活对象转移到当前区）时，如果出现对象大于Survivor区容量上限时，会将对象直接放到老年代（**当大对象创建后无法放入Eden区时，就会触发YGC,此时清空后的Eden区还是无法存放，则放到老年代，因此会出现大对象直接在老年代中存储**）；
5. 对于在2个Survivor区一直存活的对象，在每进行一次YGC进行对象转移时，会对其进行移动计数，当到达阈值后，直接将其转移到老年代
6. 当老年代尝试分配对象内存空间，出现无法放下的情况时，则会触发Full Garbage Collection（完整垃圾收集），即FGC，对整个堆区进行垃圾回收。如果还是无法放下，则抛出OOM

![](C:\Users\OneMTime\Desktop\Typora图片\堆区对象内存分配规则.jpg)

​	当抛出OOM后，可以通过获取堆内信息来分析原因，通过添加JVM运行参数来实现：

-XX：+HeapDumpOnOutOfMemoryError，这对于java程序几个月就会发生OOM异常的实际场景的问题解决尤为重要

- **堆区进行分区的目的：对对象有针对性的选择CG算法，新生代使用复制算法、老年代使用标记-整理算法**

#### 4.3.2、Metaspace（元空间）：

​	以Hotspot版本的JVM为例，元空间出现在JDK8中，在JDK7及之前版本，元空间的前身为Perm区，又叫永久代，是一个**单独的堆空间**，用于存放类的一些元数据（**类元信息、常量池**）。（**在自定义加载器没有普遍使用之前，JVM自带的加载器很少对类信息进行卸载和回收，因此一般这些信息都是永久存储，也就叫永久代**）

​	永久代和老年代的垃圾回收是绑定在一起的，只要其中一个空间被占满，就会触发FGC，进行垃圾回收；由于perm区大小在JVM启动时就固定，在类加载很多的情况下，会导致OOM或者垃圾回收触发频率过高(并且效率非常低)，对于这种情况，只能将perm区设置大一点，这样也就比较难调优，浪费内存分配额，并且当项目转移时，新开发人员由于不知道之前的perm区大小设置，而浪费大量时间分析bug(oom原因)

- 在JDK7中，对于永久代做出了优化，降低了永久代出现OOM的风险


1. 将符号引用（Symbols）移至native heap（本地内存），**##符号引用：使用字面量来代替当前类中对其他类及其字段、方法的引用，即类的类型信息所用的常量池**；
2. 字面量（String常量池和其他常量池）和静态变量移动到 heap堆区

- 在JDK8中，直接使用元空间代替永久代，让这块内存空间能够动态扩展，并且移除了永久代对FGC频繁触发的影响

  ​	和之前的永久代一样，只存储类的元数据信息，但是元空间并不在虚拟机中，而是使用native heap（本地内存），因此在默认情况下,元空间的大小只会受到本地内存的限制；当然也可以通过

  -XX:MetaspaceSize、-XX:MaxMetaspaceSize，来设置元空间使用的初始值和最大值

  **无论是永久代还是元空间，它们都是对JVM方法区规范的一种具体实现。方法区存储的具体内容包括：**

  **1、类基础信息：**

  - 类型信息：类名、父类名、实现接口名列表、类标志（class/Interface）、类修饰符
  - 类型信息所用的常量池（**Class Constant Pool** ）：存放**当前类基础信息**中，使用到的所有直接常量和对于**其他类型、字段和方法的符号引用**
  - 字段信息：字段修饰符、字段类型、字段名称
  - 方法信息：方法修饰符、方法返回值类型、方法名、方法参数、方法体字节码、方法对应栈帧的操作栈和局部变量区大小、异常表

  **2、类变量：**

  即类的静态变量,包含变量名、变量类型、变量值（在类加载时，进行了默认值赋值，之后还进行了初始化）

  **3、类相关对象的引用：**

  - 其加载时使用的类加载器的引用
  - 其加载创建对应class对象实例的引用

  **4、方法表：**

  用于动态存储当前类下，所有方法信息的入口地址（引用）

  **5、运行时常量池（Runtime Constant Pool）:**

  包含所有基础数据类型（浮点数类型除外）和String类型的常量池。在常量池缓存区间内，所有基础数据类型、及其包装类和String类型（不能为new），相同值变量存储同一个内存空间地址

#### 4.3.3、JVM Stack（虚拟机栈）：

​	栈是一个先进后出的数据结构，每次只能访问最顶端的数据。对于实际计算机，使用寄存器来实现对CPU计算数据的缓存，而JVM使用栈结构来实现。原因：

1. 对于寄存器，会存在平台没有或很少的问题，并且不同寄存器，其数据结构和规律也有很多差异，无法设计一个通用的基于寄存器的指令
2. 对于栈结构，它的数据结构简单固定，因此执行过程所依赖的指令集更少，编译器也就更容易实现，可控性更强
3. 由于栈结构不依赖于硬件，直接可以通过JVM实现，有很好的移植性更好（当然也就损失了一定性能）

​	对于虚拟机栈，它是java方法执行的内存区域，并且线程私有的。用于支持JVM进行方法调用，每一个方法在开始调用到执行完成的过程，就是虚拟机栈中元素栈帧入栈和出栈的过程。在一个活动线程中，只有位于虚拟机栈顶的栈帧才是有效的，称为当前栈帧。栈帧是方法运行的基本结构，所有JVM指令只会对当前栈帧进行操作，当方法正常执行完后，则会进行出栈，然后进行对下一个栈帧进行操作。**栈帧主要包括以下几个部分：**

1. 局部变量表

   用于存放方法参数和局部变量，相对于类属性变量，没有准备阶段（即没有默认值），因此必须显示初始化。并且对于非静态方法，需要在index[0]存放方法所属对象实例引用	

2. 操作栈

   是一个初始状态为空的栈结构，在方法执行过程中，通过指令集来对操作栈进行数据读取、写入，实现CPU计算数据的缓存，因此JVM的执行依赖于操作栈。每一个方法对应栈帧中，都有一个独立的操作栈，而栈的大小由方法元信息中的stack属性决定

   - 对于i++、++i，在虚拟机栈中执行过程的体现和区别：
     - 对于i++,首先是从局部变量表中获取变量i的值，并压入操作栈中，然后执行IINC指令（**IINC指令是在局部变量表中执行完成的**），局部变量表中的变量i的值+1，但此时操作栈中的值没有发生变化，之后出栈值任然为原来的
     - 对于++i，首先在局部变量表中执行IINC指令，然后局部变量表中获取变量i的值，此时出栈值为变化的值

3. 动态连接

   **每个栈帧中，保存了当前方法的符号引用，在方法被调用创建栈帧时，就通过该符号引用从方法表中获取方法信息的入口地址，实现动态调用**

4. 方法返回地址

   方法返回地址，在方法被调用前，保存PC计数器的值（当前指令执行所在的内存空间地址），当方法调用正常执行后，通过该返回地址，来将返回值放入上层调用栈帧的操作栈中，并调整当前PC计数器值,指向方法调用指令后面的一条指令

   方法执行时有两种情况。第一，正常退出，即执行返回指令（RETURN、IRETURN、ARETURN）；第二，异常退出；不管何种形式，方法退出过程都相当于弹出当前栈帧，之后又三种方式：

   - 正常退出，通过方法返回地址，将返回值交给调用者，并向后执行
   - 异常退出，返回地址交给异常处理器确定，将异常信息抛给能处理的栈帧，而不去使用方法返回地址来交给调用者处理
   - 没有返回值的正常退出，直接通过方法返回地址，调整PC计数器值,指向方法调用指令后面的一条指令

- 当单个线程的请求需要的虚拟机栈深度大于JVM允许的栈深度时，会抛出StackOverflowError（栈溢出错误），**即每个线程的虚拟机栈分配的内存空间是有限的，最大深度，但在运行中是进行动态分配的**。如递归，就会导致虚拟机栈不停的进栈，而不会出栈，最后使虚拟机栈的内存空间耗尽

- 方法中调用了其他方法，在虚拟机栈中的表现过程：

  1、执行该方法，创建其栈帧，压入虚拟机栈，并作为当前栈帧进行执行

  2、当运行到调用其他方法的指令时，创建该方法的栈帧，压入虚拟机栈，并作为当前栈帧进行执行

  3、在当前栈帧执行完后出栈，并将返回值放入上一个栈帧中（即第二个栈帧，且即将变为当前栈帧）

  4、原方法对应栈帧向上变为当前栈帧，进行执行

#### 4.3.4、Native Method Stacks（本地方法栈）：

​	本地方法栈和虚拟机栈类似，也是线程对象私有，但是本方法栈是为Native方法(本地方法)服务，不会受到JVM的约束。

​	本地方法是由其他语言编写（C/C++），编译成与平台处理器有关的机器码，保存在动态链接库中，每个平台都有自己专有的文件格式，如windows为.dll文件。JAVA通过**native关键字**来创建一个JNI（Java Native Interface）的方法，并通过本地方法来进行实现。本地方法在本地方法栈中执行时，能访问到JVM中的数据区，并能实现所有的java方法特性，如返回值类型、异常控制（但这要依赖于中间标准框架的解耦，相对于直接在java语言中使用，更加麻烦）

​	本地方法的使用场景：

- 当java需要对一些底层系统或某些硬件交换信息时，需要进行很繁琐的细节处理；而它们自己本身提供了该平台对应的接口，来进行这些操作，因此我们就可以直接利用java进行本地方法调用来实现，这样更加简单
- 对于操作系统，JVM支持java语言和动态链接库，因此通过本地方法来对动态链接库进行调用，实现了更全面的功能（完成java语言自身没有封装的操作系统特性），同时这些动态链接库一般基于C语言编写，执行性能更加强大

​	本地方法只有在调用时才会被加载（java类是预加载），通过java.system.loadLibrary()实现；JVM中的执行模式之一的解释执行，所使用的解释器是由C语言编写，因此它能够执行本地方法和外界环境进行交互，在JVM中已经实现了一部分的本地方法，如常用的system内中的部分方法

​	手动进行JNI实现的步骤：

1. 编写java类，使用native修饰方法，并手动加载该类所使用的本地方法（对于JVM中的本地方法，JVM会使用initializeSystemClass方法，进行隐式加载）
2. 使用javac编译java类
3. 使用javah命令生成，该class文件对应带有JNI标识的C\C++头文件
4. 使用C\C++编写c文件，实现本地方法，并且该方法定义，可以在javah生成的头文件中找到
5. 将c文件编译为动态链接库，然后java通过读取头文件数据，找到对应动态链接库中的本地方法进行加载

#### 4.3.5、Program Counter Register（程序计数寄存器）:

​	CPU只有将数据装载到寄存器中才能进行运算，而寄存器存储了指令相关现场信息，对于CPU的一个内核，只会执行某个线程中的一条指令，因此就会导致所有线程的执行，都是在不停的中断和恢复。对于JVM也是这样，此时就需要一个寄存器来保存当前线程的现场信息。JVM在创建一个线程后，会产生该线程对应的程序计数器和虚拟机栈，通过程序计数器来存放虚拟机栈的当前栈帧，指令执行所在的内存空间（通过执行治疗的偏移量和行号指示器确定）；**因此线程执行和恢复都依赖于程序计数器，并且各个线程之间互不影响，也不会发生内存溢出异常**

#### 4.3.6、JVM内存空间的线程安全：

![](C:\Users\OneMTime\Desktop\Typora图片\JVM内存空间和线程安全.jpg)

​	JVM的堆区和元空间是所有线程共享的，而虚拟机栈、本地方法区和程序计数器是线程内部私有的；但**JAVA提供ThreadLocal方式，将线程共享转换为线程私有，这也是java对象线程安全的实现方式**

### 4.4、对象实例化：

​	java是面向对象的静态强类型语言（当然可以通过继承来实现向上转型），必须指定一个类型来创建它的实例，才能够进行更多的操作（对于静态变量和方法，不需要通过创建实例来访问）

#### 4.4.1、实例化对象过程（字节码角度）：

以简单的object类，实例化为例（即 Object  object = new Object()），其实例化对象过程的字节码如下：

```java
stack=2,locals=1,args_size=0  //定义实例化方法，所需要的操作栈大小、局部变量表大小
    NEW java/lang/Object
    DUP
    INVOKESPECIAL java/lang/Object.<init> ()V
    ASTORE_1
    LocalVariableTable:
		Start  Length  Slot  Name  Signature
```

- NEW  java/lang/Object: 

  ​	获取Object类的Class对象（没有则进行类加载），根据Class对象，在堆中分配新对象的内存空间（包含所有的属性变量(赋予默认值)和新对象的引用变量（当前堆空间的入口地址）；空间分配使用CAS机制来保证线程安全），并将新对象的引用压入当前实例化方法的操作栈顶

- DUP: 

  ​	对象引用在操作栈中进行复制，栈顶引用用于调用< init>方法；另一个引用保存到当前栈帧的局部变量表中

- INVOKESPECIAL   java/lang/Object.<init> ()V：

  ​	执行栈顶对象引用中的 < init>方法，进入一个新的栈帧，将init方法参数压入新栈帧的局部变量表，然后进行方法代码执行

#### 4.4.2、对象实例化执行步骤（对象数据角度）：

- 确定类元信息是否存在：当JVM接收到new指令后，在元空间中查找该类的类元信息是否存在（即class对象）。不存在则通过双亲委派模型，使用当前类加载器进行class文件加载，生成class对象；

- 分配内存空间：通过class对象，计算实例化对象所占空间大小，在分配空间时，采用CAS保证内存分配的操作的原子性
- 设置成员变量默认值：根据成员变量类型，来设置它们的零值
- 设置对象头：设置实例化对象的哈希码、GC信息、锁信息和所属的class对象信息，这些信息具体实现方式是通过JVM来实现
- 执行init方法：初始化成员变量，并执行实例化代码块、调用类的构造方法

### 4.5、垃圾回收

​	JVM会对内存空间进行自动分配和回收管理，因此使得开发人员更加方便、安全的使用内存，实现程序逻辑；而不同的JVM由于堆内存的划分方式不一样，因此回收机制也有所不同。

#### 4.5.1、垃圾回收机制:

- **垃圾回收的目的：**

  ​	清除堆区中不再使用的对象，自动释放内存

- **垃圾回收机制(可达性分析)：**

  ​	JVM垃圾回收机制的关键，在于如何判断对象是否可以被回收，即对象是否存活。JVM引入GC Roots来实现，当一个对象与GC Roots之间没有直接或间接的引用关系时，则判断该对象可以被回收，如失去所有引用的对象、两个循环引用的对象等。GC Roots也是一个对象，当一个对象被创建时，JVM会将其类静态属性中的引用对象、常量引用的对象、虚拟机栈中引用的对象和本地方法栈中引用的对象 这四类对象选择一个作为该实例对象的GC Roots

- **垃圾回收触发和对应推荐的回收算法：**

  1. 当新生代内存空间占满时，会触发YGC，会将Eden区没有引用的对象直接回收，而依然存活的对象移动到Survivor区；此时推荐使用 **标记 - 复制算法（Mark-Copy）**，遍历所有的GC Roots，通过算法将和它们有引用关系的对象进行标记，最后将存活下来的对象（Eden区和使用的Survivor区）复制到未使用的Survivor区，清空Eden区；对于使用的Survivor区中存活时间过长的对象，转移到老年代

     优点：这样保证了GC不会产生内存空间碎片，减少内存空间的浪费；将标记和整理分为两个内存空间进行，使最后整理使用的内存空间连续

     缺点：为了实现这种方式，需要空留一半内存空间，**因此适合只存在少量存活对象的YGC中**

  2. 当老年代内存空间占满时，会触发FGC，对整个堆区内存空间进行GC；此时推荐使用 **标记 - 清除算法（Mark - Sweep）**，遍历所有的GC Roots，通过算法将和它们有引用关系的对象进行标记，然后将所有没有被标记的对象清除

     优点：由于不需要复制转移存活对象，重新分配内存空间，因此效率更高；所以使用在**需要大规模清除死亡对象的FGC中**

     缺点：由于只是对死亡对象进行清理，因此会导致出现大量的内存空间碎片，浪费内存空间、

  3. 正常情况下，只使用这两种算法，但是为了解决**标记 - 清除算法（Mark - Sweep）**的缺陷（即产生大量的内存空间碎片），因此还有一个优化算法：**标记 - 整理算法（Mark-Compact）**，在进行标记后，将存活对象移动到空白连续的内存区域，让后再进行清理，这样就会有空间碎片，但效率会慢一点

  **总体上，JVM会使用分代收集思想，新生代使用标记 - 复制算法（Mark-Copy）；老年代使用标记 - 整理算法（Mark-Compact）；**

#### 4.5.2、垃圾回收器：

不同的垃圾回收器，有不同的算法和执行方式。目前常见垃圾回收器:

1. **Serial回收器（分为新生代和老年代Serial Old ）：**

   单线程执行GC任务，YGC使用Mark-Copy；FGC使用Mark-Compact。单线程执行GC任务，因此无论何种算法执行过程中会导致STW（Stop the World整个应用程序停止）； 当频繁执行FGC时，会严重影响应用程序性能；

   特定：**单线程、简单高效，但STW时间较长，适合Client模式下的JVM**

2. **ParNew回收器：**

   多线程执行GC任务，使用Mark-Copy。默认使用同cpu核数相同的多线程并发执行GC任务，也会存在STW问题

   特点：**多线程并行收集，存在STW，可以和GMS组合使用，适合作为Server模式下JVM的新生代收集器**

3. **Parallel回收器（分为新生代和老年代Parallel Old ）：**

   多线程执行GC任务，YGC使用Mark-Copy；FGC使用Mark-Compact。虽然为多线程并行收集，但是收集策略核心在于以提供最优的停顿时间和最高的吞吐量

   特点：**多线程并行收集，存在STW，但可以手动优化控制最大停顿时间的前提下，提高吞吐量（cpu运行程序系统的时间，和总时间的占比，反应了系统单位时间内提供的算力），适合使用在吞吐量优先需求中，如后台计算应用**

   1. **CMS回收器：**

   使用Mark-Sweep，分四个阶段：初始标记（ Initial Mark ）、并发标记（ Concurrent Mark ）、重新标记（ Remark） 、并发清除（ Concurrent Sweep ），其中1、3阶段会导致STW，2、4阶段和程序并发执行，不影响程序正常执行，但耗时更长。由于使用Mark-Sweep算法，会导致整个堆区出现大量空间碎片，因此该回收器还提供-XX 配置参数，实现FGC时对老年代进行空间碎片压缩整理（Mark-Compact），但该过程会导致STW；

   特点：**多线程并行、并发收集，存在极短时间STW，但吞吐量低（占用CPU时间更长),并且空间碎片严重，容易触发频繁FGC，适合程序响应要求较高的场景，如Web应用,减少GC导致的STW时间，由于YGC不能进行空间碎片整理，因此搭配其他新生代收集器使用**

4. **G1回收器：**

   Hotspot在JDK7中推出的新一代垃圾回收器，和GMS相比，对堆空间进行重新划分，原来区域分割为相同大小的区域，并出现Humongous一个特殊的老年代区，保存大型对象；之前新生代和老年代不在进行物理隔离，都作为相同大小的区域集合（**region**）；整体上YGC使用Mark-Sweep算法、FGC使用Mark-Compact；由于对大对象，需要使用Mark-Compact将其复制到Humongous，需要更多的内存空间

   特点：**多线程并行、并发收集，独特的空间划分不会产生空间碎片，但需要更大的内存空间；可以预测GC的STW时间，选择最高效率的region进行优先处理，获取最小STW；内部还是使用分代收集，但不在内存空间中体现；适合满足吞吐量的情况下，追求最小STW，防止出现高并发下的雪崩场景**

**由此可知，垃圾回收器的选择，和使用场景和所在机器的机能有密切相关：**

- 单CPU或者小内存，单机程序：Serial回收器
- 多CPU，需要大吞吐量，如后台计算型应用：Parallel回收器（目前JAVA8 服务端JVM默认使用）
- 多CPU，追求低停顿时间：ParNew回收器(java8只能配合GMS使用)、GMS回收器、G1回收器

**当然由于每个回收器的特点不同，对应分代回收，可以进行组合使用：**

因此java基本使用选择有: ParNew/CMS（尽可能降低STW使响应更快，但吞吐量更低，浪费内存空间）、Parallel/Parallel Old（在STW可控前提下，尽可能提供吞吐量）、Parallel/serial Old（中庸，多线程分代使用最合适的算法，没有额外特点）、G1（在吞吐量可控前提下，尽可能降低STW，但耗费内存空间大）

![](C:\Users\OneMTime\Desktop\Typora图片\JVM垃圾回收器组合.png)

**JAVA垃圾回收器查询：**

java -XX:+PrintCommandLineFlags -version

### 4.6、类的卸载

**类卸载：**

​	当类经过类加载过程后，其生命周期就会开始，被JVM使用；当该类的class对象不再被引用时，就说明Class对象的生命周期结束，此时Class对象就会被垃圾回收器回收，其方法区对应的数据也会被清除

**由JVM自带的类加载器所加载的类，在整个JVM生命周期中，并不会被卸载，原因是：**

​	JVM会始终引用这些自带的类加载器，而类加载器则会使用一个集合来始终保存所有加载类的Class对象的引用，也因此，自定义类加载器可以有效避免类始终被加载，从而降低JVM的方法区的内存占用

**如何保证一个对象不被回收：**

​	我们可以知道当对象被引用时，则不会被回收；在整个JVM中，只有被JVM自带的类加载器所加载类的class对象，才不会被回收；同理，利用class对象的不可回收性，当创建其对应类的静态变量时，该静态变量保存的对象引用会一直存放在该类的class对象中，因此可以保证不被回收。**即被JVM自带类加载器所加载类的静态变量对象，能够保证永久不被回收**

### 4.7、java源文件的执行过程：

![](C:\Users\OneMTime\Desktop\Typora图片\java类执行过程.png)

## 5.异常与日志

### 5.1、异常：

​	在程序中，即使开发者代码设计的多么精密，也无法控制运行程序发生意料之外的事件，而阻止程序的正常运行；我们将这种情况的发生叫做程序异常，因此我们需要建立一套完善的异常处理机制,而这个机制核心就是解决这三个问题：

1. 哪里发生异常
2. 谁来处理异常
3. 如何处理异常

- 异常在哪里发生：

  java语言提供try-catch语法，来对异常进行预先准备处理,即默认为此处可能出现某些异常，如果出现了则进行catch代码块中的处理程序。

  注意：往往开发者为了简单，会将大段代码定义在一个try-catch块中，这样会不利于异常的定位，是不符合责任的表现；我们需要先区分哪些为稳定代码，哪些为非稳定代码，如简单的字面量赋值String s= ”helloworld“就是稳定代码，不可能发生异常；异常的捕获时应该只针对于非稳定代码，并需要区分不同的异常类型，来做相应不同的处理，如账号登入，是账号名错误，还是密码错误、还是登入次数达到上限等

- 谁来处理异常：

  java语言中提供两个关键字：throw和throws；前者是用于抛出一个异常(API提供的或者是自定义的)；后者是将该方法中抛出的异常交给该方法调用者处理；

  因此我们可以有两种选择谁来处理异常：

  - 交给方法自己处理
  - 交给方法调用者处理

- 如何处理异常：

  无论是谁来处理异常，我们都严禁开发者捕获异常后不进行任何处理或直接打印一行日志了事；

  - 如果是在方法内部处理，我们应该根据业务场景进行定制处理，如重试、回滚
  - 如果向上交给方法调用者处理，者需要对抛出的异常对象添加上下文参数、局部变量、运行环境等信息，便于排查问题

### 5.2、异常的分类

​	JDK有一套完整的异常机制，所有异常都是Throwable的子类，它有分为Error（致命异常，即错误）、Exception（非致命异常）；Error是一种特殊异常，它的出现标志着系统发生了不可控制的错误，此时就无法使用程序进行处理，必须人工介入，如OutOfMemoryError、StackOverflowError；Exception又分为checked异常（ 检查性异常）和unchecked异常（  非检查性异常，即运行时异常，有一个父类：RuntimeException）

- checked异常：

  checked异常是需要在代码中显式进行处理的异常，否则就会出现编译出错；JDK中定义了许多checked异常，它们的父类或超类都为Exception，并且不会继承RuntimeException，常见的有：SQLException、IOException、ClassNotFoundException等；进一步细分为两类：

  - 无能为力、引起注意型，如sql语句写错导致的SQLException，即使做再多的重试，也不会对异常有任何保证，因此这些异常一般不进行处理，直接try-catch保存该异常信息，并打印，供开发者介入排查问题
  - 力所能及、坦然处置型，如发生为授权异常，程序可以通知前端页面，跳转到权限申请页面；从而力所能及的促进异常解决，提供用户使用程序的体验

- unchecked异常：

  unchecked异常即运行时异常，它们都继承自RuntimeException，不需要程序进行显式的捕捉和处理，unchecked异常细分为三类：

  - 可预测异常：如IndexOutBoundsException、NullPointerException等，基于对代码性能和稳定性的要求，对于此类可以预测的异常，应该提前进行边界检测、空指针判断处理。显式的声明捕获异常，再进行额外处理，会降低代码的可读性和程序的运行效率
  - 需捕捉异常：如代码中使用HTTP客户端进行http接口调用时，出现服务器响应超时的异常（ConnectTimeoutException 连接超时、SocketTimeoutException tcp数据传输超时）时，必须手动对该异常进行处理，不能因为外界环境的异常，导致程序内部使用出现问题。处理方案可以为：关闭当前http资源，然后重新连接；或者等待一段时间后重试
  - 可透出异常：主要指框架或系统中产生，并且自身已经提供处理机制的异常；如springMVC框架中抛出的oSuchRequestHandlingMethodException 异常（没有处理请求的controller方法），抛出该异常后，springMVC会自映射对应的状态码，如404，来返回404页面

![](C:\Users\OneMTime\Desktop\Typora图片\java异常分类.jpg)

### 5.3、异常语法：

​	try-catch-finally是java提供处理程序异常的三部曲语法，它们的作用分别是：

- try代码块：监视代码的执行过程，一旦发生异常则直接跳转到catch，如果没有catch代码块，则跳转到finally
- catch代码块：可选执行代码块，用于发生异常后，进行处理或向上抛出
- finally代码块：必选执行diamante块，无论是否发生异常，都会执行，即使发生了OOM，但也有不执行的可能：
  - 没有进入try代码块
  - 进入try代码块，但是发生了死循环或死锁
  - 进入try代码块，但执行了System.exit()关闭程序操作

注意:

1、finally代码块执行前，出现return 语句时，return语句中的表达式还是会按照顺序执行并保存，然后执行完finally代码块后，再return将结果返回给上一个栈帧

2、当finally代码块中也出现return语句时，同样return语句中的表达式也会按顺序执行并保存，但后一个执行的return表达式结果会替换掉前者

3、在使用try代码块进行lock锁时，应该将lock方法放在try代码外；原因：当lock（）方法调用失败时，会抛出运行时异常（告诉开发者为什么当前不能获取到该对象锁）；但此时finally中又会执行unlock（）方法来释放锁，此时就会抛出 IllegalMonitorStateException异常（即没有获取对象锁，因此无法释放），这样后者异常就会覆盖前者，导致开发者无法获取真正的异常原因

### 5.4、异常的抛与接：

​	在异常没有找到合适调用者进行处理时，我们需要进行异常信息的传递

异常信息有两种传递方式：

- 抛出异常对象：

  ​	一般用于程序内部的调用，如dao层异常抛出，交给service层处理

- 将异常信息封装到一个特定对象中：

  ​	用在对外暴露的接口中，如HTTP请求使用错误码、RPC远程调用使用Result对象封装，前者能够让接口调用方更好的得知程序内部发生了什么错误，而不需要一定的java后台程序的知识去分析，并且减少暴露的信息，保证安全性；后者可以有效防止接口调用方，没有进行异常捕获而出现运行错误、程序中断的情况，并且避免了RPC序列化传输对大量栈信息的处理

### 5.5、日志：

​	程序系统需要日志的原因：

1. 记录操作轨迹
2. 监控系统运行状况
3. 回溯系统故障

#### 5.5.1、日志规范：

**日志级别：**

- DEBUG：级别曰志记录对调试程序有帮助的信息。 

- INFO：级别日志 用来记录程序运行现场，虽然此处并未发生错误，但是对排查其他错误具有指导意义。 

- WARN：级别日志也可以用来记录程序运行现场，但是更偏向于表明此处有出现潜在错误的可能。 

- ERROR：级别日志表明当前程序运行发生了错误，需要被关注。但是当前发 生的错误，没有影响系统的继续运行。 

- FATAL：级别曰志表明当前程序运行出现了严重的错误事件，并且将会导致应 用程序中断。

日志周期：

​	一般情况下，日志保存15天，并以一天为一个日志文件，具体可以根据日志的重要程度、日志多少和磁盘空间来延长保存时间

**日志操作注意事项：**

- 定义logger变量

```java
private static final Logger logger = LoggerFactory.getLogger(XX.class);
要确保一个类中，只有一个logger对象（静态成员常量），从而减少对象的内存占用
```

- 在生产环境中，应该禁止debug级别日志的输出

  由于logger会继承root的输出源，因此一般需要添加additivity="true"，防止日志重复输出

- error日志信息输出时，应该携带异常信息，帮助分析异常原因

```java
		try {
			int a= 1/0;
		} catch (Exception e) {
			log.error("test发生异常，异常信息："+e.getMessage(),e);
		}
```

- 减少日志打印对应用程序性能的损耗

  虽然我们在生产环境下，会提高日志级别的打印，减少不必要的日志打印；但是日志中的字符串拼接还是会执行，这样会白白浪费性能，因此需要以下手段来进行这样情况的发生：

  1、使用条件判断，判断当前logger对象的需要输出的日志级别，再对日志进行打印后者忽略

  ```java
  	if (log.isErrorEnabled()) {
  		log.error("test发生异常，异常信息："+e.getMessage(),e);
  	}
  ```

  2、使用占位符，来减少字符串拼接时，String对象的创建；使用占位符时，只有需要打印该字符串时，才会进拼接（有些日志框架不支持占位符,logback支持）

  ```java
  	int id=100;
  	String user="yh"; 
  	log.debug("错误，id：{},user:{}",id, user);
  ```

- 日志文件命名：推荐使用projectName_logName_logType.log

#### 5.5.2、日志框架：

![](C:\Users\OneMTime\Desktop\Typora图片\日志框架.jpg)

- 日志门面：

  ​	在java语言中，日志框架已经有了明确的体系，利用门面设计模式实现了多种日志框架的整合。目前日志门面框架有两个slf4j（主流）、commons-logging；它们提供了日志使用的统一接口规范，自身不进行日志功能的具体实现，目的是让开发者能够更简单的使用日志,并且能有效防止应用程序出现使用多个日志框架，而导致日志框架冲突，日志打印失效的问题

- 日志库：

  ​	日志库时日志相关功能的具体实现，主流日志库有：log4j、log-jdk(JDK1.4)、logback；最早的日志记录，只能通过system.out、system.err来完成，这样非常不方便

  ​	使用日志的优点：

  - 完善的日志级别，不同级别日志根据代码应用环境，进行不同方式的输出策略
  - 通过配置文件来降低日志和业务代码的耦合

- 日志适配器：

  ​	由于java日志框架的发展多样，作为目前主流的slf4j日志门面，无法支持老日志框架，如log4j；因此就需要一个适配器（slf4j-log4j12），来解决接口不兼容的问题

目前，新项目推荐使用slf4j+logback,logback本身就是slf4j的实现，无需日志适配器

## 6、数据结构与集合

### 6.1、数据结构

#### 6.1.1、数据结构的定义

​	数据结构是指逻辑意义上的数据组织方式和相应的处理方式

- 逻辑意义：数据结构的抽象表达方式非常丰富，但实际的物理存储相对单一；比如二叉树，数据的物理存储也并不是通过树形方式完成的；因此数据结构是建立在逻辑意义上的
- 数据组织方式： 在逻辑意义上，数据的组织方式有很多种，如数、图、队列和哈希等；同时树又可以分为二叉树、三叉数、B+树等；图可以分为有向图、无向图；队列可以分为FIFO、FILO；哈希可以根据不同的算法定义哈希值
- 数据处理方式：在特定的数据组织方式上，需要以特定的算法来实现数据的增、删、改、查和遍历，而不同的数据处理方式，也往往存在非常大的性能差异

#### 6.1.2、数据结构分类

​	数据结构是算法实现的基石，以直接前驱和直接后继的维度，可以将数据结构大致分为如下四类：

####直接前驱和直接后继：当前数据节点，它的前一个节点叫直接前驱。后一个节点叫直接后驱；

- 线性结构：0至1个直接前驱和直接后继。当线性结构为非空时，有唯一的首元素和尾元素，除这两者外，其他所有的元素都有唯一的直接前驱和直接后继。线性结构包括：顺序表、链表、栈、队列，其中栈和队列是访问受限的结构，一般栈后进先出，队列先进先出
- 树结构：0至1个直接前驱和0至n个直接后继（n大于等于2）。树是一种非常重要的有层次的非线性数据结构，稳定均衡，在计算机数据结构中应用广泛
- 图结构：0至n个直接前驱和直接后继。图结构包括简单图、多重图、有向图和无向图等
- 哈希结构：没有直接前驱和直接后继，通过特定的哈希函数，将数据索引与数据存储值关联，是一种查找效率非常高的数据结构

​	数据结构的复杂度分为空间复杂度和时间复杂度，而时间复杂度时考量当前数据结构数据处理性能的重要指标，反应了程序执行时间随当前数据量增长而增长的量级；这个量级指标通常使用大写O和一个函数描述；从好到坏，常用算法复杂度排序如下：常数级O（1）、对数级O（log n）、线性级O（n）、线性对数级O（nlogn）、平方级O（n^2）、立方级（n^3）、指数级O（2^n），对于logn 即为以2为底的对数，n为256时，其值为8

​	以猜数字为例，在0-100中随机猜一个数，没有猜中就会提示你猜的数是大了，还是小了，直到你猜中；按照随机理论，最少猜一次，最多猜100次，但实际中，我们会通过二分法进行猜测，而二分法的时间复杂度就为O（log n）

### 6.2、java集合

​	java中集合是用于存储对象的工具类容器，实现了常用的数据结构，提供了一系列对集合元素进行增加、删除、修改、查找和遍历的方法，从而降低日常开发成本。java整个集合框架体系主要分为两类，单个元素存储的Collection和key-value存储的Map，两者在功能上有很大的差异

![](C:\Users\OneMTime\Desktop\Typora图片\java集合框架图.jpg)

从整个java集合框架图中，我们可以看到整个java集合分为4大容器，List、Queue、Set、Map

#### 6.2.1、List集合

​	list集合时线性数据结构的主要实现，集合元素存在明显的上一个元素和下一个元素，也明确第一个元素和最后一个元素。list集合的遍历结果也是稳定的。该体系中最常用的是ArrayList和LinkedList实现类：

- ArrayList是容量可以改变的非线程安全集合，内部实现使用数组存储，集合扩容时会创建更大空间的新数组，并将原有数据复制到新数组中。ArrayList支持对元素的快速随机访问，但插入和删除的速度通常很慢，因为此过程需要移动其他元素
- LinkedList本质是双向链表，与ArrayList相比，插入和删除速度更快，但随机访问速度则很慢。测试表明,对于10万条的数据，其随机访问速度和ArrayList相差数百倍。LinkedList除了继承AbstractList抽象类外，还实现了Deque，即double-ended queue（双向队列），因此提供了size、first、last成员属性，从而快速获取集合中的所有节点数、第一个节点和最后一个节点。LinkedList的优点在于可以将零散的内存单元通过附件引用的方式关联，形成按链路顺序查找的线性结构，内存利用率较高

#### 6.2.2、Queue集合

​	Queue是一种先进先出的线性数据结构，数据只允许从队列的一端进行获取，另一端进行插入；对于BlockingQueue(阻塞队列)，常用于高并发编程场景中，通过其FIFO特性和阻塞操作特点，作为Buffer（数据缓存区）使用

​	Queue和BlockingQueue的区别：BlockingQueue在队列为空，进行获取操作时，会使线程阻塞；当队列已满，进行插入操作时，也会使用线程阻塞；而Queue则会直接返回null或插入失败

#### 6.2.3、Map集合

​	Map集合是以Key-Value键值作为存储元素的哈希结构。Key按照某种哈希算法计算得到唯一，即Hash值，每一个hash值在hash表中得到对应一个链表，用于存储key-value键值元素。

​	Map类提供三种Collection视图，keySet方法获的所有key集合、Values方法获取所有Value集合，entrySet方法获的所有可迭代的键值对集合。hashMap默认是线程不安全的，在高并发场景则使用concurrentHashMap

#### 6.2.4、Set集合

​	Set是不允许重复元素的集合，有三种实现类：HashSet、TreeSet、LinkedHashSet。其底层结构是通过Map集合来实现，Value为一个固定的静态Object对象，key为其存储元素

### 6.3、集合初始化

​	集合初始化通常就是进行分配容量、设置特点参数等相关工作，以常用的ArrayList、HashMap为例：（LinkedList为链表，不需要分配容量；set基于Map实现，和Map初始化一致）

- ArrayList：

  在其初始化时，会创建一个Object数组，其大小根据构造方法参数值决定：

  - 大于0则为当前值；

  - 等于0或调用无参构造方法时则创建一个空数组；

  - 小于0，抛出IllegalArgumentException（非法参数异常）

  当执行add方法时，判断数组是否容纳size+1的元素，如果不够，则进行扩容，扩容会重新创建一个Object数组，然后将old数组数据转移到new数组，并会进行如下操作：

  - 判断当前数组是否为空数组，如果是，则创建一个**默认大小的数组**，反之进行后面操作

  - 获取old数组大小，计算new数组大小: newCapacity=oldCapacity+（oldCapacity>>1）,即扩容50%，JDK7之前取ceil（oldCapacity不能整除时，50%+1）；之后则floor(四舍五入)
  - 判断newCapacity是否大于oldCapacity，防止扩容时导致超出int的表示范围；不大于，则使用当前newCapacity作为新数组大小；反之，此时扩容则直接使用oldCapacity+1作为新数组大小

  **ArrayList的内部数组默认大小为10，扩容算法为1+50%，并进行四舍五入取整**

- HashMap：

  hashMap的初始化和扩容有两个参数来决定：

  - Capacity：HashMap的存储大小，默认为16
  - loadFactor：HashMap的扩容阀值，默认为0.75

  在进行初始化时，可以对两个参数进行设置，如果没有设置则为默认值；并且在初始化时，HashMap并不会进行hash表的实际创建，只有在第一次put时，才会执行，并且会将设置Capacity值，修改为大于且最接近参数值的2的幂值，如初始化参数值为27，则实际大小为32（**使得HashMap的容量大小始终为2 ^N，在进行hash表指定hash值索引计算（（n-1）&hash）时，这样有利于&运算，并减少hash冲突**）

  当n次put时，n+1>Capacity*loadFactor,则会进行扩容，直接扩容为2倍；创建一个新的hash表，然后将old表数据转移到new表中

  **loadFactor的作用：**限制hash表的填充比例，从而减少hash冲突，提高查询效率；以空间利用率换取时间；loadFactor理论上可以>1,并不会导致容器容量超出，而只会使hash冲突率增加，在同一hash表索引对应的链表数据结构中添加冲突元素

  **HashMap默认大小为16，扩容算法为1*2**

**综上所述，在进行集合初始化时，需要设置合理容量大小，从而有效避免扩容带来的性能损耗**

- hash表是一个连续的数组，存储KV对数据


- hash值是通过hash算法计算得到key的hashCode


- hash冲突是不同key可能会根据hash算法计算得到相同hashCode，从而使它们对应的hash表索引值相同、或者是不同hashCode通过索引计算得到索引值相同；这种情况下，相同索引值数据会在对应链表中顺序储存


### 6.4、数组

​	数组是一种顺序表，在各种高级语言中，是组织和处理数据的常用方式。数组的下标从0开始，和我们实际生活常识有区别，原因是：当数据开始下标为0时，所有当前下标和开始下标的偏移量，就可以直接通过当前小标来表示，即n-0=n，不需要做额外的计算；当开始下标为0时，则需要进行-1，增加了额外计算负担；**在java体系中，数组用于存储同一类型对象，内存一旦分配就无法扩容**

**数组初始化：**

​	数组初始化方式分为两种，静态初始化、动态初始化；

```java
//静态初始化	
String [] arg1={"1","2"};
//动态初始化
String [] arg2 = new String[2];	
```

java集合中提供Vector和ArrayList的类，来实现动态大小的数组，底层实际上是不停的创建新数组来替换；前者是线程安全、性能较低已经弃用；后者线程不安全，是使用频率最高的集合之一

**数组的遍历：**

​	数组遍历优先使用JDK5引进的foreach方式，无需使用下标就可以实现遍历；当需要使用数组下标时，则使用for循环遍历，注意数组的length为属性，并不是方法（如String的length()），当然也可以使用JDK8的List集合的函数式接口遍历：

```java
Arrays.asList(arg1).stream().forEach(x->System.out.println(x));
```

**Arrays：**

​	Arrays是JDK提供操作数组对象的工具类，功能包括排序、查找、对比、拷贝、将数组转集合等操作。对于asList方法（数组转集合），需要特别注意：

转换得来的List对象并不能执行add、remove、clear方法，否则会抛出UnsupportedOperationException 异常；但可以使用set（）方法来修改指定索引的值。转换的底层源码是通过Arrays的内部类ArrayList实现：

```java
public static <T> List<T> asList(T... a) {
    return new ArrayList<>(a);
}

private static class ArrayList<E> extends AbstractList<E>
        implements RandomAccess, java.io.Serializable
    {
        private static final long serialVersionUID = -2764017481108945198L;
        private final E[] a;

		//内部保存了当前数组的引用，所有实现LIST的方法，实际上都是在操作当前数组对象
        ArrayList(E[] array) {
            a = Objects.requireNonNull(array);
        }

```

因此在使用asList方法时，一定要注意是否会变动元素个数，当然也可以通过”真正的“ArrayList构造方法，来将其转换为可变集合：

```java
 ArrayList<String> arrayList = new ArrayList<>(Arrays.asList(arg1));
```

**集合转换为数组：**

​	直接使用List的toArray无参方法，并不能实现集合转换为数组，因为该方法会导致得到的Object数组泛型丢失，无法转换为真实的数据类型；应该使用一个静态初始化的数组对象，作为toArray方法参数：

```java
String [] arg1 =new String [10];
String[] array = list.toArray(arg1);
```

但是还需要注意数组大小和list集合的大小匹配；当数组大小大于等于集合大小时，则能够正常转移；当数组大小小于集合时，则会创建一个新的空数组，大小为集合大小；并且通过实验可知，**当数组大小和集合大小相同时，转换效率最高**

### 6.5、集合与泛型

​	通过集合与泛型的联合使用，可以将泛型的功能发挥到极致；但在使用过程中，我们需要注意如下问题：

1、编译器是默认推荐使用泛型的，当不使用泛型时，集合可以存储任何类型的对象，但是遍历时需要进行准确的强行转换，否则抛出ClassCastException异常

2、使用List<Object> 和不使用泛型，两者效果并不是一样；当使用addAll方法，将一个集合数据放入另一个Integer泛型集合时，前者直接编译不通过，后者编译通过，但运行时报错；因此推荐使用泛型，来避免这些隐形BUG

3、List<?>可以接受任何泛型集合的引用赋值，并删除或清空集合元素，但是不能添加任何元素；一般用于接收不确定具体元素类型的集合

4、List<T>可以放置任意一种类型元素，但不能随意转换；JAVA提供了<? extends T>与<? super T>两种语法；前者定义了集合元素类型的上限，元素类型为T或T的子类；后者定义了集合元素类型的下限，元素类型为T或T的父类

<? extends T>可以使用get方法，将集合中的元素全部向上转型为T；但不能使用put方法

<? super T>可以编译检测put方法元素类型一定为T或T的父类；但get方法获取的元素全部都会向上转型为Object

### 6.6、元素比较

#### 6.6.1、Comparable和Comparator

​	java对于对象比较通常使用在集合元素的排序中，常用两个接口来实现元素的比较，Comparable和Comparator；前者是自己和同一类型对象比较；后者是用于比较两个同类型对象

​	对于基本数据类型包装类、String就实现了Comparable的自然排序；我们可以通过实现Comparable来自定义当前类的比较排序方式：

```java
public class UserComparator implements Comparator<User>{

	@Override
	public int compare(User o1, User o2) {
		Integer age1 = o1.getAge();
		Integer age2 = o2.getAge();
		// 比较age
		if (age1 != age2) {
			return age1 > age2 ? 1 : -1;
		}
		return 0;
	}
}
```

​		但Comparable有一个致命的缺点，当需要修改排序规则时，则要修改比较目标类，这样就违背了开闭原则；而Comparator就有效解决了这个问题：

创建一个Comparator实现类，作为目标类的比较器：

```java
public class UserComparator implements Comparator<User>{

	@Override
	public int compare(User o1, User o2) {
		Integer age1 = o1.getAge();
		Integer age2 = o2.getAge();
		// 比较age
		if (age1 != age2) {
			return age1 > age2 ? 1 : -1;
		}
		return 0;
	}
}
```

无论是Comparable还是Comparator，约定俗成重写方法返回值：小于返回-1，等于返回0，大于返回1

在Arrays.sort数组排序方法中，就使用了Comparator比较器进行排序；从而开发者可以自定义当前元素类型的排序规则；当不指定比较器时，则使用默认排序算法：

- 归并排序（Merge Sort）

  将N个元素的集合看做成N个长度为1的有序子集合；然后将这些子集合两两归并，并进行排序；一直重复，直到归并为一个长度为N的有序集合，类似于16=8+8=4+4+4+4=2+2+2+2+2+2+2+2

- 插入排序（Insertion Sort）

  从第K个元素开始，前面元素组成的数组默认有序，然后将第K个元素插入有序数组，得到一个K+1长度的有序数组，依次类推完成整个集合元素的排序；插入时，先将新元素放在k+1的位置，然后通过比较排序确定新元素正确位置

- TimSort排序

  在2002年，Tim Peters结合了归并排序和插入排序的优点，实现了TimSort排序算法。

  - 相对于传统的归并排序，不在从长度为1的有序子集合开始归并，而是将当前集合划分为多个最大排序的子集合，减少了归并次数；类似于：15267834 分隔为 1、5、 2678、34,然后归并

  - 相对于插入排序，引入了二分排序概念，即将新元素与中间元素比较，而不是从前往后依次比较，加快找到新元素正确位置的速度，提升排序效率；类似于1234567中插入5，先将5和4比较，然后5和6比较，然后5和5比较

因此在JDK7中，TimSort算法取代了原来的归并排序，作为JDK中的默认排序算法

#### 6.6.2、hashCode和equals

​		hashCode和equals用于标识对象，共同判断两个对象是否相等。每个对象创建后都会生成一个与内存地址相关的哈希值，但是不可避免的会存在哈希值冲突，因此当hashCode相同时，还需要通过equals来进行值比较，Object类提供这两个方法，并且equals方法默认是比较对象的内存地址，当我们重写这两个方法时，需要满足如下条件：

- 如果两个对象的equals结果相等，则两个对象的hashCode返回值也必须相等
- 当重写equals时，必须重写hashCode

在Map和Set类中，需要保证元素的唯一性，因此就需要使用hashCode、equals进行对象比较，为了提供处理效率，在if判断中优先比较hashCode，通过&&的短路功能，当hashCode不相等时，就不需要执行equals比较

对于String类，就重写了hashCode和equals，因为String类会由于String常量池，导致Object.hashCode、equeal相同；

### 6.7、fail-fast机制

​	fail-fast（快速失败）机制是集合在遍历元素时，出现集合元素插入、删除，则抛出异常的错误检测机制，防止增删操作对元素遍历的影响：

- ​	对于JDK中所有的非线程安全集合（java.util包下），在遍历时，会在当前线程中维护一个计数expectedModCount，在集合遍历前保存当前集合的元素增删次数**modCount**，遍历后将当前**modCount**与expectedModCount对比，保证两者相等，即遍历中集合元素没有进行增删操作；否则就抛出异常

- ​	对于JDK中所有线程安全集合（concurrent 包下），则使用fail-safe机制，当进行遍历时，使用当前集合的快照，忽略遍历时集合元素的操作；当然也就有明显的缺点，无法读取最新数据

对于遍历时删除，我们可以使用Iterator机制实现，当多线程并发时，则需要使用同步锁，或者直接使用并发容器CopyOnWriteArrayList代替ArrayList，该容器内部会自动对Iterator加锁	

### 6.8、Map类集合

​		Map接口除了提供传统的增删改查方法外，还提供了如下三个特有方法：

```java
Set<K> keySet();//返回Map类对象中的Key的Set视图

Collection<V> values();//返回Map类对象中所有Value集合的Collection视图

Set<Map.Entry<K,V>> entrySet();//返回Map类对象中key-value对的Set视图
```

它们的实现类为AbstractSet、AbstractCollection，都没有实现add方法，但实现了remove、clear；**这些视图和原容器操作都会相互影响**，因此一般情况下，不会对这些视图对象进行元素操作

​		Map类KV是否可以为null，由具体实现类约束确定：

| Map集合类         | key          | Value        | JDK  | 说明                    |
| ----------------- | ------------ | ------------ | ---- | ----------------------- |
| Hashtable         | 不允许为null | 不允许为null | 1.0  | 线程安全（过时）        |
| concurrentHashMap | 不允许为null | 不允许为null | 1.5  | 锁分段技术、CAS（JDK8） |
| TreeMap           | 不允许为null | 允许为null   | 1.2  | 线程不安全，但有序      |
| HashMap           | 允许为null   | 允许为null   | 1.2  | 线程不安全              |

对于线程安全的Map实现类：

- 对于value为null，由于map的get方法返回null时，无法判断当前key对应的value是不存在或是为null，需要搭配containsKey进行判断，但在并发环境下，就需要使用同步锁来保证get、containsKey方法执行数据的一致性，降低执行效率；

- 对于key为null，其实是要给开发规范，减少了并发过程中，对参数null的判断逻辑；并且在实际使用中，key为null的使用场景很少

因此在设计上，并发容器Map直接不允许KV为null，提供并发效率

对于TreeMap，则是key需要进行排序，key为null不太好定义排序，因此设计上直接省去了key为null

对于hashMap，设计者认为KV为null在开发中是有实际意义的，因此对它们为null进行了额外的处理（说白了就是每个设计者对null的看法不同，导致容器设计的不同）

#### 6.8.1、红黑树

​		树是一种常用的数据结构，最顶层只有一个节点，称之为**根节点**；每个节点都可以指向多个分节点，当某个节点下面没有分支时，该节点就称之为**叶子节点**；从当前节点出发，到叶子节点为止，最长简单路径上的子节点个数（不包含当前节点），就称之为该**节点高度**；从更节点出发，到当前节点为止，最长简单路径上的子节点个数（不包含根节点），就称之为当前**节点深度**；任意节点及其下面节点构成的树称之为**子树**，该节点高度，也叫做**子树高度**

​		至多只有两个子节点的树就称为二叉树，二叉树是近似二分法的一种数据结构实现，在二叉树中有存在平衡二叉树、二叉查找树概念。

- 平衡二叉树

  ​	特定：任意节点的左子树和右子树高度差不超过1，空树或只有一个节点的二叉树，也可以称之为平衡二叉树

- 二叉查找树

  ​	又称为二叉搜索树，Binary Search Tree；

  特定：对于任意节点，其左子树上所有节点值都小于它，其右子树上所有节点值都大于它，因此方便数据查找。

  ​	二叉查找树右三种节点遍历方式：前序遍历、中序遍历、后序遍历，遍历规则满足如下：
  
  - 左节点在右节点之前遍历，即从最左叶子节点所在子树开始遍历
  - 前序顺序为根节点、左节点、右节点；中序遍历为：左节点、根节点、右节点；后序遍历为：左节点、右节点、根节点；**一般使用中序遍历，从而满足正常排序**

由于二叉查找树作为一种数据结构，需要不断的进行数据的增加或删除，当不限制左右树的高度差时，就会导致其时间复杂度变为O（n），因此一般情况下二叉查找树、平衡二叉树特性需要联合使用，此时就需要通过一些算法来实现二叉树的平衡性：

- AVL树

  AVL树是一种平衡二叉查找树，大大提高了数据排序和查找的效率，保证最坏时间复杂度为O（log n）；**通过左旋、右旋的方式，使平衡二叉树保持其特性**

  - 右旋：选择左子树中的一个节点，以它作为根节点，其父节点作为新的右节点，旧的右节点作为新的右节点的左节点，也被称之为顺时针旋转![](C:\Users\OneMTime\Desktop\Typora图片\平衡二叉查找树右旋.png)

  -  左旋：选择右子树中的一个节点，以它作为根节点，其父节点作为新的左节点，旧的左节点作为新的左节点的右节点，也被称之为逆时针旋转![](C:\Users\OneMTime\Desktop\Typora图片\平衡二叉查找树左旋.png)

- 红黑树

  ​	红黑树于1972年发明，当时称为对称二叉B树，1978年优化命名为红黑树，**特点是每个节点上增加了一个属性，表示节点颜色，颜色可以为红色或黑色**

  ​	**红黑树和AVL的比较：**

  ​		它们都是在进行插入和删除元素时，通过左旋和右旋来保持自身的平衡性，从而提供树结构的时间复杂度，获取较高的查找性能。但与AVL树相比，红黑树在平衡性上，没有追求左右子树高度差不超过1的约束，而是保证**根节点到叶子节点的最长路径不超过最短路径的2倍**的大致平衡，并通过着色来更加高效的完成自平衡，在二叉查找树基础上，引入了额外约束条件：

  - 节点只能为红色和黑色
  - 根节点只能为黑色
  - 所有NIL节点都为黑色；NIL节点：即叶子节点下的两个虚节点
  - 一条路径上不能出现相邻的红色节点
  - 任何子树内，根节点到叶子节点的路径上包含相同数目的黑色节点（包括NIL节点）

通过这些约束，**保证了红黑树在新增、删除、查找的最坏时间复杂度为O（log n），并且每一次平衡时，最多只需要进行三次旋转来完成**；而对于AVL树，**由于它非常高的平衡性，因此平衡至多需要logn次，但同时由于AVL树的决定平衡，相同节点树下，平均查找次数要少于红黑树**

综上所述，红黑树和AVL树具有相同的最坏时间复杂度O（log n），但是红黑树维护平衡的成本更低，最多只需进行三次旋转，因此红黑树适合频繁插入和删除场景，AVL树适合低频修改，大量查询场景

#### 6.8.2、TreeMap

​		TreeMap是JAVA中通过Key的排序结果进行内部数据存储的Map类集合，用于对Key有排序要求的场景。

**TreeMap的Key去重：**

​	TreeMap在插入KV时，必须保证key实现了Comparable或在实例化TreeMap时，提供额外比较器Comparator，也因此不允许Key为null。但不同于HashMap，TreeMap不一定要覆写key的hashCode和equals方法，来进行key去重，因为：

​		HashMap是使用key的hashCode和equals方法去重，而TreeMap会优先使用比较器Comparator，当没有指定额外比较器时就会调用key所实现comparable接口的compareTo方法，当两者都没有时，则会抛出异常

**TreeMap的元素排序：**

​		TreeMap是基于红黑树来实现数据存储，从而实现最坏时间复杂度为O（log n）的增删改查操作，因此TreeMap源码底层，就是实现了红黑树操作

##### TreeMap源码解析：

- TreeMap实现红黑树的基本属性：

```java
public class TreeMap<K,V>
    extends AbstractMap<K,V>
    implements NavigableMap<K,V>, Cloneable, java.io.Serializable{
    //排序使用的比较器
     private final Comparator<? super K> comparator;
     //红黑树根节点
     private transient Entry<K,V> root;
     
     //红黑树颜色字面量
     private static final boolean RED   = false;
     private static final boolean BLACK = true;
     
     //内部类，红黑树节点载体类
	 static final class Entry<K,V> implements Map.Entry<K,V> {
        K key;
        V value;
        Entry<K,V> left;//左子节点载体
        Entry<K,V> right;//右子节点载体
        Entry<K,V> parent;//父节点载体
        boolean color = BLACK;//节点颜色，默认黑色     
     }
```

- TreeMap红黑树节点新增操作(删除操作和新增操作类似)：

  在进行节点新增时，从根节点开始，遍历比较：大于节点值向右；小于节点值向左；等于节点值直接替换；直到遍历到NIL节点时，创建当前节点，颜色默认黑色。整个过程无需关系节点颜色和树的平衡：

  put方法源码：

  ```java
   public V put(K key, V value) {
          Entry<K,V> t = root;
       	//判断根节点是否为null
          if (t == null) {//将key作为根节点，结束
              compare(key, key); //检测key是否可以执行比较
  
              root = new Entry<>(key, value, null);
              size = 1;
              modCount++;
              return null;
          }
          int cmp;//接收比较结果
          Entry<K,V> parent;
          
       	//获取当前treeMap的比较器
          Comparator<? super K> cpr = comparator;
          if (cpr != null) {//比较器不为null时，调用比较器compare方法进行比较
              do {
                  parent = t;//获取当前节点（第一次为根节点）
                  cmp = cpr.compare(key, t.key);//比较当前节点和新节点
                  if (cmp < 0)//小于，获取当前节点的左子节点，作为下一次比较节点
                      t = t.left;
                  else if (cmp > 0)//大于，获取当前节点的右子节点，作为下一次比较节点
                      t = t.right;
                  else
                      return t.setValue(value);//等于，则直接替换当前节点的Value值（即新节点替换当前节点）
              } while (t != null);//循环遍历，直到遍历到NIL节点
          }
       
       	//在没有指定比较器时，调用key实现的Comparable接口的compareTo方法
          else {
              //key不能为null
              if (key == null)
                  throw new NullPointerException();
              @SuppressWarnings("unchecked")
              //检测key类型是否实现Comparable接口
                  Comparable<? super K> k = (Comparable<? super K>) key;
              //开始从根节点出发，遍历比较
              do {
                  parent = t;
                  cmp = k.compareTo(t.key);
                  if (cmp < 0)
                      t = t.left;
                  else if (cmp > 0)
                      t = t.right;
                  else
                      return t.setValue(value);
              } while (t != null);
          }
       
       	//当遍历到NIL节点后，以当前KV对创建节点载体对象Entry
          Entry<K,V> e = new Entry<>(key, value, parent)
       	//并根据最后一次比较结果，判断新节点为左节点或右节点
          if (cmp < 0)
              parent.left = e;
        else
              parent.right = e;
       
       	//最后进行自平衡（重新着色、旋转）
          fixAfterInsertion(e);
          size++;
          modCount++;
          return null;//插入新节点后，返回null
      }
  ```
  
  fixAfterInsertion方法源码(和fixAfterDeletion类似)：
  
  通过put方法可以知道，当新节点插入能够运行到fixAfterInsertion方法时，说明：
  
  1. 新节点插入前，二叉树为非空树
  2. 新节点key与任何节点都不相同
  
  ```java
      private void fixAfterInsertion(Entry<K,V> x) {
          //将新节点颜色默认为红色
          x.color = RED;
  
          //新节点不能为null和根节点、父节点为红色时，进行自平衡
          while (x != null && x != root && x.parent.color == RED) {
              //如果父节点为左子节点
              if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
                  //获取父节点的父节点（爷爷）的右子节点（右叔），判断其颜色是否为红色
                  Entry<K,V> y = rightOf(parentOf(parentOf(x)));
                  if (colorOf(y) == RED) {
                      //是，则说明当前新节点到爷爷节点的子树，不满足红黑树约束
                      setColor(parentOf(x), BLACK);//将父节点置为黑色
                      setColor(y, BLACK);//爷爷节点的右节点置为黑色
                      setColor(parentOf(parentOf(x)), RED);//爷爷节点置为红色
                      x = parentOf(parentOf(x));//此时爷爷节点作为新节点，向上遍历比较
                  } else {//如果右叔节点为黑色
                      //判断新节点是否为右子节点
                      if (x == rightOf(parentOf(x))) {
                          //对父节点做一次左旋操作，并作为新节点
                          x = parentOf(x);
                          rotateLeft(x);
                      }
                 		//将此时新节点的父节点设置为黑色，爷爷节点设置为红色，对爷爷节点进行右旋
                      setColor(parentOf(x), BLACK);
                      setColor(parentOf(parentOf(x)), RED);
                      rotateRight(parentOf(parentOf(x)));
                  }
              } else {//同理，当父节点为右叔节点时，判断左叔节点
                  Entry<K,V> y = leftOf(parentOf(parentOf(x)));
                  if (colorOf(y) == RED) {
                      setColor(parentOf(x), BLACK);
                      setColor(y, BLACK);
                      setColor(parentOf(parentOf(x)), RED);
                      x = parentOf(parentOf(x));
                  } else {
                      if (x == leftOf(parentOf(x))) {
                          x = parentOf(x);
                          rotateRight(x);
                      }
                      setColor(parentOf(x), BLACK);
                      setColor(parentOf(parentOf(x)), RED);
                      rotateLeft(parentOf(parentOf(x)));
                  }
              }
          }
          root.color = BLACK;//最后保证根节点为黑色
      }
  ```
  
  左旋源码rotateLeft：
  
  ```java
   private void rotateLeft(Entry<K,V> p) {
       	//p为当前需要旋转的节点
          if (p != null) {
              //获取右子节点（之后会作为根节点），将其左子节点作为当前节点的右子节点
              Entry<K,V> r = p.right;
              p.right = r.left;
              
              //将r的左子节点类的parent属性保存p
              if (r.left != null)
                  r.left.parent = p;
              //并将p的父类保存到r的parent属性中
              r.parent = p.parent;
              
              //当p的父类为null，则当前r直接作为根节点
              if (p.parent == null)
                  root = r;
              //当根节点存在时，p为其left属性，则修改其left属性为r
              else if (p.parent.left == p)
                  p.parent.left = r;
              else
                  //p为right属性，则修改其right属性为r
                  p.parent.right = r;
              //最后修改r的left为p，p的parent为r
              r.left = p;
              p.parent = r;
          }
      }
  ```

##### TreeMap实例分析红黑树机制：

**以插入55、56、57、58、83、删除57、59为例：**

**前三步过程如下：**

![](C:\Users\OneMTime\Desktop\Typora图片\红黑树机制过程图一.jpg)

a、插入第一个元素，直接为根节点，因此颜色为黑色

b、在右边插入56，在自平衡时，首先设置为红色，由于没有爷爷节点，因此直接跳过

c.d.e、继续在最右变插入57，进行自平衡：

- 57设置为红色，父节点为右节点，则判断左叔节点颜色，由于不存在左叔节点，跳过

- 然后判断57新节点是否为左子节点，不是则跳过
- 将父节点56设置为黑色、爷爷节点55设置为红色，然后将55节点进行左旋，得到e

**插入58节点：**![](C:\Users\OneMTime\Desktop\Typora图片\红黑树机制过程图二.jpg)

a、58作为57的右节点，默认为红色，由于出现两红相邻，进行自平衡

b、判断左叔节点颜色，是否为红色，则设置父节点57为黑色、左叔节点55为黑色、爷爷节点56为红色

c、最后由于根节点必须为黑色，因此设置56节点为黑色

**插入83节点：**

![](C:\Users\OneMTime\Desktop\Typora图片\红黑树机制过程图三.png)

​	a、83作为58的右节点，默认为红色，由于出现两红相邻，进行自平衡

​	b、判断左叔节点颜色，是否为红色，不存在左叔节点，因此跳过；判断新节点83是否子左节点，不是则跳过；将父节点58设置为黑色、爷爷节点57设置为红色；然后进行爷爷节点57的左旋

​	c、57节点左旋，58节点作为子树根节点，57作为左子节点，整个子树作为右子树

**删除57节点：**

​	由于57节点没有任何子节点（子节点不需要重新连接），且本身为红色（不影响路径上黑节点个数相同），因此不影响红黑树性质，不需要自平衡

**插入59节点：**

![](C:\Users\OneMTime\Desktop\Typora图片\红黑树机制过程图四.png)

​	a、59作为83的左子节点，两红进行自平衡；判断左叔节点颜色，是否为红色，左数节点不存在，跳过；

​	b、判断新节点59是否为子左节点，是,则右旋父节点83，此时59代替83位置，83作为新节点继续进行平衡

​	c、将新节点83的父节点59设置为黑色，爷爷节点58设置为红色，左旋爷爷节点58

​	d、58作为59的左子节点，59作为右子树根节点

通过如上过程，可以得出红黑树的平衡方式：

##### 红黑树平衡方式：

- **每次平衡只针对于当前新节点的爷爷节点作为根节点的子树，进行操作**

- **新节点默认为红色，当父节点为红色时，则进行自平衡**

- **进行自平衡时，平衡规则通过叔叔节点颜色和新节点的子节点方向决定：**

  | 叔叔节点颜色 | 新节点方向       | 平衡规则                                                     |
  | ------------ | ---------------- | ------------------------------------------------------------ |
  | 红色         | 同父节点方向一致 | 父节点设置为黑色、叔节点设置为黑色、爷爷节点设置为红色       |
  | 红色         | 右子节点         | 父节点设置为黑色、叔节点设置为黑色、爷爷节点设置为红色       |
  | 黑色         | 同父节点方向一致 | 父节点设置为黑色，爷爷为红色，旋转爷爷节点，让父节点替换爷爷节点 |
  | 黑色         | 同父节方向相反   | 旋转父节点，让新节点替换为父节点（**使子节点和父节点方向相同**）；然后设置当前父节点为黑色，爷爷节点为红色，旋转爷爷节点，让父节点替换爷爷节点 |

  - **叔叔节点为红色时，新节点的方向不影响**

  - **平衡时的旋转方向，和旋转中心节点方向相反（旋转中心为左子节点，则其父节点右旋）**

##### TreeMap与其他容器相关：

​       TreeMap在时间复杂度上，要比hashMap搞，但可以提供对集合元素的排序，并且有很高的稳定性（维护排序结构的效率高）；但TreeMap线程不安全，不能在多线程中对共享数据进行写操作，需要通过同步锁实现（可以通过Collections.synchroinzedMap(treeMap)封装方法，实现同步）

​		在JDK8中，HashMap、ConcurrentHashMap中，也使用了红黑树：HashMap、ConcurrentHashMap当出现大量hash冲突时，会导致链表边长，影响查询效率；因此当链表超过8时，则hash冲突的数据，使用红黑树存储，优化查询效率；

​		TreeSet内部也使用了红黑树，其实现就是通过TreeMap来完成，只是所有value共享使用了一个静态Object对象

#### 6.8.3、HashMap

##### HashMap存储结构：

​		在所有hash类集合中，有三个基本存储概念：

| 名称   | 说明                                   |
| ------ | -------------------------------------- |
| table  | 存储所有节点数据，构成hash表的**数组** |
| slot   | 哈希槽，即table[i]这个内存空间         |
| bucket | 哈希桶，在table[i]上所有元素组成的集合 |

![](C:\Users\OneMTime\Desktop\Typora图片\hash表结构.jpg)	

- **每一个哈希槽都存放哈希桶中的第一节点元素**
- **哈希桶中的每个元素通过链表结构进行连接**	

##### hashMap源码解析：

在JDK8之前，hashMap存在并发环境下的**死链问题和扩容数据丢失问题**（不单单只是线程不安全），因此我们以JDK7中的HashMap源码进行分析：

- put方法：

  ```java
  public V put（K key，V value）{
      //通过key的hash值，计算hash表数组的索引
      int hash = hash(key);
      int i = indexFor(hash,table.length);
      
      //获取hash表中当前索引的元素节点类，
      for（Entry<K,V> e = table[i]; e != null; e = e.next）{
          Object k;
          //判断当前节点key是否和插入的K相同，相同则覆盖原值
          if（e.hash == hash && ((k = e.key) == key || key.equals(k)）{
              V oldValue = e.value;
              e.value = value;
              return oldValue;
          }
          //不同，则进行下一次循环，找到该节点的下一个节点                     
      }
                                
      //当该索引下的所有元素节点key都和要插入的key不同时，则进行元素新增
      modCount++;//集合操作数+1
      addEntry（hash, key, value, i）;    
      return null;
  }
                                
  void addEnt ry (int hash, K key , V value , int bucketindex) {
      //新增元素前，判断是否需要扩容并且当前索引已存在至少一个元素节点
      if ((size>= threshold) && (null ! = table[bucketindex])) {
          //扩容，创建新table，并将旧table中的数据进行转移
          resize (2 *table .length) ; 
  		hash = (null 1= key ) ? hash (key ) : 0 ; 
  		bucketindex = indexFor (hash , table.length);
      }
      
      //创建新节点
      createEntry(hash , key , value , bucketi ndex) ;
  }
                                
  void createEntry(int hash , K key , V value , int bucketindex) {
      //获取原来该索引链表的第一节点
      Entry ＜K,V> e = table [bucketindex];
      //创建一个新节点，并作为第一节点和原来第一节点链接
      table[bucketindex] = new Entry<> (hash , key , value , e );
      size++;
  }
  ```

- resize()扩容方法：

  ```java
  void resize(int newCapacity) {
      //创建一个两倍长度的新数组
      Entry[] newTable = new Entry[newCapacity];
      //将旧数组数据复制转移到新数组
      transfer(newTable , initHashSeedAsNeeded(newCapacity)) ;
      //替换全局变量table的引用
      table = newTable;
      threshold= (int)Math.min(newCapacity * loadFactor, MAXIMUM CAPACITY + 1)；
  }
  
  void transfer(Entry[] newTable, boolean rehash) {
      int newCapacity = newTable . length ;
      //遍历旧数组中所有的哈希桶
      for (Entry<K,V> e : table) {
          //遍历哈希桶中所有节点
          while (null != e) {
              //总是将旧数组中遍历的节点作为当前新数组哈希桶的第一元素，之前的第一元素作为next
              Entry<K, V> next= e . next ;
              if (rehash) { 
  				e.hash = null == e . key? 0 : hash(e . key) ; 
  				int i= indexFor(e .hash , newCapacity) ;
                  e. next= newTable[i] ;
                  newTable[i] = e;
                  e = next ;
              }
          }
      }
  }
  ```

通过源码可知：

**1、新元素会直接放在hash桶的第一个位置，即哈希槽**，这样可以更快的访问到新增元素。

**2、扩容数据丢失原因：**

- 扩容期间，旧表仍然可以插入数据，导致进行扩容转移时，已遍历的哈希槽新增数据，无法转移到新扩容数组中
- 当多个线程同时扩容时，会导致出现多个新扩容数据，每个线程完成扩容后，就会对线程共享遍历table进行覆盖，因此会导致先完成的新表被后完成的新表覆盖，从而使先完成线程中扩容时的新增数据丢失

**3、死链形成原因：**

​	当A、B线程同时指向transfer方法时，虽然每个线程都有各自的新数组，但是它们都在同时操作全局共享的旧数组中的所有entry对象，在共同进行同一索引的哈希桶节点时：

如旧表哈希桶节点元素为1——2——null，形成死链过程如下：

- A线程遍历1插入时：

  next=e.next  next=2

  e. next= newTable[i] ;  1.next=null

  newTable[i] = e;     newTable[i]=1

  e = next ;      e=2

  **此时：1.next=null  2.next=null    e=2**

- B线程完成1、2的插入：

  2——1——null

  **此时：1.next=null  2.next=1**

- A线程插入2：

  next=e.next  next=1 

  e. next= newTable[i] ;  2.next=1

  newTable[i] = e;     newTable[i]=2

  e = next ;      e=1

  **此时：1.next=null，2.next=1，e=1**

- A线程继续插入1

  next=e.next  next=null

  e.next= newTable[i] ;  1.next=2

  newTable[i] = e;     newTable[i]=1

  e = next ;      e=null

  **此时：1.next=2，2.next=1，e=null，结束遍历，newTable为：1——2——1——2......，从而形成死链**

当HashMap中存在死链后，进行put（）、get（）、transfer（）操作时，就会使线程进入死循环，使CPU占用快速上升，最后宕机

##### HashMap在JDK8中的优化：

- 当哈希表中的哈希桶元素超过8使，则使用红黑树来代替链表结构，提高hash冲突元素的查询效率
- 在JDK8中，HashMap进行扩容转移时，会将遍历的当前元素放在链表尾部，next统一为null，防止多线程扩容转移时对节点next的影响，解决死链问题（**虽然HashMap本身不能就在多线程中使用，但是我们不能控制开发者的行为，因此必须解决影响整个系统运行的风险（死链），对于系统业务的正确性交给开发者解决**）

对于HashMap并发时的数据丢失问题，还是没有无法解决；因此多线程环境下，请使用ConcurrentHashMap或同步处理

#### 6.8.4、ConcurrentHashMap

##### 线程安全的Hash集合：

- 在JDK1.0中，引入了Hashtable线程安全的hash集合，内部通过全互斥的同步方式处理并发，性能极差

- 在JDK5中，引入了ConcurrentHashMap并发容器，通过分段锁机制来细化锁粒度

  **分段锁机制：**ConcurrentHashMap提供一个内部类Segment，用于管理其hashEntry（也就是KV对）；这样就可以将整个Map集合分为若干个Segment类，它们可以同时进行操作，并且互不影响；而每个Segment类中的hashEntry操作，则通过加锁的方式，保证线程安全

- 在JDK8中，对ConcurrentHashMap进行了优化：
  - 引入红黑树结构，当哈希桶中的元素超过8后，链表改为红黑树，提供查询效率
  
  - 分段锁机制浪费内存空间，并在实际使用中map竞争同一个锁的概率很小，这样反而会使更新等操作时间更长；因此采用CAS来减少锁的使用，当发生hash冲突时，才使用锁来保证线程安全
  
    **CAS机制：**Compare And Swap，比较并替换，CAS机制中有3个基本操作数：V（内存地址）、A（预期值，保存旧内存地址中的值）、B（要修改的新值），只有当V中的值为A时，才执行把B的值赋值给V的操作，否则就操作失败重新执行； 
  
  - 优化size（）计算方式，提高并发能力、提供更大的size数量表示（JDK7为2^31-1;JDK8为2^63-1）

##### JDK8中的ConcurrentHashMap源码解析：

- concunrrentHashMap基本属性和内部类：

  ```java
  //节点数组，concunrrentHashMap初始化时，默认大小16
  transient volatile Node<K,V>[] table;
  
  //扩容新节点数组，默认为null，当扩容时使用，大小为原数组的两倍
  private transient volatile Node<K,V>[] nextTable;
  
  //节点类，实现了Entry接口，存储KV数据和hash表结构，内部属性有key、value、hash、next
  static class Node<K , V> implements Map.Entry<K , V> { . . . )
  
  //用于维护哈希桶中红黑树的读写锁，实现对红黑树操作的线程安全   
  static final class TreeBin<K, V> extends Node<K , V> { .. . )
   
  //红黑树节点（普通节点为链表结构）    
  static final class TreeNode<K, V> extends Node<K, V> { . .. )
  
  //扩容转发节点，实现将扩容转移时原数组的新增节点转发到新数组中
  static final class ForwardingNode<K, V> extends Node<K, V> { ... )
  
  //占位加锁节点，该节点执行某些方法时，会对其加锁    
  static final class ReservationNode<K, V> extends Node<K,V> { ... }
  
  //控制table初始化和扩容的参数变量：
  //=-1，正在初始化
  //=-n，表示（n-1）个线程正在扩容中
//>0,正常使用，并表示当前table容量
  //=0，默认值，则初始化时使用默认容量进行初始化    
private transient volatile int sizeCtl;                                               
                                                              
  static final int MIN TREE FY CAPACITY=64;  //集合所有元素要大于等于64，才进行红黑树转化
  static final int TREEIFY THRESHOLD = 8 ;   //hash桶元素个数要超过8，才进行红黑树转化
  static final int UNTREEIFY THRESHOLD = 6;  //hash桶元素个数减少到6时，红黑树才回退为链表                                           
  ```
  
  - 四种类型的Node节点：
  
  | 节点类型        | 作用                                                   |
  | --------------- | ------------------------------------------------------ |
  | Node            | 正常node节点                                           |
  | ForwardingNode  | 扩容转发节点（用于扩容转移时，对原数组新节点进行转发） |
  | ReservationNode | 加锁节点                                               |
  | TreeNode        | 红黑树节点                                             |
  
  - 红黑树和链表转化条件：
    - 哈希桶元素个数超过8
    - table长度大于等于64；当小于64时，条件1触发后，则会通过扩容减低冲突个数
  
  - 红黑树和链表的转化过程：
    
    - 链表转化为红黑树：
    
      ​		通过同步块锁住当前hash槽节点，从而防止其他线程对当前hash桶进行操作，然后通过CAS替换hash槽中原有链表；并将红黑树的根节点TreeNode保存到BinTree.first中
    
    - 红黑树转链表：
    
      ​		通过BinTree.first获取当前红黑树根节点，完成整个红黑树元素遍历，重新转化为链表，然后通过CAS替换原有红黑树；**BinTree中内置读写锁**，通过它来访问红黑树从而实现同步

- put方法:

  ​		concurrentHashMap的put方法和HashMap的思想基本一致，区别在于增加了锁的处理，put流程如下：

  ![](C:\Users\OneMTime\Desktop\Typora图片\concurrentHashMap插入流程图.png)

- 当table中当前key对应的hash槽为null时，则使用CAS插入；当不为null'时，先判断table释放处于扩容状态，是，则通过该槽预留的ForwardingNode节点，将插入数据转发到nextTable中；不是，则锁住该hash槽，进行插入

- ForwardingNode：

  ​		在table扩容时使用，nextTable在扩容转移时，会遍历所有哈希槽，当哈希槽不为null时，则将table中当前槽的所有元素复制转移到nextTable；然后在table当前槽中插入一个ForwardingNode节点，该节点会在nextTable初始化完成前，将其他线程对该槽进行元素插入行为捕捉，并协助转发到nextTable中

- ReservationNode：

  ​		该节点使用在concurrentHashMap的**computeIfAbsent系列方法**中，computeIfAbsent系列方法是通过对key做判断，然后执行一段逻辑后，再插入KV对；因此需要保证判断key不存在后，到插入KV对之前，该hash槽中的元素不会发生改变，因此使用ReservationNode节点放入需要插入新节点的位置，然后通过该对象锁执行其他操作，作为插入KV对象，使用Node节点代替ReservationNode节点

  ​		**将ReservationNode作为预留节点使用，防止当前hash桶中的节点被其他线程插入元素**

- size方法优化：

  - JDK7：

    ​		进行size方法时，对在没加锁的情况下，遍历计算所有Segment的modCount和size，然后比较前一次modCount和size，相同时，则说明遍历期间没有执行增删改方法，直接返回size总和；不同时，则重新无锁遍历，直到重复计算第三次时（比较两次都不相同后），则开始有锁遍历（此时就能保证遍历期间不会有其他线程干扰），最后释放所有Segment上的锁，返回size总和

  - JDK8：

    ​		在JDK8中，避免了锁的使用，通过使用baseCount、countCells两个属性，搭配CAS方式，优化了并发环境下Size（）的执行，过程如下：

    - 默认认为并发量较小，优先使用CAS方式直接遍历更新baseCount，记录size总数
    - 当遍历过程中发生冲突时，则认为并发量较高；则使用countCells属性，它是一个counterCell数组，counterCell内部有一个value属性，用于维护size值；每当插入数据时，则从数组中随机取出一个counterCell，进行value+1；该过程使用CAS方式，如果多次出现多个线程，使用同一个counterCell记录时，则说明并发量很高，因此对counterCells进行扩容，减少冲突
    - 在counterCells扩容期间，会尝试更新baseCount值，来记录size总数

    因此，进行size方法时，只需要将baseCount加上counterCells内的数据，就能得到size总数；**整个过程就是利用CAS方式，避免使用锁，并且通过使用多个共享变量，来维护size总数，减少高并发下，CAS的冲突**

## 7、并发与多线程

### 7.1、并发与多线程基本概念

#### 7.1.1、并发与并行

- 并发：某个时间段内，多任务交替处理的能力
- 并行：同时处理多任务的能力，目前CPU已经发展为多核，因此可以同时执行多个互不依赖的指令及执行块

它们的目标都是尽快完成所有任务，以医生坐诊为例，一个科室有两个专家同时问诊，这就是并行任务；一个医生时而问诊，时而查看化验单，然后继续问诊，这就是并发，在多个任务中来回切换

并发程序有如下特点：

1. 并发程序之间由相互制约的关系；直接制约：一个程序需要另一个程序的计算结果；间接制约：多个程序同享资源，如处理器、缓冲区
2. 并发程序的执行过程是间断的，因此程序需要记忆现场指令和执行点
3. 在并发数设置合理，CPU处理能力足够强的情况下，并发会提供程序运行效率

#### 7.1.2、线程与进程

- 线程：线程是CPU调度和分派的最小单位
- 进程：进程是计算机资源分配的最小单位

线程与进程的关系：

1. 一个进程可以包含多个线程，一个程序至少有一个进程、一个进程至少有一个线程
2. 同一个进程内的所有线程，共享该进程中的所有资源
3. 进程拥有独立的内存单元，不容易实现资源共享
4. 进程切换和创建的开销大于线程
5. 线程不能独立运行，要建立在进程基础上

#### 7.1.3、线程安全

​		多线程的作用是提高任务平均执行速度，但也会导致程序可理解性变差，增加编程难度。同时多线程的使用，并不能没有节制，要根据运行环境，定义合适的线程数。如工人板砖到12楼，10个人一起搬运要比1个人快；但10000个人搬运时，反而会因为楼道拥堵而影响速度，因此要合理配置工人数

​		线程可以拥有自己的操作栈、程序计数器、局部变量表等资源，它与同进程的其他线程共享所有进程资源。线程在生命周期内存在多种状态：NEW（新增状态）、RUNNABLE（就绪状态）、RUNNING（运行状态）、BLOCKED（阻塞状态）、DEAD（终止状态）五个状态：

![](C:\Users\OneMTime\Desktop\Typora图片\线程状态图.png)

- New，**新键状态，是线程被创建且未启动的状态**。线程创建方式有三种：
  1. 继承Tread类，重写run方法
  2. 实现Runnable接口，相对于第一种，继承Thread类往往**不符合里氏替换原则（每个子类都能替换父类进行工作，且行为不发生变化），每个线程任务都需要重新创建一个类，进行编写**；而实现Runnable接口可以是线程编写更加灵活，对外暴露细节较少，让使用者专注于实现线程任务的run（）方法上
  3. 实现Callable，相对于第二种，call（）方法有返回值，可以获取到任务完成后的执行结果，并且call（）方法可以抛出异常；而Runnable只能通过setDfaultUncaughtExceptionHandler（）额外的异常处理器，才能将子线程中的异常交给主线程处理

- RUNNABLE，**就绪状态，是调用start（）之后、运行run方法代码之前的状态**。注意的是Tread对象的start（）方法不能多次调用，否则回抛出IllegalStateException异常

- RUNNING，**运行状态，是run（）正在执行时线程的状态**。此时线程可以由于多种原因，而退出RUNNING，如CPU时间片使用完（进入就绪状态，等待继续执行run（）方法代码）、wait、sleep、未竞争到锁等

- BLOCKED，**阻塞状态，线程被阻塞，有如下种情况：**
  1. 同步阻塞：run（）方法中使用了锁，并且锁被其他线程占用
  2. 主动阻塞：调用了Thread的某些方法，主动让出了CPU执行权；如sleep（）、join（）等
  3. 等待阻塞：执行了wait（）,直到执行notify()方法，才会被唤醒

- DEAD，**终止状态，是run（）执行结束，或因异常退出后的状态，此状态是不可逆转的**

  **线程安全问题只会在多线程环境中出现，为了保证高并发场景下的线程安全，可以从以下四个维度考量**

  **1、数据单线程内可见**

  ​		单线程总是安全的。通过限制数据仅在单线程内可见，就可以避免数据被其他线程篡改。如线程任务方法中的局部变量，它存储在方法栈帧的局部变量表中，与其他线程毫无瓜葛。ThreadLoacl就采用该方式实现线程安全

  **2、只读对象**

  ​		只读对象总数线程安全的。它的特性是允许复制、拒绝写入。最典型的只读对象：String、Integer。一个对象需要拒绝写入，则满足如下条件：

  - 使用final关键字修饰类，避免被继承;防止子类重写方法，提供额外修改属性的能力，从而向上转型为父类进行使用，从而破坏父类的不可变性质

  - 使用private final关键字避免属性值被修改
  - 不提供任何更新属性值的方法，并且方法不返回可变对象属性的引用，即引用类型属性的引用不对外暴露

  **3、线程安全类**

  ​		某些线程安全类的内部有明确的线程安全机制。如StringBuffer，就是一个线程安全类，内部采用synchronized关键字修饰相关方法

  **4、同步与锁机制**

  ​		如果想要对某个对象进行并发更新操作，该对象又不属于上述三类（对象仅单线程可见、对象为只读、对象为线程安全类）；则需要开发者在代码中使用同步机制来达到线程安全

#### 7.1.4、JUC并发包

**线程安全的核心理念：要么只读、要么加锁。JDK5.0提供了JUC（java.util.concurrent）并发包,来提供java并发编程的易用性,由Doug Lea主导设计**

**JUC并发包组成：**

1、线程同步类。这些类使线程间的协调更加容易，从而淘汰了Object的wait（）、notify（）同步方式。主要代表有：

- CountDownLatch  倒数锁，让多线程任务同时开始并发执行
- Semaphore  信号量，限制资源并发访问量，但不保证资源的线程安全
- CyclicBarrier  循环栅栏，让多线程任务执行到某个节点等待，直到所有线程都到达后，再全部唤醒继续执行
- Exchanger  交换器，实现两个线程的数据交换，但先提交数据的线程会阻塞等待获取交换的数据

2、并发集合类。保证线程安全的同时，优化提升了并发性能，包括：ConcurrentHashMap、ConcurrentSkipListMap、CopyOnWriteArrayList、BlockingQueue等

3、线程管理类。引入了线程池的概念，来管理线程对象的创建，并提供ScheduledExecutorService实现定时任务，代替Timer、TimerTask（java的定时器机制）

4、锁相关类。以Lock接口为核心，在实现场景中引入了不同类型的锁相关类：

- ReentrantLock 可重入锁，和synchronized类似，可以重复使用，但加锁和解锁需要手动，并且加锁和解锁次数要一致
- ReentrantReadWriteLock 可重入读写锁，实现读写操作的锁分离

### 7.2、锁

#### 7.2.1、锁的特性：

​		计算机锁从最开始的悲观锁，发展到后来的乐观锁、偏向锁、分段锁等。锁主要提供两个特性：互斥性和不可见性

- 互斥性：在同一时间内，只能允许一个线程持有某个锁

- 可见性：即内存可见性，每一个线程都有独立的内存空间，即线程栈：

  - ​	当线程进行全局变量的计算时，会先从主存中取出该全局变量的值，然后进行计算，如果我们不使用锁，就会导致A、B来两线程同时对该变量值进行操作，最后写入主存的值为其中一个线程的计算结果，即理论上该值应该计算两次，但实际只计算了一次。即数据在两个线程中的计算是不可见的

  - ​	当使用锁时，就能保证数据同一时间只能在一个线程中计算，同时该线程释放锁后，会立即将变量的修改写入主存中，随后另一个线程获取锁时，就直接能获取到最新的变量值。因此实现了数据在线程间的可见性（每个线程都能获取最新值）

#### 7.2.2、JUC并发包中的锁类：

​		JUC并发包中，使用Lock作为锁类的顶层接口，其实现逻辑并没有用到synchronized，而是利用了volatile关键字的可见性，即ReentrantLock类：

​		ReentrantLock类中对Lock接口的实现，主要依赖于成员变量Sync，Sync类继承了AbstractQueuedSynchronizer（AQS），它是JUC并发包实现同步的基础工具。

- AQS：该类定义一个 volatile int state 变量作为共享资源，当线程获取资源失败，则进行同步FIFO队列中等待，如果成功获取资源就执行临界区代码。执行完释放资源后，就会通知同步队列中等待的线程出队获取资源并执行

  - 在ReentrantLock中，初始化定义state=0，获取资源加锁则+1，释放资源解锁则-1

  - 在CountDownLatch中，初始化定义state=count，执行countDown（）方法-1，直到state为0时，唤醒所有调用await（）方法的线程。并且此时线程再调用await（），并不会等待，即CountDownLatch是一次性的
  - 在CyclicBarrier中，和CountDownLatch类似，但在state=0，唤醒所有调用await（）方法的线程后，会将state重置为parties
  - Semaphore中，初始化定义state=permits，当state>0时就能获得锁，并且每一个线程获得锁，则将state减1，当state=0时，就会阻塞其他线程，等待锁的释放。因此当permits>0时，Semphore就为共享锁（则需要保证当前锁作用的代码块，其线程安全，只是为了减少并发量，提升并发执行效率）

  - **StampedLock，JDK8中引入，是对ReentrantReadWriteLock的改进**

#### 7.2.3、同步代码块（Synchronized）

​		java提供Synchronized关键字来同步代码块，该关键字有两种方式进行加锁操作：

- 在方法签名中使用synchronized，这样整个方法执行都会是同步的；并根据方法是否为 static，来确定锁的类型（对象锁/类锁）
- synchronized（对象/类.class）{代码块}，使用该语法方式同步代码块，这样可以缩小锁的作用范围和时间，并且可以选择锁类还是对象

**synchronized锁使用原则：**

​		锁定义的范围尽可能小，锁的时间尽可能段，即能锁对象，就不要锁类；能锁代码块，就不要锁方法

**synchronized锁的实现：**

synchronized锁特性由JVM负责实现。在JDK不断优化迭代中，synchronized锁的性能也得到了极大的提高，特别是对偏向锁的实现。JVM底层实现如下：

​		JVM底层通过监视锁来实现synchronized同步。监视锁机monitor，每个对象都会带有该隐藏字段。当使用synchronized时，JVM会根据当前synchronized的使用环境，找出加锁对象，判断该对象的monitor字段的状态，来判断加锁执行代码块，通过字节码进行分析：

​		1、当调用一个synchronized修饰的方法时，在方法元信息中，会使用ACC_SYNCHRONIZED表示该方法为同步方法

​		2、此时就用monitorenter指令，获取该方法所处对象的monitor，当获取的monitor=0时，说明当前对象没有被其他线程加锁，则该线程对对象加锁并执行后序代码，并将monitor+1

​		3、如果当前线程已经持有了monitor，则继续将monitor+1（即线程可以重复对某对象加锁）

​		4、若跟当前monitor返回 <0,则说明对象被其他线程加锁，此时线程就进入阻塞状态

**在JDK6中**，对synchronized进行优化，提供了三种锁的实现，偏向锁、轻量级锁、重量级锁，并提供三者的自动升级和降级：

- 偏向锁：当目前只有一个线程使用该锁时，在第一次获取锁后，**锁状态由轻量级转变为偏向锁**，该**锁对象（MarkWord）**的ThreadId字段会记录下当前线程的ID，后面该线程又需要获取锁时，就判断ThreadId释放和线程ID相同，相同，就不需要获取锁触发同步，直接执行代码；不相同，则**锁状态由偏向锁转化为轻量锁**

  **偏向锁不是互斥锁**

- 轻量级锁：当该锁被多个线程访问时，锁状态由**偏向锁转变为轻量级锁**；此时其他线程并不会由于无法获取锁而阻塞，而是通过自旋的方式不停尝试获取锁

  **轻量级锁不是互斥锁，等待获取轻量级锁的线程并不会阻塞，并且自旋也没有公平性（等待时间长短，和尝试获取锁的成功率无关）**

  **自旋锁：其实是轻量级锁中自旋获取锁的一种方式，并不是一个真正的锁，通过CAS机制，来尝试获取锁，防止线程阻塞，增加CPU的线程切换；但是过多线程和过长时间的尝试，会使CPU做无用功**

- 重量级锁：锁处于轻量级锁状态，出现线程自旋一定次数的时候，还没有获取到锁时，则**锁状态由轻量级锁转变为重量级锁**；此时所有线程当获取锁失败时，直接进入阻塞状态

  **重量级锁是互斥锁，会导致其他线程阻塞**

**在锁的升降级过程中，都是用了CAS机制，进行锁的状态转变、获取和释放**

### 7.3、线程同步

**1、资源共享有两种原因：**

- 资源短缺，多线程共享CPU就是从资源短缺的角度考虑

- 共建需求，多线程共享同一个变量，就是从共建需求考虑


**2、原子性：**		

​		在多线程中对同一个变量进行写操作是，如果操作没有原子性，就可能产生脏数据。而操作原子性就是该操作是一个不可分割的一系列指令，在执行完毕前不会被任何其他操作中断，要么全部执行，要么全部不执行。因此**如果每个线程的对共享资源的修改都是原子操作，则就不存在线程同步问题，synchronized就是通过互斥性，来实现线程执行同步代码操作的原子性**

​		以i++操作为例，它分为三步，ILOAD->IINC->ISTORE,即加载变量i的值到操作栈中，变量i进行自增，然后将操作栈的值保存到变量表中（根据i++结果赋值来进行）

- **java赋值操作的原子性：**

  - 除long、double外，其他基本数据类型变量的赋值通过JVM来保证其原子性（在64位机器上，long、double赋值具有原子性）
  - 对于reference引用的赋值，根据JLS原理，JVM会自动实现其原子性（实际操作是：ALOAD ->ASTORE，先将引用压入操作栈，然后出栈放入变量表）

  由于这些操作的原子性都是交给JVM实现的，因此和操作系统平台和JVM有关，因此在实际编程过程中，我们不能把它们当作原子性的操作，并认为线程安全

**3、线程同步：**

​		同步在我们生活中随处可见，比如排队。而计算机的线程同步，就是线程之间按某种机制协调异常执行，当一个线程对某个内存进行操作时，其他线程就不可对该内存地址进行操作。实现线程同步的方式有很多，比如同步方法、锁、阻塞队列等

#### 7.3.1、Volatile

​		每一个线程都有自己独占的内存区域，如操作栈、局部变量表等。它们是JVM内存布局中，相当于CPU的缓存，通过将引用类型变量在堆内存中的副本保存到本地内存中，让线程在本地内存实现中对变量进行操作（**缓存执行速度大于内存,因此执行效率更高**)，执行结束后，再同步到堆内存中。这样就会有时间差，这段时间内，线程对该副本的本地操作，对于其他线程都是不可见的。

​		volatile，英译“挥发、不稳定的”，延伸意思就是敏感的。当使用volatile修饰变量时，线程对该变量的每次操作前，都会从主存中获取最新值，修改完成后，则会将最新值立即同步到主存中，从而保证该变量的可见性，并且阻止**指令重排**的发生；

- **多线程变量不可见：**

  ​		由于CPU缓存机制，导致缓存和内存数据的不一致性；在一定时间内，缓存数据不会被更新（CPU会根据某些策略来对缓存进行清理）

  ​		当线程加锁时，CPU会主动更新缓存数据；当线程释放锁时，CPU会主动将缓存数据立即更新到更新到主存

- **指令重排：**

​		在单例模式中，如果没有使用同步锁，则在某个线程new 进行创建对象时，编译器执行过程如下：

​		1、分配内存空间

​		2、初始化对象

​		3、将内存空间地址赋值给对象引用

但由于编译器的指令优化重排，会在分配内存空间后，直接将地址赋值给对象引用，导致此时对象并没有完成初始化；而另外一个线程再调用get方法时，就会获得一个初始化不完整的对象；而通过volatile，就可以防止指令重排，只有对象实例化完成后，才会返回内存空间地址，进行引用赋值

- **volatile的使用：**		

  ​		volatile解决了共享变量在多线程中的可见性，但不具备synchronized的互斥性。因此volatile变量的操作并不具有原子性。

  ​		volatile用于一写多读的并发场景，比如并发容器CopyOnWriteArrayList，它对于写操作会使用进行加锁，然后使用一个volatile修改的数组变量，保存最终修改后的数据，从而在写操作成功后，立即将数据同步給其他线程；**但由于volatile变量的所有操作，都需要同步到内存变量中，因此线程的执行速度会下降**


#### 7.3.2、信号量同步

​		**信号量同步是指在不同线程之间，通过传递同步信号量，来协调线程执行的先后次序**

- **CountDownLatch（倒数锁）**，以时间维度作为信号量同步，当线程使用CountDownLatch进行等待阻塞后，当CountDownLatch的倒数值达到0时，唤醒所有被CountDownLatch等待阻塞的线程，此时CountDownLatch失效（还是能执行countDown(）、await()方法，但没有作用）

  ```java
  //子线程任务类
  public class RunnableTask implements Runnable {
  	private String content;
  	private final CountDownLatch count;
  
  	public RunnableTask(String content, CountDownLatch count) {
  		this.content = content;
  		this.count = count;
  	}
  
  	@Override
  	public void run() {
  		System.out.println(content+"执行");
  		count.countDown();
  	}
  }
  
  //主线程开启子线程、倒数锁
  public static void main(String[] args) {
  	CountDownLatch count = new CountDownLatch(3);
  		
  	Thread thread1 = new Thread(new RunnableTask("Thread1", count));
  	Thread thread2= new Thread(new RunnableTask("Thread2", count));
  	Thread thread3 = new Thread(new RunnableTask("Thread3", count));
  		
  	thread1.start();
  	thread2.start();
  	thread3.start();
  		
  	//通过倒数锁，使主线程睡眠（保证所有子线程执行完后，再执行主线程）
  	try {
  		count.await();
  	} catch (InterruptedException e) {
  		e.printStackTrace();
  	}
  	System.out.println("所有子线程执行完成");
  ```

- **CyclicBarrier（循环栅栏）**，以时间维度作为同步信号量，线程使用CyclicBarrier进行等待阻塞，其阻塞线程数达到指定值时，同时唤醒所有等待阻塞线程。并且重新重置CyclicBarrier，继续监控后序使用CyclicBarrier等待的线程

  ```java
  //子线程任务类，每个阶段都会等待
  public class RunnableTaskCyclic implements Runnable {
  	private String content;
  	private final CyclicBarrier cyclicBarrier;
  
  	public RunnableTaskCyclic(String content, CyclicBarrier cyclicBarrier) {
  		this.content = content;
  		this.cyclicBarrier = cyclicBarrier;
  	}
  
  	@Override
  	public void run() {
  		try {
  			System.out.println(content + "完成第一次计算");
  			cyclicBarrier.await();
  			System.out.println(content + "完成第二次计算");
  			cyclicBarrier.await();
  			System.out.println(content + "完成第三次计算");
  			cyclicBarrier.await();
  			System.out.println(content + "完成最后计算");
  		} catch (InterruptedException | BrokenBarrierException e) {
  			e.printStackTrace();
  		}
  	}
  }
  
  //主线程使用循环栅栏
  public static void main(String[] args) {
  	//当栅栏数（循环栅栏拦截的线程数）达到指定值后，执行相应方法,最后唤醒所有线程
  	CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new Runnable() {
  		@Override
  		public void run() {
  			System.out.println("合并结果计算");
  		}
  	});
  	// 循环创建、执行子线程
  	for (int i = 0; i <3; i++) {
  		new Thread(new RunnableTaskCyclic("线程"+i, cyclicBarrier)).start();
  	}
  }
  ```

- **Semaphore（信号量）**，以信号维度作为同步信号量，它定义以所有使用它的子线程，最大并发执行数，在线程任务执行前，先调用**acquire（）方法**，Semaphore保存了当前执行的线程数，如果未达到最大并发数，则线程继续执行任务；如果到达最大并发数，则阻塞线程，并使用一个链表存放阻塞线程。当出现其他线程完成任务执行**release（）方法**退出Semaphore监控时，则立即唤醒链表中的第一个线程

  ```java
  	//指定信号量的限制线程数，开启公正性（等待最久的线程，下一个执行）
  	Semaphore semaphore = new Semaphore(2, true);
  	//定义子线程任务
  	Runnable runnable = new Runnable() {
  		@Override
  		public void run() {
  			try {
  				//该段代码只能同时被2个线程使用，其他线程等待
  				//通过acquire（）、release()方法标记需控制访问的代码块的起止点
  				semaphore.acquire();
  				System.out.println(Thread.currentThread().getName());
  				Thread.sleep(3000);
  				semaphore.release();
  			} catch (InterruptedException e) {
  				e.printStackTrace();
  			}
  		}
  	};
  	//创建多个子线程，并执行
  	for (int i = 0; i < 10; i++) {
  		new Thread(runnable).start();
  	}
  ```

- **CountDownLatch（倒数锁）和CyclicBarrier（循环栅栏）的比较**：

  - 相同点：它们都是以时间维度，作为同步信号量；当自身属性达到指定值时，此刻释放所有线程资源，让子线程继续执行

  - 不同点：CountDownLatch是一次性的，而CyclicBarrier可以循环利用

    ​				有CountDownLatch参与的线程，既可以是用于倒数的线程，又可以是等待倒计时的线程；CyclicBarrier都参与等待计数的线程，但CyclicBarrier的构造方法提供一个runnable参数，用于定义栅栏开启前（唤醒所有等待线程前）需要执行的代码

**JUC并发包提供的信号量同步工具类，无论从性能、安全性、方便性上，都远优于开发者手动使用对象的wait（）和notify（）方式协调线程间的同步。因此开发者应该尽量使用信号同步类**

### 7.4、线程池

​		多线程可以更加充分合理地协调使用CPU、内存、网络、I/O等系统资源，而线程创建需要开辟虚拟机栈、本地方法栈、程序计数器等线程私有地本地内存空间。在线程被销毁时，就需要对这些内存空间进行资源回收，而频繁地创建和销毁线程，就大大浪费了使用在本地内存创建和回收上的系统资源，增加并发编程风险。另外，当服务器负载过大时，我们需要新线程能够等待或之间拒绝服务。这些都无法通过线程自身来解决，所以通过线程池就可以来协调多个线程，其作用如下：

- 利用线程池管理和复用线程，控制最大并发数
- 实现任务线程队列缓存策略和拒绝机制

- 实现线程执行与时间相关功能，如定时执行、周期执行
- 隔离线程环境，通过两个不同的线程池，来将两种类型线程隔离，配置不同的线程池策略，避免各类型线程池互相影响；

#### 7.4.1、ThreadPoolExecutor

​		JUC并发包，提供了一整套线程池框架，常用核心类就是ThreadPoolExecutor（线程池执行器），通过该类源码来了解线程池基本属性：

##### ThreadPoolExecutor构造方法

```java
public ThreadPoolExecutor(
	int corePoolSize,//核心线程数
    int maximumPoolSize,//最大线程数
    long keepAliveTime,//线程空间时间
    TimeUnit unit,//空闲时间单位
    BlockingQueue<Runnable> workQueue,//待执行任务的缓存队列
    ThreadFactory threadFactory,//线程工厂
    RejectedExecutionHandler handler//拒绝策略  ){
         if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
    }
```

1、corePoolSize，常驻核心线程数。如果等于0，则任务执行完后，没有任何请求进入时，则销毁线程池中的线程；如果大于0，则即使任务完成，核心线程也不会被销毁。**该值设置非常关键，过大会浪费资源，过小会导致线程频繁创建和销毁**

2、maximumPoolSize，最大线程数。必须大于等于1，如果待执行的线程数大于该值，则待执行的任务（runnable）进入缓存队列，等待有空闲线程后，再出队执行。如果maximumPoolSize=corePoolSize，则该线程池为固定大小线程池，内部不会发生线程的创建和销毁

3、keepAliveTime，线程空闲时间。当线程空闲时间达到keepAliveTime值时，线程会被销毁，直到只剩下corePoolSize个线程为止，避免过多空闲线程，浪费内存和句柄资源。默认情况下，线程池的线程数大于corePoolSize时，keepAlive才起作用；但当ThreadPoolExecutor的allowCoreThreadTimeOut变量为true时，核心线程也会超时回收

4、TimeUnit，时间单位，keepAliveTime通常使用TimeUnit.SECONDS(秒)

5、workQueue，缓存队列。当请求线程数大于maxmumPoolSize时，线程进入BlockingQueue阻塞队列。使用两个锁来控制队列的出栈、入栈，保证线程安全

6、threadFactory，线程工厂。用于生成一组相同任务的线程。线程池的命名可以通过thradFacotry来添加线程名前缀进行区分。从而就能得知线程是由哪个工厂生成，来自于哪个线程池

7、handler，拒绝策略。当任务缓存队列达到上限时，可以通过该策略来处理请求，用于线程池的限流保护

​		在构造方法中，对这七个参数进行了校验：corePoolSize不能小于0、maximumPoolSize必须大于等于1，并且不能小于corePoolSize、keepAliveTime必须大于等于0、workQueue、threadFactory和handler不能为null

##### 自定义handler（拒绝策略）

ThreadPoolExecutor提供四个公开的静态内部类，用于定义其拒绝策略：

- AbortPolicy（默认值）：丢弃任务并抛出RejectedExecutionException（拒绝执行）异常
- DiscardPolicy：直接丢弃任务，非常不推荐
- DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列
- CallerRunsPolicy：跳过线程池，调用任务run（）方法直接执行（使用主线程执行）

​        当线程池达到最大值、并且缓存队列已满，就触发拒绝策略；但这四种默认策略都太过简单，或者没有解决实质性问题（**即当前线程池的属性没有设计好**），因此在实际工作中，应该自定义拒绝策略

```java
public class MyThreadPoolPolicy implements RejectedExecutionHandler{
	@Override
	public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
        //当线程池缓存队列满时，打印线程池状态信息
		System.out.println(executor.toString());
	}
}
```

##### 自定义threadFactory（线程工厂）

​		线程工厂可以对线程做出明确的标识，并在不同的线程中，区别它们来自于哪个线程池。让我们更好的分析问题原因，**在实际工作中，必须使用线程工厂来对线程池生产的线程进行标识**

```java
public class MyThreadFactory implements ThreadFactory {
	private final String namePrefix;// 线程名前缀
	private final AtomicInteger nextId = new AtomicInteger(1);// 线程计数，初始值为1

	public MyThreadFactory(String namePrefix) {
		this.namePrefix = namePrefix;
	}

	@Override
	public Thread newThread(Runnable r) {
		String name = namePrefix + nextId.getAndIncrement();// 类似于i++;
		Thread thread = new Thread(r, name);
		System.out.println(thread.getName() + "线程已创建");
		return thread;
	}
}
```

##### ThreadPoolExecutor线程池状态

```java
//ctl为AtomicInteger类型，右边29位表示当前工作线程数，左边3位标识线程池状态
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```

```java
//Integer.size=32,因此count_bits=29，用于进行int参数的位运算，表示线程池状态
private static final int COUNT_BITS = Integer.SIZE - 3;
```

ThreadPoolExecutor线程池具有五种线程池状态：

- RUNNING：运行状态，接受新任务，并处理排队任务
- SHUTDOWN：关闭状态，不接受新任务，但继续处理已排队任务
- STOP：停止状态，不接受新任务，并立即关闭正在处理任务
- TIDYING：整理状态，所有任务已终止，workerCount=0，并会自动调用terminated（）方法
- TERMINATED：终止状态，terminated（）方法调用完成

当调用shutdown（）方法时，线程池会从RUNNING转变为SHUTDOWN;

当调用shutdownNow（）方法时，线程池会从RUNNING转变为STOP;

当在SHUTDOWN、STOP状态下，线程池完成所有任务关闭后，转化为TIDYING,并调用terminated（）方法;

当terminated（）方法完成时，转化为TERMINATED状态

![](C:\Users\OneMTime\Desktop\Typora图片\线程池状态图.jpg)



​		它们通过和COUNT_BITS属性相关的位运算，得到一个int类型数字来表示相应线程池状态，然后将**ctl**变量和各个线程池状态变量值进行比较，得到当前线程池状态

##### ThreadPoolExecutor任务执行流程

- **execute方法**，判断线程池是否可以执行任务，并选择

  ```java
  public void execute(Runnable command) {
      //任务对象不能为null
  	if (command == null)
  		throw new NullPointerException();
      
      //获取表示当前线程池状态和工作线程数的int值
  	int c = ctl.get();
      //判断工作线程池数是否小于核心线程数，则将任务交给已有线程处理，并保证工作线程数小于核心线程数
  	if (workerCountOf(c) < corePoolSize) {
  		if (addWorker(command, true))
  			return;
  		c = ctl.get();
  	}
      
      //不是，判断线程池处于运行状态，然后将任务放入工作队列（可以成功，未满）
  	if (isRunning(c) && workQueue.offer(command)) {
  		int recheck = ctl.get();
          //又一次判断线程是否处理运行状态
          //不在运行状态，则删除该任务，并执行拒绝策略
  		if (! isRunning(recheck) && remove(command))
  			reject(command);
        	//处于工作状态，则判断当前工作线程是否为0，为0则创建一个新线程执行,并且保证工作线程数小于最大线程数（避免核心线程数为0，从而触发创建新线程）
     		else if (workerCountOf(recheck) == 0)
  			addWorker(null, false);
          
          //工作线程不为零，则让任务在工作队列中等待被执行
      }
      //放入工作队列不成功（已满），且没有空闲线程执行，则执行拒绝策略
  	else if (!addWorker(command, false))
  		reject(command);
  }
  ```

- **addWorker方法**，使用CAS机制将任务真正的交给线程执行

  ```java
    private boolean addWorker(Runnable firstTask, boolean core) {
          retry://定义语法标签，使用 break/countinue retry快速跳出多重循环
          for (;;) {
              int c = ctl.get();
              int rs = runStateOf(c);
  
              //检测工作队列不为空，、线程池至少为shutdown状态、当前任务不为null
              if (rs >= SHUTDOWN &&
                  ! (rs == SHUTDOWN &&
                     firstTask == null &&
                     ! workQueue.isEmpty()))
                  return false;
  
              //当前工作线程数不能超过最大线程数/核心线程数（根据参数core决定）、和2^29(保证不影响左边3位所表示的线程状态值)
              for (;;) {
                  int wc = workerCountOf(c);
                  if (wc >= CAPACITY ||
                      wc >= (core ? corePoolSize : maximumPoolSize))
                      return false;
                  
                  //此时，将当前工作线程数+1，跳出循环
                  if (compareAndIncrementWorkerCount(c))
                      break retry;
                  
                 //如果工作线程数+1操作不成功，则判断线程池是否属于runnning状态，不属于则跳出循环，从retry入口开始重新判断;属于则重新最近循环进行+1（CAS操作） 
                  c = ctl.get();  // Re-read ctl
                  if (runStateOf(c) != rs)
                      continue retry;
                  // else CAS failed due to workerCount change; retry inner loop
              }
          }
  
        	//创新新线程，执行任务
          boolean workerStarted = false;
          boolean workerAdded = false;
          Worker w = null;
          try {
              w = new Worker(firstTask);
              final Thread t = w.thread;
              if (t != null) {
                  //使用同步锁
                  final ReentrantLock mainLock = this.mainLock;
                  mainLock.lock();
                  try {
                  	//获得锁后，再次检测线程池状态、新线程状态
                      int rs = runStateOf(ctl.get());
                      if (rs < SHUTDOWN ||
                          (rs == SHUTDOWN && firstTask == null)) {
                          if (t.isAlive()) // precheck that t is startable
                              throw new IllegalThreadStateException();
                          
                          //正常，则将新线程加入到工作线程中
                          workers.add(w);
                          int s = workers.size();                        
                          if (s > largestPoolSize)
                              largestPoolSize = s;
                          workerAdded = true;
                      }
                  } finally {
                      //释放锁
                      mainLock.unlock();
                  }
                  //执行线程任务
                  if (workerAdded) {
                      t.start();
                      workerStarted = true;
                  }
              }
          } finally {
              if (! workerStarted)
                  addWorkerFailed(w);
          }
          return workerStarted;
      }
  ```

因此线程池工作流程如下：

- 提交任务：判断工作线程数是否达到核心线程数，没有则创建新线程、执行任务；否则，则进入下一步
- 判断线程池缓存队列是否已满，没有则将任务存储在队列中；否则，进入下一步
- 判断工作线程数达到最大线程数，没有则创建线程、执行任务；否则，执行拒绝策略

7.4.2、线程池实现类

#### 7.4.3、线程池三种实现类

​		首先，先通过线程池类框架图，来了解三种线程池实现类：

![](C:\Users\OneMTime\Desktop\Typora图片\线程池类框架图.jpg)

- Executor接口，仅定义execute（）方法，用于线程池执行Runnable接口任务
- ExecutorService接口，提供了submit（）、shutdown（）、invokeAll（）等方法，用于线程池执行任务、关闭所有线程池任务、执行多个任务等
- ScheduleExecutorService接口，提供了4种执行定时及周期性任务方法
- AbstractExecutorService，实现了ExecutorService接口定义的所有方法，但未实现execute（）方法

**线程池的三个实现类：**

- **ThreadPoolExecutor**

  ​		最常用的线程池对象，前一节进行了解析

- **ScheduledThreadPoolExecutor**

  ​		在ThreadPoolExecutor基础上，添加了定时及周期性任务执行功能。在此之前，定时任务是通过Timer、TimerTask来实现，但它们存在很大的缺点：

  ​		**Timer是单线程执行任务，因此在进行周期任务时，会出现前一次任务未执行完，导致后一次任务延期执行；但另外Timer中的线程TimerThread内部没有做异常处理，某次任务出现异常，会导致整个线程结束，无法继续周期执行**

  ​		而ScheduledThreadPoolExecuto这种线程池机制，就很好的解决了单线程带来的问题，它提供了对周期性任务执行，它提供了两种执行方案：

  ​		scheduleAtFixedRate，固定间隔时间执行，无论前一次任务是否完成，都会执行下一次任务

  ​		scheduleWithFixedDelay，固定延迟时间执行，当前一次任务执行完成后，才开始计算延迟

  ​		但是ScheduledThreadPoolExecuto相对于Timer，有一个致命缺点，无法使用指定自然时间，规定第一次执行时间（spring task、Quartz解决了整个问题，使用cron表达式）

- **ForkJoinPool**

  ​		JDK7引入的线程池，它是对ThreadPoolExecutor的补充，在某些应用场景下性能比ThreadPoolExecutor更好：

  ​		ThreadPoolExecutor每个任务都是由单个线程独立处理的，当出现一个非常耗时的大任务是，就可能出现只有一个线程在处理这个大任务，而CPU的其他线程处于空闲状态，导致CPU负载不均衡。而ForkJoinPool就解决了这种问题，它会将任务拆分为多个小任务，使用**fork**将小任务给多个线程同时处理，最后再使用**join**将多线程结果汇总，实现一个工作的**分治并行处理**，**合理利用现代CPU的多核心、多线程技术**

  ​		ForkJoinPool的实现就是基于JDK7新增的并发框架：**Fork/Join框架**

##### Fork/Join框架

​		Work Stealing算法（**工作窃取算法**）是Fork/Join框架的核心：

- 每个线程都有自己的一个WorkQueue，该工作队列为双端队列
- 队列支持三个功能：push（入栈）、pop（出栈）、poll（获取队列中的第一元素，即队尾出栈）
- push/pop只能被队列所有者线程调用；poll只能被其他线程调用（实现工作窃取）
- 子任务调用fork时，就会push到相应线程队列中；线程通过队列来获取执行任务
- 当工作队列为空时，线程随机从另一个线程的工作队列末尾poll窃取任务

#### 7.4.4、Executors（线程池工厂）

​	在实际编程中，开发者一般喜欢使用Executors的静态工厂方法来创建线程池对象，提供了对部分参数值设置，Executor有五个方法，来创建三种线程池实现类对象。 

**Executors提供五个静态方法，来获取不同功能类型的线程池对象：**

- Executors .newWorkStealingPool：

  ​		在JDK8中引入，使用**ForkJoinPool**实现类，并行级别默认为JVM可用的处理器个数（CPU线程数）、ThreadFacory使用ForkJoinPool内部提供的默认值、异常处理器为null、asyncMode=true

  ```java
      public static ExecutorService newWorkStealingPool() {
          return new ForkJoinPool
              (Runtime.getRuntime().availableProcessors(),
               ForkJoinPool.defaultForkJoinWorkerThreadFactory,
               null, true);
      }
  ```

- Executors.new CacheThreadPool：

  ​		使用**ThreadPoolExecutor**实现类，maximumPoolSize为Interg.MAX_VALUE,是高度可伸缩线程池，因此有OOM风险。corePoolSize为0，keepAliveTime默认为60s，因此所有工作线程都可以被回收

- Executors.newSingleThreadExecutor:

  ​		使用**ThreadPoolExecutor**实现类，corePoolSize、maximumPoolSize为1，keepAliveTime为0s，是一个单线程的线程池，相当于单线程串行执行所有任务，保证任务按提交顺序依次执行

- Executors.newFixedThreadPool:

  ​		使用**ThreadPoolExecutor**实现类，corePoolSize=maximumPoolSize，并且需要指定，keepAliveTime为0s，是一个固定线程数的线程池

- Executors.newScheduledThreadPool:

  ​		使用**ScheduledThreadPoolExecutor**实现类，maximumPoolSize为Interg.MAX_VALUE，因此存在OOM风险。需要指定corePoolSize，并且线程不会被回收。

  ​		Executors还提供newSingleThreadScheduledExecutor方法，用于创建一个核心线程数为1、支持定时及周期性任务执行的线程池	

  

**五种线程池对象的缓存队列：**

​		Executors .newWorkStealingPool（），

​		Executors.newCacheThreadPool（），使用SynchronousQueue<Runnable>，通过同步阻塞队列，该队列不存储元素，并每次put都会阻塞主线程，内部保证立即有空闲线程（或新线程）可以执行该任务，然后让该线程take任务，主线程唤醒；**保证了主线程提交任务，立刻调用子线程获取执行任务的同步过程**（SynchronousQueue具有非公正性和公正性两种，公正性即出现两个线程先后put（），导致线程阻塞，SynchronousQueue可以根据put（）的先后，take（）指定元素；**在newCacheThreadPool（）中使用非公正的SynchronousQueue**）

​		Executors.newSingleThreadExecutor（）、Executors.newFixedThreadPool（）使用LinkedBlockingQueue<Runnable>，通过阻塞队列缓存任务，保证缓存任务执行的公正性

​		Executors.newScheduledThreadPool（），使用DelayedWorkQueue，延迟阻塞队列，实现定时及周期性任务执行

#### 7.4.5、线程池的使用

​		通过线程池的源码分析，在线程池使用中，我们需要注意如下几点：

1 、合理设置线程池参数，根据实际业务场景来确定合理工作线程数

2、线程资源必须通过线程池提供，不允许项目中自行显式创建线程

3、线程池声明时，必须指定有意义的线程名称，方便出错回溯（即要自定义ThreadFactory）

4、虽然JUC包提供了Executors，用于快速创建相应功能类型的线程池对象；但是这样会让我们违背第一、三条，增加线程池使用的风险，因此**不允许使用Executors**

### 7.5、ThreadLocal

​		ThreadLocal用于在线程并发中作为共享变量，为每个线程创建一个变量副本（使用同一个变量对象，但在多线程中，该对象对应的值是独立的），因此也叫做**线程局部变量**

#### 7.5.1、引用类型

​		在JVM内存分配和回收中，我们知道java对象的垃圾回收，是通过它于其他对象是否存在引用关系来决定的。实际上，引用关系可以分为四类：

- 强引用，Strong Reference，最为常见。 User  user1 = new User（），这样的变量声明和定义就会产生对该对象的强引用。而只该对象存在强引用，即GC Roots存在，那么java垃圾回收时，即使内存耗尽，也不会回收该对象

- 软引用，Soft Reference，引用力度弱于“强引用”，SoftReference<User> user2 = new SoftReference<User>（new User（）），即将该对象的强引用转换为软引用，当系统将要触发OOM时，就会回收new user（）对象，从而使得user2.get（）方法返回null；

- 弱引用，Weak Reference，引用力度弱于前两个，WeakReference<User> user3 = new WeakReference<User>（new User（）），即将该对象强引用转化为弱引用，当JVM进行YGC时会被回收，从而使的user3.get（）方法返回null

- 虚引用，Phantom Reference，极弱的一种引用，PhantomReference<User> user4 = new PhantomReference<User>（new User（）），即将该对象强引用转化为虚引用，定义完成后，并不能获取该引用指定对象。在实际开发中，基本不会使用

  

  ​		强引用的最常用的，只有将user1=null时，强引用消除，才能使该对象被回收；而对于其他三种都可以减少对象在生命周期所占用的内存大小。但其使用成本较大，需要**避免当前对象存在强引用，而导致其他三种应用的特性无法实现**，因此使用风险更大

- **弱引用的使用：**

​		在hashMap中，如果将user1作为key放入map，则此时map就会保存该强引用；当我们将user1=null时，该User对象也不会被回收，hashMap也就依然保存该KV对；但当HashMap使用弱引用存放数据时，只要user1=null，则该User对象就可以被YGC回收，此时HashMap也就不在保存该KV对

​		**ThreadLocal就利用了WeakReference（弱引用）特性，让ThreadLocal对象在多线程中，能够更好地方便回收，避免使用强引用劫持，导致对象无法回收，内存泄漏**

#### 		7.5.2、ThreadLocal源码分析

​		ThreadLocal是一个泛型类，该泛型对应ThreadLocal作为共享变量值的数据类型

ThreadLocal类中提供一个包私有的静态内部类：ThreadLocalMap

- ThreadLocalMap

  ​		ThreadLocalMap内部是一个定制的哈希表数据结构，用于维护ThreadLocal对象及其值

  - ThreadLocalMap的KV对节点对象Entry，使用了ThreadLocal的WeakReference弱引用，并且将ThreadLocal对象作为Key，其值作为Value
  
    ```java
     static class Entry extends WeakReference<ThreadLocal<?>> {
                /** The value associated with this ThreadLocal. */
                Object value;
    
                Entry(ThreadLocal<?> k, Object v) {
                    super(k);
                    value = v;
                }
            }
    ```
  
    
  
  - Thread类中，有一个成员变量： ThreadLocal.ThreadLocalMap threadLocals = null;因此**每个线程都有一个ThreadLocalMap对象，来维护同一个ThreadLocal所对应的值**

ThreadLocal类通过set（）、get（）、remove（）方法来操作线程中的ThreadLocal，并且这些方法内部都是通过当前线程对象中的ThreadLocalMap属性，来进行最终的操作和存储

- set（）方法：

  ```java
   public void set(T value) {
       	//获取当前线程中的ThreadLocalMap对象
          Thread t = Thread.currentThread();
          ThreadLocalMap map = getMap(t);
       
       	//判断ThreadLocalMap对象是否为null
       	//不为null，则将ThreadLocal及其值放入ThreadLocalMap对象存储
          if (map != null)
              map.set(this, value);
          else
              //为null，则创建ThreadLocalMap对象，并存储该KV对
              createMap(t, value);
      }
  ```

- get（）方法：

   ```java
      public T get() {
          //获取当前线程中的ThreadLocalMap对象
          Thread t = Thread.currentThread();
          ThreadLocalMap map = getMap(t);
          
          //判断ThreadLocalMap对象是否为null
          //不为null，则获取当前ThreadLocal对象的保存值
          if (map != null) {
              ThreadLocalMap.Entry e = map.getEntry(this);
              if (e != null) {
                  @SuppressWarnings("unchecked")
                  T result = (T)e.value;
                  return result;
              }
          }
          
          //为null，创建一个ThreadLocalMap对象，交给当前线程
          //并执行initialValue()，初始化ThreadLocal保存值，并将其和保存值存入ThreadLocalMap对象中
          return setInitialValue();
      }
   ```

- remove（）方法

  ```java
       public void remove() {
           //获取当前线程中的ThreadLocalMap对象
           ThreadLocalMap m = getMap(Thread.currentThread());
           //不为空，则删除当前ThreadLocal所对应的KV对
           if (m != null)
               m.remove(this);
       }
  ```

我们可以得知：

1、所有ThreadLocal值的初始化，是在其get（）方法中实现的，并且ThreadLocal值并不会被ThreadLocal对象保存，而是由线程中的ThreadLocalMap对象持有；

2、ThreadLocal通过弱引用存储在ThreadLocalMap中，当ThreadLocal不存在强引用时，就会在下一次YGC时，被回收

##### ThreadLocal线程安全

​		多线程访问ThreadLocal对象时，会将ThreadLocal值的副本保存到线程的ThreadLocalMap中，之后的set、get方法执行，都是对该副本的操作。因此也就不会存在线程安全问题，所有线程中的ThreadLocal值也不会相互干扰。从而相对于全局变量，就省略了加锁同步、减少线程竞争，当然变量操作也就没有了可见性

##### ThreadLocal的脏数据

​		线程复用就会产生脏数据。由于线程池会重用Thread对象，那个和Thread绑定的静态属性ThreadLocal变量也会被重用。如果在上一次任务没有清理线程相关ThreadLocal信息时，下一次任务直接调用ThreadLocal的get（）方法，则就可能重用之前数据，而不是使用ThreadLocal定义的初始值

​		解决方式：

​		每次任务完成前，remove清理Thread中所有绑定的ThreadLocal；或者在每次执行任务前，执行set方法来初始化ThreadLocal值

##### ThreadLocal的内存泄露问题

​		ThreadLocal在设计上，就在想办法避免内存泄漏问题：

1、ThreadLocalMap使用弱引用保存ThreadLocal，从而保证即使线程存活，ThreadLocal也能被回收：

​		如果ThreadLocalMap使用强引用保存ThreadLocal：当前线程任务结束，但线程一直存活，其ThreadLocalMap属性实例和ThreadLocal就会一直存在，从而导致ThreadLocal及其值无法被回收；

​		如果使用弱引用来保存：当JVM进行YGC时，就会自动将不存在强引用的ThreadLocal进行回收，因此只要ThreadLocal没有被任何一个线程任务使用时，就会被回收，**从而实现无用ThreadLocal的自动回收（如将ThreadLocal定义为Task类的成员变量，任务完成后，ThreadLocal就会便随task对象一起被回收）**

2、当ThreadLocal被手动回收后（使用ThreadLocal=null，来释放该对象），则ThreadLocalMap中就会存储一个key=null的键值对，当执行ThreadLocal的set（）、get（）方法时，ThreadLocalMap就会自动将key==null的value置也为null，使已回收ThreadLcoal对应的Value也能够被垃圾回收**（但这样必须要保证，在ThreadLocal=null后，需要调用一次get、set方法）**

​		在实际使用中，ThreadLocal通常作为私有静态变量使用，因此会一直存在该类class对象的强引用，从而即使线程任务结束后，也无法被回收；因此如果线程不会销毁，则该键值对会一直存储在ThreadLocalMap中，导致内存泄漏；

​		解决方式：

​		在线程池中，就会常常出现核心线程不被销毁的情况，因此我们需要在使用完ThreadLocal值后，需要调用remove方法，释放value值，或者直接将线程属性threadLocals = null（线程在下次使用ThreadLocal时，会重新初始化创建）

##### ThreadLocal的本质作用

​		在一个线程任务中，可能需要调用很多方法来实现功能，而方法间的信息传递，就需要使用返回值和参数来，这样就会大大增加每个方法对参数和返回值的处理，并增加类之间的耦合。因此当使用ThreadLocal作为线程独有的局部变量时，就可以**存储单个线程上下文信息，减少参数传递，同时作为全局变量，提供给所有线程使用，但又不存在线程安全问题（每个线程中，该变量对象对应的值是独立存在的）**

#### 7.5.3、ThreadLoacl在父子线程间的传递

​		在Thread类中，所有构造方法都会调用执行同一个方法：

 ```java
    private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals) {
  
        xxx      
        //判断是否存在父线程、inheritThreadLocals==true
        if (inheritThreadLocals && parent.inheritableThreadLocals != null)
            //成立，则将父线程中的inheritableThreadLocals数据，存放到子线程中的inheritableThreadLocals
            this.inheritableThreadLocals =
                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
		xxx
    }
 ```

- Thread提供**inheritableThreadLocals属性**，来进行父子线程间的信息传递；其实现类也就是ThreadLocalMap，用于存放需要在线程间传递的InheritableThreadLocal变量
- **InheritableThreadLocal**继承了ThreadLocal类，并重写了getMap()、createMap()和childValue()方法，用于初始化和获取当前线程的Thread.inheritableThreadLocals属性值

##### InheritableThreadLocal的使用：

```java
private static InheritableThreadLocal<User> kILL_NUMBER = new InheritableThreadLocal<User>();
	public static void main(String[] args) {
		//此时主线程的inheritableThreadLocals属性已初始化
		kILL_NUMBER.set(new User("yh"));
		
        //该构造方法默认开启当前父线程的inheritableThreadLocals属性传递
		Thread thread = new Thread(null, new Runnable() {
			@Override
			public void run() {
                //此时子线程可以获取已保存父线程的值
                System.out.println(kILL_NUMBER.get().getName());
				
                //睡眠一段时间，等待父线程的inheritableThreadLocals属性数据发生改变
                try {
					Thread.sleep(1200);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
                //此时数据同步到子线程中
				System.out.println(kILL_NUMBER.get().getName());
				
			}
		},"子线程1");	
		thread.start();
        
        //睡眠一段时间，等待子线程第一次打印
        try {
            Thread.sleep(200);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
		user.setName("HHH");
		kILL_NUMBER.set(user);
	}
}
```

注意：

1、在子线程被创建时，父线程中的inheritableThreadLocals属性数据，就会复制Value引用，同步到子线程中；对于非final引用类型数据，它们使用同一个Value的引用（同一个对象），因此在不改变Value引用（不进行重新赋值）的情况下，子线程和父线程对value值的修改，会互相影响；

2、对于基本数据类型不能作为泛型使用在InheritableThreadLocal中；而其基本数据类型包装类（final引用类型），它们实际上相同值的Value，使用的是不同对象，因此父子线程对value值的修改，并不会互相影响

#### 7.5.4、ThreadLocal的使用场景

​		以SimpleDateFormat为例，作为全局变量时，存在线程安全风险。一般情况下，有如下方式解决：

1、避免作为全局变量，所有方法在内部定义其局部变量，进行使用（最低效的方式，浪费内存）

2、所有格式化的方法进行加锁同步处理，保证线程安全（通过降低效率，减少对象的创建）

**3、使用ThreadLocal来包装SimpleDateFormat，使每个线程都有自己独立的副本，实现线程安全**

**重点：**

​		**在JDK8中，重新优化了日期和时间的API，从而也可以使用新的线程安全的时间格式化类，来保证全局变量的线程安全**

## 8、单元测试

